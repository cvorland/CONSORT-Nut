<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>CONSORT-Nut 2025</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <script src="https://unpkg.com/html-docx-js/dist/html-docx.js"></script>
  <script src="https://unpkg.com/file-saver/dist/FileSaver.js"></script>

  <style>
      body { font-family: 'Inter', sans-serif; }
      
      /* Hide all pages by default */
      .page-content { display: none; }
      
      /* Show the active page */
      .page-content.active { display: block; }
      
      /* Smooth fade for tabs */
      .fade-in { animation: fadeIn 0.3s ease-in-out; }
      @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }

      /* Styling for hyperlinks in text */
      a { color: #1d4ed8; text-decoration: underline; }
      a:hover { color: #1e40af; }
  </style>
</head>
<body class="bg-gray-50 text-gray-800">

  <header class="bg-white shadow-sm">
      <div class="container mx-auto px-6 py-8 text-center">
          <h1 class="text-4xl md:text-5xl font-bold text-gray-900">CONSORT-Nut</h1>
          <p class="text-xl text-gray-600 mt-2">Extension of the CONSORT 2025 Statement for Nutrition Trials</p>
      </div>
  </header>

  <nav class="bg-gray-900 sticky top-0 z-50 shadow-lg">
      <div class="container mx-auto px-6">
          <div class="flex items-center justify-center h-16">
              <div class="flex space-x-4 overflow-x-auto whitespace-nowrap py-2 no-scrollbar" id="nav-links">
                  <a href="#checklist" class="nav-link text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm font-medium">Checklist</a>
                  <a href="#how-to-use" class="nav-link text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm font-medium">How to Use</a>
                  <a href="#background" class="nav-link text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm font-medium">Background</a>
                  <a href="#events" class="nav-link text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm font-medium">Events/Webinars</a>
                  <a href="#training" class="nav-link text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm font-medium">Training Resources</a>
                  <a href="#publications" class="nav-link text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm font-medium">Publications</a>
                  <a href="#team" class="nav-link text-gray-300 hover:bg-gray-700 hover:text-white px-3 py-2 rounded-md text-sm font-medium">Team</a>
              </div>
          </div>
      </div>
  </nav>

    <main class="container mx-auto px-4 md:px-6 py-12 max-w-5xl">
        
        <section id="checklist-page" class="page-content active fade-in">
            <div class="bg-white p-6 md:p-8 rounded-lg shadow-md border border-gray-200">
                <div class="bg-indigo-50 border-l-4 border-indigo-600 text-indigo-800 p-4 mb-8">
                    <p class="font-semibold">Interactive Checklist</p>
                    <p class="text-sm">Use this tool to track reporting in your manuscript. Enter page numbers and notes, then download the completed document. Note: all references were removed for the online format. The CONSORT 2025 and CONSORT-Nut documents should be consulted for more details.</p>
                </div>
                <div id="how-to-use-banner" class="bg-indigo-100 text-indigo-800 p-4 rounded-md mb-8 text-center cursor-pointer hover:bg-indigo-200 transition">
                  <p class="font-semibold">New to CONSORT-Nut? Click here for guidance on how to use this checklist.</p>
              </div>

                <div class="flex justify-center mb-6">
                    <button id="toggle-all-btn" class="bg-gray-200 text-gray-800 font-semibold px-4 py-2 rounded-md hover:bg-gray-300 transition text-sm flex items-center">
                        <span class="mr-2">▶</span> Expand All Details
                    </button>
                </div>
  
                <form id="checklist-form" class="space-y-10">
                    </form>

                <div class="mt-12 text-center pt-8 border-t">
                    <button id="download-word-btn" class="bg-blue-600 text-white font-semibold px-8 py-3 rounded-md hover:bg-blue-700 transition shadow-lg flex items-center justify-center mx-auto">
                        <svg class="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path></svg>
                        <span>Download Completed Checklist (.docx)</span>
                    </button>
                    <p class="text-xs text-gray-500 mt-2">The Word document will include all your notes and page numbers.</p>
                </div>
            </div>
        </section>

        <section id="how-to-use-page" class="page-content">
          <div class="bg-white p-8 rounded-lg shadow-md">
             <h2 class="text-3xl font-bold mb-4">How to Use</h2>
             <p class="text-lg">Using the CONSORT-nut Statement
                 CONSORT-Nut is a reporting guideline designed to improve how nutrition trials are described in scientific publications. It helps researchers clearly and completely report key aspects of their study, making it easier for readers, reviewers, and editors to understand what was done and why.
                 <br /><br />
                 Authors should use CONSORT-Nut when writing the results of a nutrition trial. It may also be consulted when writing the protocol, extending corresponding <a href="https://www.consort-spirit.org/" target="_blank">SPIRIT statement</a> items where applicable. The checklist includes items that guide you in reporting important details, which improves transparency and completeness.
                 <br /><br />
                 CONSORT-nut is an extension of the <a href="https://www.consort-spirit.org/" target="_blank">CONSORT statement</a>, which is used for clinical trials. This means you should use both guidelines together when reporting nutrition trials. If CONSORT-Nut does not include specific instructions for a particular item, follow the general CONSORT guidance.
                 <br /><br />
                 It is important to note that reporting guidelines like CONSORT-Nut are not tools for evaluating the quality of a study or its findings. They are meant to support clear and thorough reporting.
                 <br /><br />          
                 Many journals encourage or require authors to use reporting guidelines when submitting manuscripts. Authors may be asked to upload a completed checklist, indicating the page number where each item is addressed in the manuscript. This helps reviewers and editors quickly locate essential information.
                 <br /><br />
                 If you believe a checklist item does not apply to your study, do not leave it blank. Instead, explain why the item is not relevant. This adds transparency and helps readers understand what was and was not done in your research.
             </p>
         </div>
     </section>
 
     <section id="background-page" class="page-content">
          <div class="bg-white p-8 rounded-lg shadow-md">
             <h2 class="text-3xl font-bold mb-4">Background</h2>
             <p class="text-lg">High-quality nutrition evidence is essential for effective public health policy and practice. While Randomized Controlled Trials (RCTs) are a robust design for establishing causality, nutrition trials have unique characteristics that create reporting challenges. Factors such as participants' background diets, difficulty in blinding, and defining appropriate control groups often lead to incomplete reporting.
             <br /><br />
             There is substantial evidence that nutrition trials are frequently reported inadequately , often with poorly defined outcomes and missing protocols or statistical analysis plans. This poor reporting is unethical, wastes resources, limits reproducibility and replicability, and can lead to erroneous conclusions by researchers and policymakers, ultimately causing public confusion and low trust in nutrition science.
             <br /><br />
             CONSORT-Nut was developed to address the expressed need from researchers and journal editors for specific guidance to improve the reporting of nutrition trials.
             <br /><br />
             <strong>How CONSORT-Nut Was Developed</strong>
             <br /><br />
             The CONSORT-Nut guideline is an extension of the CONSORT 2025 statement, developed by nutrition researchers and reporting guideline experts from the Federation of European Nutrition Societies (FENS) and the STAR-Nut group (EQUATOR). The guideline was created over a 4-year, multi-step iterative process involving broad consultation. This process began with a FENS working group drafting initial recommendations, which were then refined using feedback from the global nutrition community, journal editors, and a formal Delphi survey.
             <br /><br />
             The guideline was harmonized with the updated CONSORT 2025 statement and piloted with early career researchers to test and improve its clarity. The result is CONSORT-Nut, which includes 10 nutrition-specific recommendations intended to improve the completeness of reporting in nutrition trials.
             <br /><br />
             For full details on the development of CONSORT-Nut, please see the "Publications" tab.
         </p>
         </div>
     </section>
     
     <section id="events-page" class="page-content">
         <div class="bg-white p-8 rounded-lg shadow-md">
             <h2 class="text-3xl font-bold mb-4">Events & Webinars</h2>
             <p>Stay tuned for upcoming events and webinars where we will discuss the implementation and impact of CONSORT-Nut.</p>
         </div>
     </section>
 
     <section id="training-page" class="page-content">
         <div class="bg-white p-8 rounded-lg shadow-md">
             <h2 class="text-3xl font-bold mb-4">Training Resources</h2>
             <p>Find resources here to help you use the CONSORT-Nut checklist effectively in your research and manuscript preparation.</p>
         </div>
     </section>
 
     <section id="publications-page" class="page-content">
         <div class="bg-white p-8 rounded-lg shadow-md">
             <h2 class="text-3xl font-bold mb-4">Publications</h2>
             <p class="italic">
                 Rigutto-Farebrother, J., Murphy, K. J., Minihane, A.-M., Shyam, S., Weaver, C., Calder, P. C., Khandpur, N., Tammam, J., Vorland, C. J. & Lachat, C. (2025). CONSORT-Nut: an extension of the CONSORT 2025 statement for reporting nutrition trials (manuscript in preparation). Preprint available at [placeholder for preprint link].
             </p>
         </div>
     </section>
     
     <section id="team-page" class="page-content">
      <div class="bg-white p-8 rounded-lg shadow-md">
          <h2 class="text-3xl font-bold mb-6 text-center">Meet the Team</h2>
          <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8">
              
              <!-- Jessica Rigutto-Farebrother -->
              <div class="bg-gray-100 rounded-lg shadow-md p-6 text-center">
                  <img class="w-48 h-48 rounded-full mx-auto mb-4 object-cover" style="object-position: 40% 10%;" src="https://i.imgur.com/zfebUnP.jpeg" onerror="this.onerror=null;this.src='https://placehold.co/256x256/EFEFEF/333333?text=Photo';" alt="Photo of Jessica Rigutto-Farebrother">
                  <h3 class="text-xl font-bold">Jessica Rigutto-Farebrother</h3>
                  <p class="text-gray-600">MPharm, MPH, Dr. sc. ETH</p>
                  <p class="mt-2 text-sm">ETH Zürich & University of Notre Dame</p>
                  <a href="https://iei.nd.edu/initiatives/global-center-for-the-development-of-the-whole-child/people/jessica-rigutto-farebrother" target="_blank" class="mt-4 inline-block bg-blue-600 text-white text-sm font-semibold px-4 py-2 rounded-md hover:bg-blue-700 transition">View Profile</a>
              </div>

              <!-- Karen J Murphy -->
              <div class="bg-gray-100 rounded-lg shadow-md p-6 text-center">
                  <img class="w-48 h-48 rounded-full mx-auto mb-4 object-cover" src="https://cdn.theconversation.com/avatars/311371/width238/image-20161025-28373-ue4gpj.jpg" onerror="this.onerror=null;this.src='https://placehold.co/256x256/EFEFEF/333333?text=Photo';" alt="Photo of Karen J Murphy">
                  <h3 class="text-xl font-bold">Karen J Murphy</h3>
                  <p class="text-gray-600">PhD, MDiet, APD</p>
                  <p class="mt-2 text-sm">University of South Australia</p>
                  <a href="https://people.unisa.edu.au/karen.murphy" target="_blank" class="mt-4 inline-block bg-blue-600 text-white text-sm font-semibold px-4 py-2 rounded-md hover:bg-blue-700 transition">View Profile</a>
              </div>

              <!-- Anne-Marie Minihane -->
              <div class="bg-gray-100 rounded-lg shadow-md p-6 text-center">
                  <img class="w-48 h-48 rounded-full mx-auto mb-4 object-cover" style="object-position: 50% 20%;" src="https://research-portal.uea.ac.uk/files-asset/183311023/Anne_Marie_Minihane_1.jpg?w=320&f=webp" onerror="this.onerror=null;this.src='https://placehold.co/256x256/EFEFEF/333333?text=Photo';" alt="Photo of Anne-Marie Minihane">
                  <h3 class="text-xl font-bold">Anne-Marie Minihane</h3>
                  <p class="text-gray-600">BSc, PhD</p>
                  <p class="mt-2 text-sm">University of East Anglia</p>
                  <a href="https://research-portal.uea.ac.uk/en/persons/anne-marie-minihane" target="_blank" class="mt-4 inline-block bg-blue-600 text-white text-sm font-semibold px-4 py-2 rounded-md hover:bg-blue-700 transition">View Profile</a>
              </div>
              
              <!-- Sangeetha Shyam -->
              <div class="bg-gray-100 rounded-lg shadow-md p-6 text-center">
                  <img class="w-48 h-48 rounded-full mx-auto mb-4 object-cover" style="object-position: 50% 15%;" src="https://sciroi.net/wp-content/uploads/sites/2/2024/07/Sangeetha-S.png" onerror="this.onerror=null;this.src='https://placehold.co/256x256/EFEFEF/333333?text=Photo';" alt="Photo of Sangeetha Shyam">
                  <h3 class="text-xl font-bold">Sangeetha Shyam</h3>
                  <p class="text-gray-600">PhD</p>
                  <p class="mt-2 text-sm">Rovira i Virgili University, Spain</p>
                  <a href="https://sciroi.net/person/sangeetha-shyam/" target="_blank" class="mt-4 inline-block bg-blue-600 text-white text-sm font-semibold px-4 py-2 rounded-md hover:bg-blue-700 transition">View Profile</a>
              </div>
              
              <!-- Connie Weaver -->
              <div class="bg-gray-100 rounded-lg shadow-md p-6 text-center">
                  <img class="w-48 h-48 rounded-full mx-auto mb-4 object-cover" src="https://ens.sdsu.edu/_resources/images/directory-photos/weaver-connie.jpg" onerror="this.onerror=null;this.src='https://placehold.co/256x256/EFEFEF/333333?text=Photo';" alt="Photo of Connie Weaver">
                  <h3 class="text-xl font-bold">Connie Weaver</h3>
                  <p class="text-gray-600">PhD</p>
                  <p class="mt-2 text-sm">San Diego State University</p>
                  <a href="https://ens.sdsu.edu/people/faculty/weaver-connie" target="_blank" class="mt-4 inline-block bg-blue-600 text-white text-sm font-semibold px-4 py-2 rounded-md hover:bg-blue-700 transition">View Profile</a>
              </div>

              <!-- Philip C. Calder -->
              <div class="bg-gray-100 rounded-lg shadow-md p-6 text-center">
                  <img class="w-48 h-48 rounded-full mx-auto mb-4 object-cover" src="https://www.southampton.ac.uk/sites/default/files/styles/max_1300x1300/public/staff/pcc-97219.jpg.webp?itok=2B9guXIu" onerror="this.onerror=null;this.src='https://placehold.co/256x256/EFEFEF/333333?text=Photo';" alt="Photo of Philip C. Calder">
                  <h3 class="text-xl font-bold">Philip C. Calder</h3>
                  <p class="text-gray-600">PhD, DPhil</p>
                  <p class="mt-2 text-sm">University of Southampton</p>
                  <a href="https://www.southampton.ac.uk/people/5x2d7j/professor-philip-calder" target="_blank" class="mt-4 inline-block bg-blue-600 text-white text-sm font-semibold px-4 py-2 rounded-md hover:bg-blue-700 transition">View Profile</a>
              </div>

              <!-- Neha Khandpur -->
              <div class="bg-gray-100 rounded-lg shadow-md p-6 text-center">
                  <img class="w-48 h-48 rounded-full mx-auto mb-4 object-cover" src="https://www.vcard.wur.nl/WebServices/GetMedia.ashx?id=108856" onerror="this.onerror=null;this.src='https://placehold.co/256x256/EFEFEF/333333?text=Photo';" alt="Photo of Neha Khandpur">
                  <h3 class="text-xl font-bold">Neha Khandpur</h3>
                  <p class="text-gray-600">ScD</p>
                  <p class="mt-2 text-sm">Wageningen University & Research</p>
                  <a href="https://www.wur.nl/en/persons/neha-khandpur.htm" target="_blank" class="mt-4 inline-block bg-blue-600 text-white text-sm font-semibold px-4 py-2 rounded-md hover:bg-blue-700 transition">View Profile</a>
              </div>
              
              <!-- Jonathan Tammam -->
              <div class="bg-gray-100 rounded-lg shadow-md p-6 text-center">
                  <img class="w-48 h-48 rounded-full mx-auto mb-4 object-cover" src="https://media-cdn.brookes.ac.uk/mediacontainer/medialibraries/oxfordbrookes/profile-images/staff/hls/shssw/n-z/tammam-jonathan-p0089089-small.jpg?width=256&height=256&ext=.jpg" onerror="this.onerror=null;this.src='https://placehold.co/256x256/EFEFEF/333333?text=Photo';" alt="Photo of Jonathan Tammam">
                  <h3 class="text-xl font-bold">Jonathan Tammam</h3>
                  <p class="text-gray-600">PhD, RD, RNutr</p>
                  <p class="mt-2 text-sm">Oxford Brookes University</p>
                  <a href="https://www.brookes.ac.uk/profiles/staff/jonathan-tammam/" target="_blank" class="mt-4 inline-block bg-blue-600 text-white text-sm font-semibold px-4 py-2 rounded-md hover:bg-blue-700 transition">View Profile</a>
              </div>

              <!-- Colby J Vorland -->
              <div class="bg-gray-100 rounded-lg shadow-md p-6 text-center">
                  <img class="w-48 h-48 rounded-full mx-auto mb-4 object-cover" src="https://publichealth.indiana.edu/images/profile/cvorlandProfile.jpg" onerror="this.onerror=null;this.src='https://placehold.co/256x256/EFEFEF/333333?text=Photo';" alt="Photo of Colby J Vorland">
                  <h3 class="text-xl font-bold">Colby J Vorland</h3>
                  <p class="text-gray-600">PhD</p>
                  <p class="mt-2 text-sm">Indiana University</p>
                  <a href="https://publichealth.indiana.edu/about/directory/Colby-Vorland-cvorland.html" target="_blank" class="mt-4 inline-block bg-blue-600 text-white text-sm font-semibold px-4 py-2 rounded-md hover:bg-blue-700 transition">View Profile</a>
              </div>

              <!-- Carl Lachat -->
              <div class="bg-gray-100 rounded-lg shadow-md p-6 text-center">
                  <img class="w-48 h-48 rounded-full mx-auto mb-4 object-cover" src="https://i.imgur.com/sqt6agB.jpeg" onerror="this.onerror=null;this.src='https://placehold.co/256x256/EFEFEF/333333?text=Photo';" alt="Photo of Carl Lachat">                        <h3 class="text-xl font-bold">Carl Lachat</h3>
                  <p class="text-gray-600">PhD</p>
                  <p class="mt-2 text-sm">Ghent University</p>
                  <a href="https://research.ugent.be/web/person/carl-lachat-0/en" target="_blank" class="mt-4 inline-block bg-blue-600 text-white text-sm font-semibold px-4 py-2 rounded-md hover:bg-blue-700 transition">View Profile</a>
              </div>

          </div>
      </div>
  </section>

    </main>

    <footer class="bg-gray-800 mt-12">
      <div class="container mx-auto px-6 py-4 text-center text-gray-400">
      </div>
  </footer>

    <script>
    (function () {
            document.addEventListener('DOMContentLoaded', function () {
                const navLinksWrap = document.getElementById('nav-links');
                const pages = document.querySelectorAll('.page-content');
                const form = document.getElementById('checklist-form');

                // Function to show a page and update navigation styling
                function showPage(hash) {
                    if (!pages || !pages.length) return;

                    // Determine target page ID (default to 'checklist' if hash is empty)
                    const targetId = (hash ? hash.substring(1) : 'checklist') + '-page';
                    const targetPage = document.getElementById(targetId);
                    
                    // Hide all pages
                    pages.forEach(page => page.classList.remove('active'));
                    
                    // Show target page (fallback to checklist if target doesn't exist)
                    if (targetPage) {
                        targetPage.classList.add('active');
                    } else {
                        const defaultPage = document.getElementById('checklist-page');
                        if(defaultPage) defaultPage.classList.add('active');
                    }

                    // Update Navigation Link Styling (Highlight the active tab)
                    if (navLinksWrap) {
                        const links = navLinksWrap.querySelectorAll('.nav-link');
                        const currentHash = hash || '#checklist';
                        
                        links.forEach(link => {
                            // Reset to inactive style (text-gray-300)
                            link.classList.remove('bg-gray-900', 'text-white');
                            link.classList.add('text-gray-300');

                            // Apply active style if matches (bg-gray-900 text-white)
                            if (link.getAttribute('href') === currentHash) {
                                link.classList.remove('text-gray-300');
                                link.classList.add('bg-gray-900', 'text-white');
                            }
                        });
                    }
                }

                // Event delegation for navigation clicks
                if (navLinksWrap) {
                    navLinksWrap.addEventListener('click', function (e) {
                        const t = e.target;
                        // Check if clicked element is a nav link
                        if (t && t.classList && t.classList.contains('nav-link')) {
                            e.preventDefault();
                            const targetHash = t.getAttribute('href');
                            
                            // Update URL without reload
                            history.pushState(null, '', targetHash);
                            
                            // Update view
                            showPage(targetHash);
                        }
                    });
                }

                // Handle "How to use" banner click inside checklist
                const howToBanner = document.getElementById('how-to-use-banner');
                if (howToBanner) {
                    howToBanner.addEventListener('click', () => {
                        const targetHash = '#how-to-use';
                        history.pushState(null, '', targetHash);
                        showPage(targetHash);
                    });
                }

                // Handle browser Back/Forward buttons
                window.addEventListener('popstate', function () {
                    showPage(window.location.hash);
                });

                // Initial load
                showPage(window.location.hash);
            });

        // Full Data Object - cleaned of citations
        const checklistData = [
            // --- TITLE AND ABSTRACT ---
            {
                group: 'Title and Abstract',
                items: [
                    {
                        id: '1a',
                        title: 'Title and structured abstract',
                        text: 'Identification as a randomized trial',
                        consort_explanation: `<p>The ability to identify a report of a randomised trial in a bibliographic database depends to a large extent on how it was indexed. Indexers might not classify a report as a randomised trial if the authors do not explicitly report this information. To help ensure that a study is appropriately indexed and easily identified, authors should use the word "randomised" in the title to indicate that the participants were randomly assigned to their comparison groups.</p>`,
                        consort_examples: `<p>“Efficacy and Safety of Early Administration of 4-Factor Prothrombin Complex Concentrate in Patients With Trauma at Risk of Massive Transfusion: The PROCOAG Randomized Clinical Trial.”</p>`,
                        nut_ext: 'Identification of the dietary comparator, where possible',
                        nut_explanation: `<p><i>Title</i><br />In addition to stating ‘randomized trial’, the title should include details of the food or supplement bioactive(s), food/food group, dietary pattern or eating behaviour intervention. Where word count allows, the title should also provide information on the dietary comparator, as this is critical for the interpretation of the findings and their translation into nutrition policy. For food-based intervention, where dietary patterns, foods or food extracts are used as the ‘control’, all such comparators will contain a range of bioactive components, the selection of which will impact on the perceived efficacy of the intervention of interest and the detected size effect. For supplementation studies which used a placebo capsule/pill, a derivation of the term placebo-controlled should be used in the title.<br /><br /><i>Abstract</i><br />Abstracts should be clear, transparent, and sufficiently detailed to be stand-alone. As with the title, the abstract should describe the nutrient or bioactive (and its chemical form if relevant), food/food group, dietary pattern or eating behaviour intervention in as much detail as the word-count allows, along with the comparator intervention. Authors should be cognizant when describing dietary patterns of how they may be interpreted, when applicable. For example, “low fat” vs. “low carbohydrate” masks other dietary differences that may be important to the interpretation of results. Because space is limited in the abstract, additional details about the intervention and comparator will be reported elsewhere (see item #13), but we suggest quantifying key targets (e.g., “20% energy from fat”), or naming the primary food group(s) manipulated (e.g., “replacing 100 g red meat with 100 g fish”). If no intervention was administered in the comparator group, e.g. ‘usual-care’ for patients or ‘habitual-diet’, then this should also be stated and described. If eating behaviour, dietary intake or nutrition status is the primary outcome, the abstract should also clearly state it, along with their quantification methodology.</p>`,
                        nut_examples: `<p><i>Title</i><br />1. “High-dose vitamin D versus placebo to prevent complications in COVID-19 patients: Multicentre randomized controlled clinical trial” (Mariani et al., 2022)”.</p><p>2. “Impact of a Low-Carbohydrate Compared with Low-Fat Breakfast on Blood Glucose Control in Type 2 Diabetes: A Randomized Trial” (Oliveira et al., 2023).</p><p>3. “Low versus standard calorie and protein feeding in ventilated adults with shock: a randomised, controlled, multicentre, open-label, parallel-group trial” (Reignier et al., 2023).<br /><br /><i>Abstract</i><br />1. “We randomly assigned participants to receive 1000 mg of elemental calcium as calcium carbonate with 400 IU of vitamin D3 daily or placebo” (Jackson et al., 2006).<br />2. “In a multicenter trial in Spain, we assigned 7447 participants (55 to 80 years of age, 57% women) who were at high cardiovascular risk, but with no cardiovascular disease at enrolment, to one of three diets: a Mediterranean diet supplemented with extra-virgin olive oil, a Mediterranean diet supplemented with mixed nuts, or a control diet (advice to reduce dietary fat). Participants received quarterly educational sessions and, depending on group assignment, free provision of extra-virgin olive oil, mixed nuts, or small non-food gifts” (Estruch et al., 2018).<br />3. “Newly diagnosed patients with breast cancer (N = 173) undergoing chemotherapy were randomized to a year-long nutrition and exercise intervention (n = 87) or usual care (UC, n = 86)” (Puklin et al., 2024).</p>`
                    },
                    {
                        id: '1b',
                        title: 'Title and structured abstract',
                        text: 'Structured summary of trial design, methods, results, and conclusions',
                        consort_explanation: `
                            <p>Transparent and sufficiently detailed abstracts are important because readers often base their assessment of a trial on such information. Some readers use an abstract as a screening tool to decide whether to read the full article. However, not all trials are freely available and some health professionals and other users do not have access to the full trial reports.</p>
                            <p>A journal abstract should contain sufficient information about a trial to serve as an accurate record of its conduct and findings, providing optimal information about the trial within the space constraints and format of a journal. A properly constructed and written abstract helps individuals to assess quickly the relevance of the findings and aids the retrieval of relevant reports from electronic databases. The abstract should accurately reflect what is included in the full journal article and should not include information that does not appear in the body of the paper. In addition, abstracts should not be a distorted representation of the trial results. Studies comparing information reported in a journal abstract with that reported in the text of the full publication have found claims that are inconsistent with, or missing from, the body of the full article. Abstracts are also frequently reported with spin defined as a distorted representation of the study results. Authors should avoid selectively reporting only statistically significant secondary outcomes or subgroup analyses. Conversely, omitting important harms from the abstract could seriously mislead interpretation of the trial findings and benefit-to-harms balance that is critical for decision making.</p>
                            <p>An extension to CONSORT 2001 provided a list of essential items that authors should include in a journal (or conference) abstract when reporting the main results of a randomised trial. A systematic review of 10 meta-research studies examined the reporting quality of abstracts of randomised trials and found improvements in reporting following publication of this extension. Table 2 provides a list of essential items to include in an abstract; it is based on the CONSORT for Abstracts extension and has been updated to reflect changes made to the main CONSORT checklist. We strongly recommend the use of structured abstracts for reporting randomised trials. They provide readers with information about the trial under a series of headings pertaining to the design, conduct, analysis and interpretation. Some studies have found that structured abstracts offer greater value and information coverage than the more traditional descriptive abstracts and allow readers to find information more easily. We recognise that journals have their own structure for reporting abstracts. It is not our intention to suggest changes to these formats, but to recommend what information should be reported.</p>
                        `,
                        nut_ext: 'Description of the bioactive compound, nutrient, food/food group, dietary pattern or eating behaviour intervention and comparator',
                        nut_explanation: `<p>Abstracts should be clear, transparent, and sufficiently detailed to be stand-alone. As with the title, the abstract should describe the nutrient or bioactive (and its chemical form if relevant), food/food group, dietary pattern or eating behaviour intervention in as much detail as the word-count allows, along with the comparator intervention. If no intervention was administered in the comparator group, e.g. ‘usual-care’ for patients or ‘habitual-diet’, then this should also be stated. The abstract should also clearly state if eating behaviour, dietary intake or nutrition status is the primary outcome along with their quantification methodology.</p>`,
                        nut_examples: `<p>1. “We randomly assigned participants to receive 1000 mg of elemental calcium as calcium carbonate with 400 IU of vitamin D3 daily or placebo” (Jackson et al., 2006).</p><p>2. “In a multicenter trial in Spain, we assigned 7447 participants... to one of three diets: a Mediterranean diet supplemented with extra-virgin olive oil, a Mediterranean diet supplemented with mixed nuts, or a control diet (advice to reduce dietary fat). Participants received quarterly educational sessions and, depending on group assignment, free provision of extra-virgin olive oil, mixed nuts, or small non-food gifts” (Estruch et al., 2018).</p><p>3. “Newly diagnosed patients with breast cancer (N = 173) undergoing chemotherapy were randomized to a year-long nutrition and exercise intervention (n = 87) or usual care (UC, n = 86)” (Puklin et al., 2024).</p>`
                    }
                ]
            },
            // --- OPEN SCIENCE ---
            {
                group: 'Open Science',
                items: [
                {
                        id: '2',
                        title: 'Trial registration',
                        text: 'Name of trial registry, identifying number (with URL) and date of registration',
                        consort_examples: `<p>“This study was registered in the Iranian Registry of Clinical Trials under the code IRCT20150531022498N30: https://en.irct.ir/trial/41031. Registered on July 26, 2019.”</p>`,
                        consort_explanation: `
                            <p>The consequences of non-publication of entire trials (ie, publication bias), and of selective reporting of outcomes and analyses within trials, have been well documented. For almost 40 years, there have been growing calls to address these practices. Today, a ubiquitous view recommends trial registration as the best practice to achieve this goal, and inform policymakers and potential participants about ongoing trials. Registering clinical trials, before any assignment of participants, with unique trial identification numbers and other basic information about the trial so that essential details are made publicly available, is a minimum best practice. Serious problems of withholding data led to renewed efforts to ensure registration of randomised trials. The World Health Organization (WHO) states that “the registration of all interventional trials is a scientific, ethical and moral responsibility.”</p>
                            <p>In September 2004, the ICMJE established a policy that it would only consider trials for publication if they had been registered before the enrolment of the first participant. This policy resulted in a substantial increase in the number of trials being registered. However, some trials are still not registered. The ICMJE gives guidance on acceptable registries (https://www.icmje.org/about-icmje/faqs/clinical-trials-registration/) and also accepts registration in WHO primary registries (https://www.who.int/clinical-trials-registry-platform/network/primary-registries) and ClinicalTrials.gov. Registers charging a fee to view their content should be avoided to ensure equity of access for everyone, including patients and the public.</p>
                            <p>The Transparency and Openness Promotion (TOP) guidelines, endorsed and used by thousands of journals, recommends trial registration. In a survey of 168 high impact factor medical journals’ “Instructions to authors” in 2014, 78 journals stated that all recent clinical trials must be registered as a requirement of submission to that journal. A more recent survey in 2019 of surgical journals publishing randomised trials found that 53 of 82 journals mandated prospective registration.</p>
                            <p>Despite recommendations, and mandates in some jurisdictions for clinical trialists to register their trial and evidence that registration deters selective reporting, this is still not happening universally. Authors should provide the name of the registry, the trial’s associated registration number, date of registration and, where possible, the URL for the trial’s registration. We recommend that authors also report whether (or when) the trial results are available on the associated trial register.</p>
                            <p>Despite the considerable increase in clinical trial registration, there is a strong body of evidence showing the lack of access to trial results. The latest version of the Declaration of Helsinki states that “Researchers have a duty to make publicly available the results of their research on human participants and are accountable for the timeliness, completeness, and accuracy of their reports . . . Negative and inconclusive as well as positive results must be published or otherwise made publicly available.” In 2015, WHO published a new statement on the public disclosure of trial results, which requests that “the key outcomes are to be made publicly available within 12 months of study completion by posting to the results section of the primary clinical trial registry. Where a registry is used without a results database available, the results should be posted on a free-to-access, publicly available, searchable institutional website of the Regulatory Sponsor, Funder or Principal Investigator.” Some legislations are also in place in the US, UK, and Europe requesting the posting of trial results on clinical trials registry within 12 months after study completion.</p>
                            <p>Authors should indicate whether the trial results are publicly posted to the trial registry, as a preprint (with URL citation) or as published articles (with citations).</p>
                        `
                    },
                    {
                        id: '3',
                        title: 'Protocol and SAP',
                        text: 'Where the trial protocol and statistical analysis plan can be accessed',
                        consort_examples: `<p>“The full trial protocol and the Statistical Analysis Plan can be accessed in the Supplementary Material”. This article and supplementary material are open access.</p>`,
                        consort_explanation: `
                            <p>A protocol for the complete trial (rather than a protocol of a specific procedure within a trial, such as for the intervention) is important because it prespecifies the methods of the randomised trial, for example, the primary outcome (item 14). Having a protocol provides important context to interpret a trial, implement its findings, and facilitate replication and appraisal of risk of bias. It can also help to restrict the likelihood of undeclared post hoc changes to the trial methods and selective outcome reporting (item 10). Elements that are important to address in the protocol for a randomised trial are described in the SPIRIT 2025 statement.</p>
                            <p>A protocol may either include the full statistical analysis plan or may include a section outlining the main principles while referencing and reporting the full statistical analysis plan as a separate, more detailed document. The statistical analysis plan typically includes details about several aspects of the clinical trial, such as the data analysis plan for the primary outcome(s) and all secondary outcomes. Details about what to include in a statistical analysis plan can be found elsewhere.</p>
                            <p>The protocol should be signed off by the trial steering committee before the allocation of any participants and data collection. Similarly, the full statistical analysis plan should be signed off by the trial steering committee before the dataset is closed for analysis. This allows transparent documentation of any subsequent changes to either document. In many trials, changes to the protocol and statistical analysis plan may happen after the trial onset for legitimate reasons (eg, in response to challenges that were not anticipated or new evidence). In these cases, each iteration of the protocol and statistical analysis plan should record the changes along with their rationale and timing.</p>
                            <p>There are several options for authors to consider to ensure their trial protocol, and full statistical analysis plan where applicable, are accessible to interested readers. The protocol and full statistical analysis plan (and their various iterations) can be stored in a repository, such as the Open Science Framework, which is free to use and access for all readers. Openness and accessibility are core elements of open science (see Open science section). Trial protocols and statistical analysis plans can also be published in journals such as Trials and BMJ Open. Open access publication would ensure that any reader, including patients and the public, can access the document. Trial registration (item 2) will also ensure that a minimum set of trial protocol details are available as part of the trial’s registration (https://www.who.int/clinical-trials-registry-platform), but often a registration record leaves large ambiguity about key protocol issues and statistical analyses. The more detailed trial protocol can also be posted on most clinical trial registries.</p>
                            <p>Ideally, the authors should give access to the protocol signed off by the trial steering committee before the allocation of any participants and data collection with any subsequent changes with their rationale and timing.</p>
                            <p>When submitting a completed trial report, trial authors can include their protocol as a supplemental document or provide a URL to its location. Such documentation can facilitate peer review and help identify reporting biases.</p>
                        `
                    },
                    {
                        id: '4',
                        title: 'Data sharing',
                        text: 'Where and how the individual de-identified participant data (including data dictionary), statistical code, and any other materials can be accessed',
                        consort_examples: `
                            <p>“All data requests should be submitted to the corresponding author (AR) for consideration as agreed in our publication plan. Access to anonymised data may be granted following review with the Trial Management Group and agreement of the chief investigator (AR).”</p>
                            <p>“Deidentified data collected and presented in this study, including individual participant data and a data dictionary defining each field in the set, will be made available upon reasonable request after publication of this Article, following approval by regulatory authorities. Data can be requested by contacting the corresponding author.”</p>
                        `,
                        consort_explanation: `
                            <p>Data and code sharing can take the transparency of trial reporting to a different, more desirable level. Sharing individual de-identified participant data would be helpful in many ways: verifying results and increasing trust; using data more extensively for secondary analyses; and using data for individual patient data meta-analysis (IPD MA). Data sharing is also associated with increased citations (ie, broader dissemination). Some trial groups have worked collaboratively to conduct IPD MA. However, for most randomised trials, data sharing does not happen. During the covid-19 pandemic, there were many examples of authors’ intentions to share data that then did not transpire (ie, they did not share their data). There is increasing concern that some trials are fraudulent or considered to be so-called zombie trials, which becomes evident only on inspection of the raw data. However, even if zombie trials are not as prevalent as feared, genuine trials can have such an important role and high value that it is important to maximise their utility by making them more open. Detailed documentation of sharing plans may help in this direction.</p>
                            <p>All data sharing should abide by the principle of being as open as possible and as closed as necessary throughout a randomised trial’s life cycle (from SPIRIT to CONSORT). It is important to ensure that all the appropriate permissions are included on the patient consent forms. Trials cannot share data that are not fully anonymised without the appropriate patient consent, and full anonymisation can be difficult. Care must be taken to share participant data appropriately to maintain confidentiality. Suitable mechanisms must be in place to appropriately de-identify participant data, and data should only be shared in a safe and secure manner that fits with the consent obtained from participants.</p>
                            <p>Data sharing typically involves sharing: the underlying data generated from the trial’s conduct; a data dictionary (ie, structure, content, and meaning of each data variable); and other relevant material(s) used as part of the trial’s analysis such as the trial protocol, data management plan, statistical analysis plan, and code used to analyse the data. A trial’s data can be shared in a variety of ways, such as via an institutional repository (eg, belonging to the university associated with the trial’s coordinating centre) and/or a public-facing repository, or by having a bespoke process to provide data. Often, a data use agreement is necessary, which will, at a minimum: prohibit attempts to reidentify or contact trial participants; address any requirements regarding planned outputs of the proposed research (eg, publication and acknowledgment requirements); and prohibit non-approved uses or further distribution of the data.</p>
                            <p>In a growing number of jurisdictions, funders such as the National Institute for Health (NIH), in the US and the National Institute for Health and Care Research (NIHR) in the UK, alongside other funders such as the Gate’s Foundation, now require researchers to share their data and make the results publicly available for anyone to read. Similarly, some journals are also requiring authors to include a data sharing statement as part of the article submission process (eg, Annals of Internal Medicine, The BMJ, JAMA Network journals, PLoS Medicine).</p>
                            <p>The process of signalling how data sharing will be achieved is often contained in a data management plan but may also be found in the trial protocol or statistical analysis plan. More complete details regarding developing a data management plan are beyond the scope of this paper. Such details can be found elsewhere. Authors should provide some description of where these details can be found (eg, name of repository and URL to data, code, and materials). Sharing may also entail embargo periods, and if so, the choice of an embargo should be justified and its length should be stated. If data (or some parts thereof) cannot be shared, the reasons for this should be reported and should be sensible and following ethical principles.</p>
                            <p>For more complex trials (eg, types of talking therapies, physiotherapy), additional materials to share might include a handbook and/or video to detail the intervention. Often these can be shared much more freely than the data, as there are fewer issues with confidentiality.</p>
                        `
                    },
                    {
                        id: '5a',
                        title: 'Funding',
                        text: 'Sources of funding and other support (eg, supply of drugs), and role of funders in the design, conduct, analysis, and reporting of the trial',
                        consort_examples: `
                            <p>“Grant support was received for the intervention from Plan International and for the research from the Wellcome Trust and Joint United Nations Programme on HIV/AIDS (UNAIDS). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.”</p>
                            <p>“Funding: Merck Sharp and Dohme . . . The study funder had a role in the study design, data collection, data analysis, data interpretation, and writing of the report.”</p>
                            <p>The article also states that “Merck employees LY, SB, and PB were involved in the conceptualisation of the study, formal analysis, the investigation process, development of the methodology, project administration, drafting the manuscript, and had critically reviewed and edited the manuscript.”</p>
                        `,
                        consort_explanation: `
                            <p>Reporting the funding source(s), and the exact roles of the trial funders, provides important context for readers of a trial report when ascertaining overall methodological rigor (eg, relevance of the type of comparator intervention and eligibility criteria for patients) and risk of bias (eg, selective reporting of favourable results). The trial report should therefore describe details of all funders and the types of funding, as well as the role of the funder in trial design (ie, protocol development), conduct, data analysis, and reporting (ie, interpretation, manuscript writing, and dissemination of results). This should include whether the funder controlled the final decision regarding any of these aspects of the trial, and any mechanisms introduced to minimise funder influence. If the funder had no direct involvement in the trial, that should be stated.</p>
                            <p>A randomised trial requires considerable funding, typically from pharmaceutical or device companies (industry funding); or from research councils or other scientific or private foundations, or governmental or non-governmental organisations (non-industry funding). One study of trials conducted between 2010 and 2015 estimated the median cost per phase 3 drug company trial at $21.4m (£17.21m; €20.7m), with substantial variation. The mean cost of clinical trials funded by the NIHR in the UK, reflecting differences in the research and care infrastructure already funded, was lower, but still sizeable—approximately £1.3m—with considerable variation. The various types of funders differ in their overall agenda, their reasons for funding a trial, and their propensity to influence the trial.</p>
                            <p>Funding of a trial typically involves direct monetary support, but financial support may also be provided indirectly in the form of free trial drugs, equipment, or services (eg, statistical analysis or use of medical writers). Among the most highly cited clinical trials published in 2019 to 2022, two thirds were funded by industry sponsors, many of whom also provided industry analysts and coauthors.</p>
                            <p>Industry funding of trials is associated with conclusions that favour the experimental intervention. A systematic review of 75 methodological studies, comparing industry funded studies with non-industry funded studies (mostly randomised trials), reported that industry funded studies had favourable conclusions more often than non‐industry funded studies (risk ratio 1.34; 95% confidence interval (CI) 1.19 to 1.51). Industry funded trials may also report more favourable results (ie, larger estimates of intervention effects) than comparable trials that are funded by non-industry sources. One review of eight published meta-epidemiological studies reported that intervention effects (odds ratios) from industry funded trials were, on average, exaggerated by 5% (95% CI −6% to 15%), although the result was imprecise and consistent with chance findings. However, trials with a high risk of industry funder influence (eg, on trial design, conduct, analysis, and reporting) exaggerated effect estimates by 12% (95% CI 3% to 19%). Undue influence on trials from non-industry funders with a strong interest in a specific trial result has been described, but has been studied much less.</p>
                            <p>A review of 200 trials published in 2015 found that 178 (89%) publications included a funding statement. However, in half of the publications, the role of funder was not reported; in the other half, the reporting was often unclear or incomplete; and undisclosed funding from a for-profit organisation was found in 26 of 54 trials reporting only not-for-profit funding. Another study surveyed authors of 200 trials fully funded by industry and found that funders had been involved in the design of 173 trials (87%), in the data analysis of 146 trials (73%), and in the reporting of 173 trials (87%). No clear consensus exists on a monetary threshold for when funding from a source with conflict of interest becomes problematic. It is also unclear whether commercial funding is less important than the degree and type of funder influence on trial design, conduct, analysis, and reporting.</p>
                        `
                    },
                    {
                        id: '5b',
                        title: 'Conflicts of interest',
                        text: 'Financial and other conflicts of interest of the manuscript authors',
                        consort_examples: `
                            <p>“SYR reports grants from Amgen, Astellas, Daiichi Sankyo, Eisai, Merck, Roche, Zymeworks, Indivumed, MSD, Ono/Bristol Myers Squibb, AstraZeneca, BI, Taiho, Lilly, SN Bioscience. SRF has received honoraria as an invited speaker for Lilly, Eisai, Daiichi Sankyo, MSD, and Ono/Bristol Myers Squibb; has participated on advisory boards for Amgen and Indivumed; and has served as an advisor for Astellas, Daiichi Sankyo, Eisai, LG Biochem, Merck Sharpe Dohme, Ono/Bristol Myers Squibb, and AstraZeneca. D-YO reports grants from AstraZeneca, Novartis, Array, Eli Lilly, Servier, BeiGene, Merck Sharpe Dohme, and Handok; and has participated on a data safety monitoring board or advisory board for AstraZeneca, Novartis, Genentech/Roche, Merck Serono, Bayer, Taiho, ASLAN, Halozyme, Zymeworks, Bristol Myers Squibb/Celgene, BeiGene, Basilea, Turning Point, Yuhan, Arcus Biosciences, IQVIA, and Merck Sharpe Dohme. M-HR reports research grants from AstraZeneca; consulting fees from Bristol Myers Squibb, Ono, Lilly, Merck Sharpe Dohme, Novartis, Daiichi Sankyo, AstraZeneca, Sanofi, and Astellas; and has received honoraria for lectures, presentations, speakers bureaus, or educational events from Bristol Myers Squibb, Ono, Lilly, Merck Sharpe Dohme, Novartis, Daiichi Sankyo, AstraZeneca, Sanofi, and Astellas . . .”</p>
                            <p>“LY, SB and PB report full-time employment by Merck Sharp and Dohme, a subsidiary of Merck (Rahway, NJ, USA), and stock ownership in Merck. LSW reports consulting fees from Amgen; and has received honoraria for lectures, presentations, speakers bureaus, or educational events from Novartis, Bristol Myers Squibb, Merck Sharpe Dohme, Roche, and Amgen.”</p>
                            <p>“PY, YB, JLee, MGF, JLi, MAL, TC, SQ, SL, and HP declare no competing interests.”</p>
                        `,
                        consort_explanation: `
                            <p>Disclosure of authors’ conflicts of interest provides important context for readers of a trial report when ascertaining the overall methodological rigor of a trial (eg, relevance of the type of comparator intervention and eligibility criteria for patients) and risk of bias (eg, selective reporting of favourable results). Conflicts of interest of all trial manuscript authors should be reported, along with any procedures to reduce the risk of conflicts of interest influencing the trial’s design, conduct, analysis, or reporting.</p>
                            <p>Conflicts of interest can be defined as “a set of circumstances that creates a risk that professional judgement or actions regarding a primary interest will be unduly influenced by a secondary interest.” In the context of authors of a trial report, conflicts of interest imply a risk that investigators’ personal interests and allegiances, or ties with companies or organisations, have undue influence on the design, conduct, analysis, or reporting of a trial. The concept implies a risk of influence and is not indicative of actual wrongdoing.</p>
                            <p>Conflicts of interest are most often associated with the drug and device industries. Types of financial ties include salary support or grants; ownership of stock or options; honorariums (eg, for advice, authorship, or public speaking); paid consultancy or service on advisory boards and medical education companies; and receipt of patents or patents pending. An analysis of 200 trials from 2015 reported that 57% of trials had at least one author declaring financial conflicts of interests.</p>
                            <p>Conflicts of interest may also exist with support from or affiliation with government agencies, charities, and professional and civic organisations. Non-financial conflicts of interest include academic commitments; personal or professional relationships; and political, religious, or other affiliations with special interests or advocacy positions. An analysis of 200 trials found that 4% of trials had at least one author declaring non-financial conflicts of interest. There is ongoing discussion on the association between a problematic non-financial conflict of interest and a reasonable point of view.</p>
                            <p>A cross sectional study of 190 randomised trials, published in core clinical journals, found that trials with authors’ conflicts of interest had more positive results than trials without. The presence of a financial tie was associated with a positive study outcome (odds ratio 3.23; 95% CI 1.7 to 6.1). This association was also present after adjustment for the study funding source (odds ratio 3.57; 95% CI 1.7 to 7.7).</p>
                            <p>Although financial conflicts of interest are often declared in trials, the declarations are generally imprecise, and undisclosed conflicts are common. A systematic review of studies comparing financial conflicts of interest declared in medical publications or guidelines (not only randomised trials) with declarations in payment databases (eg, the Open Payments Database) found that the median percentage of authors with “non-concordant” disclosures was 81%. A study including only randomised trials found that 35 (30%) of 115 authors from non-industry funded trials had undisclosed conflicts of interest whereas that was the case for 102 (50%) of 203 authors from industry funded trials. For financial conflicts that cannot be tracked to public databases and for non-financial conflicts, the rate of non-disclosure is unknown but it is likely to be even higher.</p>
                        `,
                        nut_ext: 'No formal extension for item 5b pertaining to nutrition trials. However, authors are advised to keep the example below in mind while reporting trial findings.',
                        nut_explanation: `
                            <p>While there are no additional recommendations for this item specific to nutrition trials, it is noted that assessing or managing COIs in nutrition needs a nuanced approach. To date, COI declaration in nutrition predominantly focuses on declaring funding or collaborations with the food industry, disregarding other potential biases arising from personal beliefs, practices (such as dietary preferences) or subsequent professional incentives. While it can be argued that such biases are common to all fields, nutrition scientists have the added challenge of navigating biases arising from their own dietary norms established as a result of family, cultural, or religious influences. The consensus meeting described earlier identified that COI declarations for nutrition trials should include both industry-links (financial) and other personal biases relating to diet and environment. This consensus is in-line with the CONSORT 2025 recommendations that defines COI as “a set of circumstances that creates a risk that professional judgement or actions regarding a primary interest will be unduly influenced by a secondary interest.”</p>
                        `,
                        nut_examples: `
                            <p>“The study received funds from (….) Companies and (... …). has received research grants from ….. Growers Associations, ……., the … Company (investigator initiated, unrestricted grant), ….. He has been on the speaker’s panel, served on the scientific advisory board, and/or received travel support and/or honoraria from Nutritional …, …Medical Center, The University of …, 2020 … International Conference…Institute of …..., the Nutrition Foundation … …, ……. the …Nutrition Society, …Society of Nutrition (ASN)... …. He is a member of the … Consortium ... His wife, …. is a director and partner of … Clinical Research for the Food Industry, his 2 daughters, ….have published a vegetarian book that promotes the use of the foods described here, … has served as an external resource person to the World Health Organization’s Nutrition Guidelines Advisory Group on ….. The World Health Organization paid for his travel and accommodation to attend meetings …. to present and discuss this work. He has received speaker’s fees from …. as a principal investigator. He serves as a member of the … Advisory Committee to … .. (Government of ….), a co-opted member of the Scientific Advisory Committee on Nutrition (SACN) Subgroup … and as an independent director of …...” (Jenkins et al., 2022).</p>
                            <br /><p>This is an example of a conflict of interest (COI) declaration that lists links with the food industry (previous grants, consulting fees, travel support and honoraria), potential positional biases and financial interests relating to other activities by the author, his family members or associates which could benefit from the trial findings, and affiliations and membership of the author in organizations with perceived interest in the study. The exhaustive mention of COIs facilitates assessing authors personal dietary beliefs and practices.</p>
                        `
                    }
                ]
            },
            // --- INTRODUCTION ---
            {
                group: 'Introduction',
                items: [
                {
                        id: '6',
                        title: 'Background and rationale',
                        text: 'Scientific background and rationale',
                        consort_examples: `<p>“Most problems with shoulder pain are managed in primary care by physiotherapists and GPs [general practitioners] . . . Evidence from small, short-term trials suggests that physiotherapist-prescribed exercise is promising. However, a Cochrane review highlighted the insufficient evidence about the treatment's long-term clinical effectiveness and cost-effectiveness. Despite widespread provision, uncertainty exists about which types of exercise and levels of physiotherapy supervision are associated with the best outcomes. This evidence is limited by problems in study design and lack of comparator groups. Progressive resistance training to improve muscular strength, whether supervised or home based, has been identified as a core component of exercise for patients with rotator cuff disorders. Subacromial corticosteroid injections are commonly used to reduce local tissue inflammation and pain. Compared with placebo, corticosteroid injections have short-term benefit in the shoulder, although the longer-term benefits and harms are not known. Corticosteroid injections are being used increasingly in clinical practice alongside physiotherapy for the management of people with rotator cuff disorders; hence justification for investigating corticosteroid injection in the GRASP (Getting it Right: Addressing Shoulder Pain) trial alongside physiotherapist-prescribed exercise.”</p>`,
                        consort_explanation: `
                            <p>Typically, the introduction of the trial report consists of free-flowing text, in which authors explain the scientific background and rationale for their trial, and its general outline. The rationale may be explanatory (eg, to assess the possible influence of a drug on renal function under tightly regulated conditions) or pragmatic (eg, to guide practice by comparing the benefits and harms of two treatments in a clinical setting). Authors should report any evidence of the benefits and harms of active interventions included in a trial and should suggest a plausible explanation for how the interventions might work, if this is not obvious. Understanding the rationale or theory underpinning an intervention helps readers to understand which aspects or components are likely to be essential to its efficacy. In addition, authors should justify the choice of comparator(s). The choice of the comparator (active or placebo) will influence effect estimates. It could raise ethical concerns if patients could be allocated to a placebo or to a suboptimal treatment while an active treatment has been proven effective. Authors should justify the need for the trial they conducted and show that there was equipoise about the best treatment for the condition in the population being studied.</p>
                            <p>The Declaration of Helsinki states that biomedical research involving people should be based on a thorough knowledge of the scientific literature. It is unethical to expose humans unnecessarily to the risks of research. Some clinical trials have been shown to have been unnecessary because the question they addressed had been, or could have been, answered by a systematic review of the existing literature. Thus, the need for a new trial should be justified in the introduction. Ideally, this justification should include a reference to one or more systematic reviews of previous trials. In the absence of a published systematic review, authors should report and summarise the results of previous relevant trials or note their absence. The percentage of published trial reports that cite a systematic review of pre-existing evidence where one is available has increased over time, but over a quarter still fail to do so.</p>
                        `,
                        nut_ext: 'Rationalization of the study within the context of the current dietary recommendations and food intake in the population of interest, if relevant. The target population chosen should be justified, giving details, where possible. PICO (Population, Intervention, Comparator, Outcome) criteria should be clearly identifiable.',
                        nut_explanation: `
                            <p>The introduction should clearly describe the specific nutrition question using the PICO framework, and the scientific background and justification should provide a critical assessment of available RCTs, high-quality systematic reviews of RCTs, observational studies (with a focus, where available on prospective cohort data) and pre-clinical evidence. If it is not obvious, the conceptual behavioural, physiological, or molecular mechanism underpinning the impact of the intervention on the primary outcome measures (or secondary outcomes for a secondary analysis) should be stated.</p>
                            <p>Unlike pharmacological RCTs, in many nutrition RCTs, there will be a background habitual eating behaviour and intake of the intervention’s nutrient or non-nutrient bioactive, food, or dietary pattern of interest. In order to contextualize the study design and research findings, it is important to include in the introduction, as relevant, a description of typical population (of interest) eating behaviours, intakes or status of the intervention component, or associated dietary recommendations. This will also provide insights for meaningful inter-study comparisons, with often greater response to intervention anticipated in habitual low consumers of a beneficial dietary component. For example, for an omega-3 (EPA+DHA) intervention, a greater responsiveness of a range of health outcomes (omega-3 status, blood triglycerides, cognition) would be anticipated in a population or individual with a low versus high habitual intake and status, with interventions in replete individuals often resulting in little benefit. The VITAL study demonstrates this, with the impact of intervention on the composite cardiovascular endpoint and incident myocardial infarction only evident in those with a fish intake < 1.5 portions per week indicative of a low EPA+DHA intake and status.</p>
                            <p>A clear articulation of how the intervention is aligned with current behaviour, intake, values and preferences if known, and recommendations is also important from a nutrition policy or food product innovation perspective, with interventions which are more closely aligned with habitual intakes and recommendations, rather than more extreme diet intakes and eating behaviour changes, having a greater opportunity to realize impact.</p>
                            <p>Finally, as an overall measure of completeness of the introduction, the ‘population’ criterion in the PICO framework should be clearly identified, with a brief explanation and justification given for the choice of studied population, e.g. postmenopausal women, children, adults living with obesity etc.</p>
                        `,
                        nut_examples: `
                            <p>“When the calcium plus vitamin D trial of the Women’s Health Initiative (WHI) was designed, in the early 1990s, guidelines recommended daily intakes of 800 to 1200 mg of calcium with 400 IU of vitamin D for the prevention of osteoporosis. Many American women consumed less.” (Jackson et al., 2006).</p>
                            <p>“….and guidelines recommend reducing the daily dietary sodium intake to 100 mmol (equivalent to 2.3 g of sodium or 5.8 g of sodium chloride) or less…..Does reducing the level of sodium from the average intake in the United States (approximately 150 mmol per day, which is equivalent to 3.5 g of sodium, or 8.7 g of sodium chloride) to below the currently recommended upper limit of 100 mmol per day lower blood pressure more than reducing the sodium level only to the recommended limit?” (Sacks et al., 2001).</p>
                            <p>“Only 40% of four- to eight-year-old Dutch children meet the recommendation of the Dutch Nutrition Center to consume 100–150 g of vegetables and 1.5 servings of fruit per day.” (de Gooijer et al., 2024).</p>
                        `
                    },
                    {
                        id: '7',
                        title: 'Objectives',
                        text: 'Specific objectives related to benefits and harms',
                        consort_examples: `<p>“To evaluate whether a structured exercise programme improved functional and health related quality of life outcomes compared with usual care for women at high risk of upper limb disability after breast cancer surgery.”</p>`,
                        consort_explanation: `
                            <p>Objectives are the questions that the trial was designed to answer. Adequate reporting of the research question is essential to allow readers to appraise and interpret the trial results. The PICO framework, which requires defining the patient population (P); the experimental intervention (I); the comparator intervention or condition (C); and the outcome or outcomes (O) of interest, has been proposed to help define the research question. PICO is sometimes styled as PICOTS, to include T (the timeframe) and/or S (the setting).</p>
                            <p>Treatment decisions require an evaluation of the balance between benefit and harm; however, information about harms is frequently omitted or incompletely reported in published reports of trial results. Trials whose primary objective is to evaluate benefits of an intervention may not be powered to detect harms, but authors should still report whether they considered harms outcomes when planning the trial.</p>
                            <p>Authors should clarify whether the aim is to establish superiority of the experimental intervention, or non-inferiority or equivalence, as compared with the comparator intervention. Authors should also report whether the trial is intended to provide preliminary data (a pilot or feasibility trial), explore pharmacokinetic properties, or generate confirmatory results.</p>
                            <p>For multi-arm trials, authors should clarify which treatment group comparisons are of interest (eg, A v B; A v C). If authors planned to readjust the objective during the trial (eg, in some platform trials or basket trials), this should be reported. Finally, trials can be designed to study the effect of the experimental intervention under different conditions, often described on a spectrum from ideal conditions (explanatory trial) to standard clinical care conditions (pragmatic trial).</p>
                            <p>The objectives should be phrased using neutral wording (eg, “to compare the effect of treatment A versus treatment B on outcome X for persons with condition Y”) rather than in terms of a particular direction of effect. The trial objectives should align with what was specified in the trial registry and protocol; any changes to the trial objectives after it commenced should be reported with reasons (item 10).</p>
                            <p>Recently, some trials have been designed using the estimands framework to define the research question and trial objectives. While the terminology surrounding estimands may be new to some investigators, it is expected that the use of this framework will become more widespread.</p>
                        `
                    }
                ]
            },
            // --- METHODS ---
            {
                group: 'Methods',
                items: [
                {
                        id: '8',
                        title: 'Patient and public involvement',
                        text: 'Details of patient or public involvement in the design, conduct, and reporting of the trial',
                        consort_examples: `
                            <p>“A study patient advisory group advised on study design before funding, in study set-up, and during recruitment. They chose the term best current treatment and informed the design of clinic procedures (including how best to reduce the burden of intervention), questionnaire design, and participant information. This group informed protocol modifications in response to low recruitment, and guided interpretation of the findings. Two public contributors were members of the independent trial steering committee.”</p>
                            <p>“The UK Musculoskeletal Trauma Patient and Public Involvement (PPI) Group co-designed this study. In particular, the group advised on the choice of outcome measures and the follow-up arrangements, which were designed to limit the number of face-to-face hospital visits needed. Subsequently, a patient member from this group became a member of the DRAFFT2 Trial Management Group, overseeing all elements of the set-up and delivery of the trial and the dissemination of the lay summary at completion. Another patient member of the group was also a member of the independent Trial Steering Committee.”</p>
                            <p>“Office workers, workplace champions, and managers within the target organisation were involved in the study design during the grant application process and the study delivery phase. During the grant application phase, the purpose and design of the study as well as the suggested intervention strategies were presented to two large groups of council employees. As a result of these meetings, the study design included using finger prick blood testing rather than taking venous blood samples, participants receiving feedback on health measures, and incentives for attending follow-up. During the study set-up and delivery, a council employee advisory group met several times and provided advice on delivery of the interventions (feedback showed that workplace champions would not be comfortable delivering the initial education session because of the training and planning time required, so this session was delivered online instead), recruitment processes (feedback was provided on participant documents and recruitment messages and strategies within the council), installation of the height adjustable desk, and troubleshooting. Two council employees were also part of the trial steering committee, which met twice a year during the study”.</p>
                            <p>“In the context of the pandemic and the need to design the study in a short period, no patients were involved in setting the research questions or the outcome measures, nor were they involved in developing plans for recruitment, design, or implementation of the study. No patients were asked to advise on interpretation or writing up of results.”</p>
                        `,
                        consort_explanation: `
                            <p>Patient and public involvement (PPI) has been shown to be particularly beneficial in clinical trials. It can help researchers to identify and prioritise research topics and questions; identify relevant outcome measures; boost recruitment and retention; improve trial design and tools; and improve the acceptability of trials. PPI can also improve the communication and dissemination of the trial results to participants. Public involvement in other types of health research has been shown to help researchers to engage under-served populations and recruit diverse participant groups. Thus, transparent reporting of PPI is essential to allow readers to appraise the relevance and usefulness of findings to end users and to fully evaluate and understand a trial’s methodology and conduct. If patients and the public were not involved, authors should report this with the reasons why.</p>
                            <p>PPI in health research entails collaborating or partnering with patients and members of the public to design, conduct, report, interpret, or disseminate research: the research is done by or with patients and the public—rather than done for, at, or about them. Importantly, this is distinct from including patients or members of the public in a trial as participants. PPI contributors can be people with current or past experience of a health condition; their families, carers, and advocates; members of communities who are target users of an intervention or service; or members of the wider public with a broader perspective. The terminology used differs internationally: for example, such activity is most commonly known as “patient and public involvement” in the UK, whereas “patient engagement” is more common in mainland Europe and North America, “community and public engagement” is commonly used in part of Africa, and “consumer involvement” is frequently used in Australia.</p>
                            <p>The GRIPP (Guidance for Reporting Involvement of Patients and Public) checklist was developed in 2011 with the aim of improving the reporting of PPI activities in health research; followed in 2017 by GRIPP2. The GRIPP2 checklist includes GRIPP2-SF, which is a short form of the GRIPP2 checklist where PPI is the secondary focus of the research. Examples of reporting of PPI involvement could include whether and how patients were involved in the trial objectives, whether patients advised on optimising patient recruitment and retention, and whether and how patients were included in selection of the trial outcomes.</p>
                            <p>Funding bodies are increasingly encouraging or requiring researchers to include PPI in grant applications, but mandating of PPI reporting by journals has remained uncommon. In 2014, The BMJ introduced a requirement for submitted manuscripts to include a PPI statement, and this was extended to other BMJ journals from 2018. A 2023 study of trials addressing chronic conditions found that approximately 80% of trial reports published in these journals included a PPI subsection, and around 40% of these reported that PPI activities had been conducted. Few other journals have followed suit in mandating reporting of PPI activities. In the absence of an explicit requirement, reporting of PPI activities remains infrequent, appearing in an estimated 0-5% of published trial reports. There is limited evidence to indicate the extent to which this reflects a lack of PPI activity versus PPI activity being conducted but not reported.</p>
                        `,
                        nut_ext: 'No formal extension, but specific advice provided: Report interest-holder, patient and public consumer involvement (PPI) in the design, delivery, and dissemination.',
                        nut_explanation: `
                            <p>In addition to the CONSORT 2025 guidance, for nutrition trials and in particular eating behaviour interventions, PPI is beneficial for effective delivery and upholding moral and ethical considerations. Therefore, the following information should be reported in the manuscript if available. Firstly, describe the involvement of PPI in the design phase in order to ensure as much as possible, that the research question reflects real-world concerns and priorities, that the intervention is inclusive, e.g., by being culturally appropriate and practical, in terms of intervention goals, available food, portion sizes and food preferences, and that the study materials (e.g. questionnaires) are understandable and appropriate. Secondly, include any information on how PPI advised on recruitment strategies and the identification of barriers such as food insecurity or lack of cultural appropriateness, inclusion of undersampled populations to improve generalizability, and monitoring load, e.g. the completion of food diaries or questionnaires, biological sample collections, and clinical assessments. Finally report on how PPI was involved in the reporting, translation, and dissemination of the findings, to ensure they reach the public in an understandable way and pragmatically influence dietary guidelines and public health messaging. The GRIPP2 (Guidance for Reporting of Involvement of Patients and Public) is recommended for PPI reporting guidance.</p>
                        `,
                        nut_examples: `
                            <p>“The PPI [patient and public involvement] in this intervention development process is described according to the GRIPP2 SF (Guidance for Reporting Involvement of Patients and the Public (2nd version)- Short Form) sub-headings [50]…….What was involved for PPI Collaborators? (GRIPP2 SF Heading) – PPI were involved and will continue to be involved with various aspects of the study, however for the purposes of this paper we focused on the PPI input into the development of the intervention materials. During the adaptation of the 10TT intervention, the PPI collaborators were involved in shaping the intervention design and content via discussions, email, and written feedback for the following elements of the intervention” (McClelland et al., 2024).</p>
                            <p>“PPI members who represent young adults with a lived experience of the psychological impact of weight management (n=3) will be involved throughout the project. PPI members pretested and provided feedback on the survey, and going forward, findings from the study will be shared with PPI members and their interpretation of the findings considered alongside those of the research team. Their interpretation of the findings will be critical to our reporting and dissemination. For example, suggestions for research, policy and practice generated from study findings will be made in consultation with the PPI members”. (Whatnall et al., 2022).</p>
                            <p>“The co-design process engaged with these topics, exploring them in detail with a group of ‘lived experience’ stakeholders working toward design-based solutions that could address each topic. Since this study’s aim was to test the application of the co-design approach in intervention development, this paper will only focus on the diet aspects of T2D management. The co-design study had two objectives: (1) to co-design, with end-users, a digital dietary intervention to promote health behaviour change among adults at risk of T2D, and (2) to evaluate the co-design process involved in developing a digital dietary intervention prototype.” (PMID: 34763701)</p>
                        `
                    },
                    {
                        id: '9',
                        title: 'Trial design',
                        text: 'Description of trial design including type of trial (eg, parallel group, crossover), allocation ratio, and framework (eg, superiority, equivalence, non-inferiority, exploratory)',
                        consort_examples: `
                            <p>“This was a multicenter, stratified (6 to 11 years and 12 to 17 years of age), with imbalanced randomization [2:1], double-blind, placebo-controlled, parallel-group study conducted in the United States (41 sites).”</p>
                            <p>“This multicentre, pragmatic, superiority randomised trial compared three parallel groups for patients referred to secondary care for treatment of primary frozen shoulder, who were recruited from 35 hospital sites in the UK. Individual participants were randomly assigned with unequal allocation (2:2:1) to arthroscopic capsular release, manipulation under anaesthesia, or early structured physiotherapy, to allow for different effect sizes between groups.”</p>
                        `,
                        consort_explanation: `
                            <p>The word “design” is often used to refer to all aspects of how a trial is set up, but it also has a narrower interpretation. Many aspects of the broader trial design, including details of randomisation and blinding, are addressed elsewhere in the CONSORT checklist. This item refers to the type of trial (eg, parallel group or crossover) and the conceptual framework (eg, superiority, equivalence, or non-inferiority).</p>
                            <p>CONSORT 2025 focuses mainly on trials with participants individually randomised to one of two parallel groups. While many published trials have such a design, the main alternative designs are multi-arm parallel, crossover, cluster, and factorial designs, with each having their own specific CONSORT extensions. A detailed review of randomised trials published in PubMed in 2012 showed that of the 1122 trials, 953 (85%) were parallel group; the other main designs were crossover (n=98; 13%) and cluster (n=31; 3%). Of these 1122 trials, 892 (80%) had two groups, 146 (13%) had three groups, and 61 (5%) had four or more groups.</p>
                            <p>Most trials are designed to identify the superiority of a new intervention, if it exists, but others are designed to assess non-inferiority or equivalence. It is important that researchers clearly describe the design of their trial, including the unit of randomisation (eg, patient, general practice, lesion). These details should also be included in the abstract (item 1b).</p>
                            <p>If a less common design is used, authors should explain their choice, especially as such designs may imply the need for a larger sample size or more complex analysis and interpretation. Although most trials use equal randomisation (eg, 1:1 for two groups), it is also helpful to provide the allocation ratio explicitly.</p>
                        `,
                        nut_ext: 'Description of how the trial design aligns with the research question. Explanation of duration and its appropriateness for the outcomes',
                        nut_explanation: `
                            <p>The design of a human nutrition RCT must be appropriate for the research question to be answered. Every decision made in the design and execution of human trials influences the relevance and applicability of the study’s results. The objective is to produce high-quality, ethically sound data while maximizing the generalizability of the findings and upholding scientific integrity.</p>
                            <p>The length of the intervention period and its appropriateness for measuring outcomes should be determined by the predicted duration required to see a biologically or clinically relevant and statistically significant change. This should be clearly reported. For example, a dietary intervention aiming to increase bone mineral density, should not be of fewer than 12 months duration given the slow and gradual process of bone density. Some outcomes may reach a threshold and plateau (erythrocyte fatty acid status) while other outcomes may change in a linear manner (e.g. body weight).</p>
                            <p>Crossover trials can be an efficient design and often used in nutrition trials. A critical assumption of this design is that the effects of the intervention from the first period do not carryover and influence the outcomes in the next period. Authors should explicitly state how they addressed this assumption. For guidance on reporting these and other design and statistical elements of crossover trials, investigators should follow the CONSORT-crossover extension.</p>
                        `,
                        nut_examples: `
                            <p>“Epidemiological evidence shows that non-Mediterranean populations with a priori measured high adherence to a MedDiet have lower risk of CVD [11,18]. … It has been suggested that the adaptability and variety of the diet makes it transposable to non-Mediterranean countries [18–20]. The limitation of the meta-analysis is the inclusion of observational studies only. There are few longer term intervention trials to assess how successfully non-Mediterranean populations can change their diets. Consequently, it remains unknown whether it is plausible for regions beyond the Mediterranean Sea to adopt the MedDiet. Barriers may include cultural beliefs, palatability, food access, cost, time for food preparation/shopping, and environment (for example proximity to fast food restaurants and access to discretionary foods) [21]. Whether the Australian population can adopt the MedDiet ad libitum over the longer term is unknown. We conducted a randomised controlled intervention trial in an older Australian population to determine how well this population could adopt the MedDiet in 6 months. The primary outcome for this study is adherence to the MedDiet… .” (Davis et al., 2017)</p>
                            <p>“Two weeks of dietary change appears to be sufficient time for equilibration of linoleic acid (18:2n–6) in plasma lipid fractions (16, 17). However, the duration of trials has been too short to establish the time to equilibration in erythrocytes and no trials have been undertaken to explore whether administering the diets in the reverse order (i.e. n–6 PUFA- to SFA-rich diet) results in the opposite changes in FA composition in plasma, blood, and tissue lipids. … Although we have demonstrated the FA composition of erythrocytes reflected the change in dietary fat within days, the time frame of the study (19 d) did not provide the opportunity to examine if further, albeit subtle, changes occurred. Determining when equilibrium is achieved will provide a more robust understanding of the time frame the lipid pool is reflecting. The aims of the present study were to compare, using a randomized crossover design, changes over time during two 8-wk diet periods (SFA-rich, and n–6 PUFA-rich) in the abundance of specific FAs [pentadecanoic acid (15:0) and linoleic acid of plasma, erythrocytes, buccal (cheek) cells, and adipose tissue lipids] to: 1) determine the usefulness of buccal cells as biomarkers of SFAs and n–6 PUFAs; and 2) assess if erythrocytes can be considered a superior long-term biomarker of dietary intake compared with plasma lipid fractions.” (Hodson et al., 2014)</p>
                        `
                    },
                    {
                        id: '10',
                        title: 'Changes to trial protocol',
                        text: 'Important changes to the trial after it commenced including any outcomes or analyses that were not prespecified, with reason',
                        consort_examples: `
                            <p>“The original primary endpoint was all-cause mortality, but, during a masked analysis, the data and safety monitoring board noted that overall mortality was lower than had been predicted and that the study could not be completed with the sample size and power originally planned. The steering committee therefore decided to adopt co-primary endpoints of all-cause mortality (the original primary endpoint), together with all-cause mortality or cardiovascular hospital admissions (the first prespecified secondary endpoint).”</p>
                            <p>“As described in the published protocol paper, a protocol amendment was made to revise the sample size in response to new information on the minimal clinically important difference of the primary outcome measure, the Patient-Oriented Eczema Measure (POEM). Our original sample size used a POEM score for minimal clinically important difference of 3, which was based on research carried out in secondary care among people with moderate or severe eczema. Fresh evidence, however, suggested that a change in POEM score of 2.1 to 2.9 represents a change likely to be beyond measurement error. A protocol amendment was therefore made to change the target sample size for the trials based on seeking to detect a difference in POEM score of 2.5 points between groups, increasing the target sample size from 200 to 303 for each trial.”</p>
                        `,
                        consort_explanation: `
                            <p>A protocol for a randomised trial serves as the foundation for planning, conduct, reporting, and appraisal, specifying in detail how the trial will be conducted. There may be deviations from the original protocol, as it is impossible to predict every possible change in circumstances during the course of a trial. Some trials will therefore have important changes to the methods after trial commencement. There are many reasons for deviations from the initial study protocol; for example, changes could be due to external information becoming available from other studies, or internal financial difficulties, or lower than anticipated recruitment rates. In some trials, an independent data monitoring committee will have as part of its remit the possibility of recommending protocol changes based on seeing unblinded data. Authors should report the nature and timing of protocol changes because changes made at different times (eg, before or after breaking the blinding) might be associated with different risks of bias.</p>
                            <p>Authors should report all major changes to the trial after it commenced indicating the reason for the changes and when the changes occurred. Such changes might affect the trial methods, such as the randomisation ratio, eligibility criteria, interventions, outcomes, method of analysis or duration of follow-up; or might affect the trial conduct, such as dropping a trial site with poor data quality.</p>
                            <p>Some trials are set up with a formal adaptive design, which allows pre-planned changes to an ongoing trial without compromising the validity of conclusions. It is therefore essential to distinguish pre-planned changes from unplanned changes that may also occur. Such adaptive trial design modifications are usually to the sample size and number of treatment groups, and can lead to decisions being made more quickly and with more efficient use of resources than would be possible with traditional, non-adaptive parallel group trials. Specific guidance has been developed for reporting trials with a formal adaptive design; authors could consult this for more detailed information.</p>
                            <p>Most trials record multiple outcomes, with the risk that results will be reported for only a selected subset. Prespecification and reporting of completely defined primary and secondary outcomes for both benefits and harms (item 14) should remove such a risk. In some trials, however, circumstances require a change in the way an outcome is assessed, the designation of outcomes as primary or secondary or even, as in the example above, a switch to a different outcome. For example, there may be external evidence from other trials or systematic reviews suggesting the time point for the primary outcome might not be appropriate; or recruitment or the overall event rate in the trial may be lower than expected. Changing an endpoint based on unblinded data are much more problematic, although may be specified in the context of an adaptive trial design.</p>
                            <p>Whether the modifications are explicitly part of the trial design or in response to changing circumstances, it is essential that they are fully reported and the reason for the change explained to help the reader interpret the results. Such information is not always reported. A comparison of protocols and publications of 102 randomised trials found that 62% of trial reports had at least one primary outcome that was changed, introduced, or omitted compared with the protocol. Primary outcomes also differed between protocols and publications for 40% of a cohort of 48 trials funded by the Canadian Institutes of Health Research. None of these subsequent 150 trial reports mentioned, let alone explained, changes from the protocol. Similar results from other studies have been reported in a systematic review of empirical studies, comparing trial registers or protocols to published trial reports.</p>
                        `                     },
                        {
                        id: '11',
                        title: 'Trial setting',
                        text: 'Settings (eg, community, hospital) and locations (eg, countries, sites) where the trial was conducted',
                        consort_examples: `
                            <p>“The study was conducted in paediatric diabetes services experienced in the use of CSII [continuous subcutaneous insulin infusion], in nine University and six local hospitals within the NHS in England and Wales.”</p>
                            <p>“Setting: One large health board area with a materially deprived, inner city population in the west of Scotland, United Kingdom. Although described as a single centre, NHS Greater Glasgow and Clyde has the largest health board population (1.2m) in the United Kingdom. It is spread over a wide geographical area including severely materially deprived post-industrial areas as well as some more affluent communities. Maternity booking and antenatal care are provided in both hospital and local healthcare settings. Delivery (13 844 infants in 2013[reference]) takes place in three major maternity hospitals.”</p>
                        `,
                        consort_explanation: `
                            <p>Along with the eligibility criteria for participants (item 12a) and the description of the interventions (item 13), information on the settings and locations where the trial was conducted is crucial to enable readers to judge the applicability and generalisability of a trial. Were participants recruited from primary, secondary, or tertiary healthcare, or from the community? Healthcare institutions vary greatly in their organisation, experience, and resources and the baseline risk for the condition under investigation. Other aspects of the setting, including the social, economic, and cultural environment, might also affect a study’s external validity.</p>
                            <p>Authors should report the number and type of settings and describe the care providers involved. They should report the locations in which the study was carried out, including the country, city if applicable, and immediate environment (eg, community, general practice, hospital outpatient clinic, or inpatient unit). In particular, it should be reported whether the trial was carried out in one site (single centre trials) or several sites (multicentre trials). The description of the setting should provide enough information so that readers can judge whether the results of the trial could be relevant to their own setting. The environment in which the trial is conducted might differ considerably from the setting in which the trial’s results are later used to guide practice and policy. Authors should also report any other information about the settings and locations that could have influenced the observed results.</p>
                        `,
                        nut_ext: 'No formal extension, but specific advice provided: Describe if participants were domiciled/supervised or if meals were packed out/honor system.',
                        nut_explanation: `
                            <p>There is no extension for item 11 pertaining to nutrition trials. However, authors are advised to keep in mind that for human nutrition trials, it is crucial to describe where interventions were delivered. Furthermore, it should be described if participants were domiciled so that eating occasions could be supervised or if meals were packed out and participants expected to comply using an honor system.</p>
                        `,
                        nut_examples: `
                            <p>“The boys and girls were housed in a campus residence hall converted into a metabolic unit for two 3-week balances in the summer separated by a 1-week washout when they returned to their homes. During the balance, participants were scheduled for a variety of educational and recreational activities coordinated as a summer-camp environment. The first 7 days of each balance served as equilibration to the basal diet, and the last 14 days served as the study. All meals, snacks, and beverages were provided.” (Wu et al., 2010).</p>
                        `
                    },
                    {
                        id: '12a',
                        title: 'Eligibility criteria',
                        text: 'Eligibility criteria for participants',
                        consort_examples: `<p>“Patients aged 18 years or older were recruited from 20 UK National Health Service (NHS) trusts. Patients were eligible if they had a diagnosis of shoulder pain attributable to a rotator cuff disorder (eg, cuff tendonitis, impingement syndrome, tendinopathy, or rotator cuff tear) that had started within the past 6 months. We used the diagnostic criteria set out in the British Elbow and Shoulder Society (BESS) guidelines. Patients were excluded if they had a history of significant shoulder trauma (eg, dislocation, fracture, or full-thickness tear requiring surgery), neurological disease affecting the shoulder, other shoulder conditions (eg, inflammatory arthritis, frozen shoulder, or glenohumeral joint instability), received corticosteroid injection or physiotherapy for shoulder pain in the past 6 months, or were being considered for surgery. Detailed criteria are in the protocol.”</p>`,
                        consort_explanation: `
                            <p>A comprehensive description of the eligibility criteria used to select the trial participants is needed to help readers interpret the study. In particular, all inclusion and exclusion criteria should be reported to judge to whom the results of a trial apply—that is, the trial’s generalisability (applicability) and relevance to clinical or public health practice (item 30). A description of the method of recruitment, such as by referral or self-selection (eg, through advertisements) is also important in this context. Because they are applied before randomisation, eligibility criteria do not affect the internal validity of a trial, but they are central to its external validity.</p>
                            <p>Typical and widely accepted selection criteria relate to the nature and stage of the condition or disease being studied, the exclusion of persons thought to be particularly vulnerable to harm from the study intervention, and to issues required to ensure that the study satisfies legal and ethical norms. The informed consent of study participants, for example, is typically required in intervention studies. Where relevant, it is important to describe whether sex and/or gender were taken into account in the design of the trial, including whether there was adequate representation of men and women (or diverse genders), and justify the reasons for any exclusion.</p>
                            <p>Despite their importance, eligibility criteria are often not reported adequately. For example, in an analysis of 283 reports of trials published between 1994 and 2006 in high impact general medical journals, reporting of exclusion criteria was often poor and incomplete: 84% of published trials contained at least one poorly justified exclusion criteria, and in 61% more than a quarter of the trial’s exclusion criteria were poorly justified. Any differences in eligibility criteria between the trial protocol and final publication should also be highlighted and reasons for any discrepancies reported. A review of 52 protocols and 75 subsequent full publications submitted to a German medical ethics committee between 2000 and 2006 identified modifications to the eligibility criteria for 85% of trial publications, with 41% of final publications containing newly added criteria. Similar deficiencies have been found in other studies.</p>
                        `,
                        nut_ext: 'Target population(s) and their dietary, physiological or nutritional characteristics. Eligibility criteria related to baseline nutritional status (anthropometric, biochemical, clinical or medical, diet, food allergies), if relevant.',
                        nut_explanation: `
                            <p>The context of the target population requires more explanation for human nutrition studies as background or habitual diet can provide a wide range of exposure to the food, supplement or nutrient/bioactive being studied, which can affect the responsiveness to intervention and the interpretation of the results. Reporting on the population selected for study should align with the aims of the study. For an efficacy study, the intervention might target populations at risk to show maximum benefit. For example, the Dietary Approaches to Stop Hypertension (DASH) trial recruited participants who had higher than normal blood pressure to determine if dietary interventions could reduce blood pressure. If the aim of the study is to determine effectiveness of an intervention in the general population, a much larger and generally representative population may be recruited. For example, the VITamin D and Omega-3 Trial (VITAL) tested omega-3 fatty acids and vitamin D supplementation on prevention of cardiovascular disease and cancer.</p>
                            <p>Baseline nutritional status or exposure is especially important to consider in nutrition studies for interpretation of outcome measures. In the DASH study, there were two interventions; sodium reduction and improved diet quality. Baseline urinary sodium values showed that the groups assigned to control and intervention were similar and above the recommended intakes for sodium typical of a Western diet. This study used 24-hour urinary sodium levels to estimate sodium intake, the preferred biomarker for dietary salt intake. In contrast, the components of the higher quality diet represented by the DASH diet are not known making it difficult to assess background diet quality. Thus, with one strong marker of diet exposure and one weak marker of exposure, the investigators chose to compare end of treatment blood pressure values and made no adjustments for baseline diet exposure.</p>
                        `,
                        nut_examples: `
                            <p>“To be eligible, participants had to be at least 22 years old and to have an average systolic blood pressure on at least three screening visits of 120 to 159 mmHg and an average diastolic blood pressure of 80 to 95 mmHg.  We targeted an enrollment that was 50 percent blacks and 50 percent women.  The criteria for exclusion was heart disease, renal insufficiency, poorly controlled hyperlipidemia or diabetes mellitus, diabetes requiring insulin, special dietary requirements, intake of more than 14 alcoholic drinks per week, or the use of antihypertensive drugs or the use of other medications that would affect blood pressure or nutrient metabolism.” (Sacks et al., 2001).</p>
                            <p>“Using flavanols as a model dietary intervention and a set of recently validated flavanol biomarkers, we here investigated the impact of background diet and adherence on the outcomes of a subcohort of the COcoa Supplement and Multivitamin Outcomes Study (COSMOS, NCT02422745). We found that 20% of participants in the placebo and cocoa-extract intervention arms had a flavanol background intake as high as the intervention, and only 5% did not consume any flavanols. Approximately 33% of participants in the intervention group did not achieve expected biomarker levels from the assigned intervention… Taking these factors into account resulted in a larger effect size for all observed endpoints… These results highlight the importance of taking background diet and adherence into consideration in RCTN to obtain more reliable estimates of outcomes through nutritional biomarker-based analyses.” (Ottaviani et al., 2025).</p>
                        `
                    },
                    {
                        id: '12b',
                        title: 'Eligibility criteria',
                        text: 'If applicable, eligibility criteria for sites and for individuals delivering the interventions (eg, surgeons, physiotherapists)',
                        consort_examples: `<p>“All participating centres . . . were major neurosurgical centres, treating large numbers of patients after aneurysmal subarachnoid haemorrhage (SAH), each centre treating between 60 and 200 cases annually . . . Centres had to have expertise in both neurosurgical and endovascular management of ruptured aneurysms. Only accredited neurosurgeons with experience of aneurysm surgery were permitted to manage patients in the trial. Endovascular operators had to have done a minimum of 30 aneurysm treatment procedures, before they were permitted to treat patients in the trial”.</p>`,
                        consort_explanation: `
                            <p>For all types of trials, it is important to define the eligibility criteria for clinical sites, and to consider the characteristics of the treatment providers who will provide both the experimental and comparator interventions. Evidence suggests that patient outcomes can be associated with hospital and care provider volume. A systematic review of 135 trials found that 71% observed a positive association between hospital volume and outcomes, and 70% observed an association between care provider volume and outcomes. Different levels of expertise of care providers in each intervention group can bias treatment effect estimates. Furthermore, an intervention might be found to be safe and effective in a trial performed in high volume sites by high volume care providers but could have different results in low volume sites. For example, in an analysis of Medicare National Claim files of 167 208 patients who had undergone coronary stent surgery, patients treated by high volume physicians and at high volume sites experienced better outcomes than those treated by low volume physicians at low volume sites. Similar studies show that in most non-pharmacological trials, care provider expertise and site volume will influence treatment effects.</p>
                            <p>Eligibility criteria for care providers and sites are often poorly reported. A systematic review of randomised trials in surgery found that the setting and the site volume of activity were reported in only 7% and 3% of articles, respectively. Eligibility criteria were reported for care providers in 41% of the articles, and the number of care providers performing the intervention was reported in 32%. A careful description of care providers involved in the trial, as well as details of the sites in which participants were treated, helps readers appraise the risk of bias and the applicability of the results. Eligibility criteria for sites typically relate to site volume for the procedure under investigation or similar procedures. Eligibility criteria for care providers might include professional qualifications, years in practice, number of interventions performed, skill as assessed by level of complication when performing the intervention, and specific training before trial initiation. Exclusion criteria should be justified because they will influence the applicability of the trial results.</p>
                        `,
                        nut_ext: 'No formal extension for item 12b pertaining to nutrition trials. However, authors are advised to keep the specific advice below in mind while reporting trial findings.',
                        nut_explanation: `
                            <p>For nutrition trials it is important to state the location where the intervention was delivered, e.g. community setting, clinical trial unit, primary or secondary care, residential care unit, workplace, school, multi-site trial etc. and include the eligibility criteria for site selection (if relevant). For individuals delivering the intervention, any eligibility requirement should be articulated such as education, certification, accreditation and training requirements (e.g. degree/registration in dietetics, nutrition, psychology or health coaching or completed a related course), relevant experience (e.g. lived experience for peer-delivered interventions) or exclusion criteria.</p>
                        `,
                        nut_examples: `
                            <p>“We did this open-label, cluster-randomised trial at 49 primary care practices in Scotland and the Tyneside region of England. General practices (GPs) representing populations with a wide range of social and geographic features were invited to participate by the Primary Care Research Network (PCRN) in Scotland, and North East Commissioning Support in Tyneside. …. There were no specific eligibility criteria for practices.” (Lean et al., 2018)</p>
                            <p>“A nurse or dietitian (as available locally) in each intervention practice was given a total of 8 h structured training by the study research dietitians experienced in Counterweight-Plus. Training followed a standard protocol, to minimise variability and maintain fidelity across all practices. Mentoring of nurses and dietitians was done by the study research dietitians during each stage of the intervention, with feedback as required.” (Lean et al., 2018)</p>
                        `
                    },
                    {
                        id: '13',
                        title: 'Intervention and comparator',
                        text: 'Intervention and comparator with sufficient details to allow replication. If relevant, where additional materials describing the intervention and comparator (eg, intervention manual) can be accessed',
                        consort_examples: `
                            <p>“Each sulfadoxine–pyrimethamine course consisted of three tablets containing 500 mg of sulfadoxine and 25 mg of pyrimethamine (unbranded generic sulfadoxine–pyrimethamine, Medopharm, Chennai, India; quality controlled by Durbin, Hayes, UK) given as a single oral dose for 1 day (appendix p 2). Each dihydroartemisinin–piperaquine course was dosed according to the bodyweight of each participant and consisted of three to five tablets containing 40 mg of dihydroartemisinin and 320 mg of piperaquine (Alfasigma, Bologna, Italy), given orally once a day for 3 consecutive days. Each dose of azithromycin consisted of two tablets containing 500 mg (Universal Corporation, Nairobi, Kenya) given orally once daily for 2 consecutive days (cumulative dose of 2 g) at the same time as the first and second daily dose of dihydroartemisinin–piperaquine at enrolment. The placebo tablets were also provided by Universal Corporation and had the same appearance as active azithromycin (appendix p 2). The first daily dose was administered in the study clinic under the direct supervision of the study staff, combined with a slice of dry bread or a biscuit. The daily doses on the second and third days were self-administered at home at approximately the same time of the day and in a similar manner as the first dose taken under observation in the clinic.”</p>
                            <p>“The experimental group received 6 sessions of standard OMT (osteopathic manipulative treatment), and the control group 6 sessions of sham OMT, each session at 2-week intervals. For both experimental and control groups, each session lasted 45 minutes and consisted of 3 periods: (1) interview focusing on pain location, (2) full osteopathic examination, and (3) intervention consisting of standard or sham OMT. Briefly, in both groups, practitioners assessed 7 anatomical regions for dysfunction (lumbar spine, root of mesentery, diaphragm, and atlantooccipital, sacroiliac, temporomandibular, and talocrural joints) and applied sham OMT to all areas or standard OMT to those that were considered dysfunctional. All health care providers were board-certified nonphysician, nonphysiotherapist osteopathic practitioners (Répertoire National de la Certification Professionnelle, niveau 1). They all received a 2-day training according to international standards to deliver both standard and sham OMT. Full descriptions of osteopathic practitioner training and interventions are provided in eAppendices 3 and 4 in Supplement 2. In both groups, pharmacological interventions, nonpharmacological interventions, and spinal surgery were allowed. Cointerventions were self-reported at 3, 6, and 12 months by use of a standardized checklist (eAppendix 5 in Supplement 2).”</p>
                        `,
                        consort_explanation: `
                            <p>Complete reporting of the intervention and comparator details is essential to enable readers to understand the study results and adequately translate them to clinical practice. Several studies have shown poor reporting of interventions and comparators in randomised trials. Authors should describe each intervention thoroughly, including control interventions, or use of placebo procedure. The description should provide sufficient detail to allow replication, such as to allow a clinician wanting to use the intervention to know exactly how to administer the intervention/comparator that was evaluated in the trial. Key information includes the different components of the intervention/comparator, how and when it should be administered, the intervention/comparator material (ie, any physical or informational materials used in the intervention/comparator, including those provided to participants or used in intervention/comparator delivery or in training of providers and where it can be accessed (eg, online appendix, URL)); the procedure for tailoring the intervention/comparator to individual participants, and how fidelity (ie, the extent to which the intervention/comparator were implemented as planned in the protocol by care providers) or adherence (ie, the extent to which trial participants implement the intervention/comparator as planned in the protocol) were assessed or enhanced.</p>
                            <p>Assessing fidelity and adherence can be complex and vary according to the intervention/comparator (eg, one-off, short term repeated, long term repeated). Various deviations to the protocol can occur. For example, participants might initiate the intervention but then discontinue the intervention completely and permanently after a specific period of time, discontinue the intervention temporarily, reduce the dose, or modify the schedule. If relevant, authors should provide the prespecified definition for classifying participants as being treated as planned or not.</p>
                            <p>In addition, authors should indicate whether criteria were used to guide intervention/comparator modifications and discontinuations and where applicable describe these criteria. This information could be particularly important to evaluate the risk of bias due to deviations from the intended interventions, an important domain of the risk-of-bias tool developed by Cochrane. Assessing this domain requires a clear understanding of, and ability to distinguish between, deviations that occur as planned in the protocol and deviations that arise due to the experimental context.</p>
                            <p>The research question (ie, explanatory v pragmatic) will affect the standardisation of the intervention/comparator as well as how adherence or fidelity is assessed or enhanced. In explanatory trials, the aim is to estimate treatment effect under ideal circumstances. The intervention/comparator are usually highly standardised with close monitoring of fidelity and adherence to the intervention/comparator and strategies to increase them. In contrast, pragmatic trials aim to determine treatment effect in clinical conditions. The intervention and comparator are usually highly flexible, and measurement of fidelity and adherence are unobstructive with no strategies to maintain or improve them. Nevertheless, assessing fidelity and adherence to the intervention/comparator, or at least recording the most important components of the intervention/comparator, is necessary to understand what was actually administered to participants. This is particularly important for complex interventions where diversity in the implementation of the intervention is expected. For example, in a pragmatic trial assessing a surgical procedure where the procedure is left to surgeons’ choice, investigators should plan to systematically record key elements related to pre-operative care, anaesthesia, the surgical approach, and post-operative care. This information is essential to provide a relevant description of the intervention that was actually provided when the trial is completed.</p>
                            <p>If the control group or intervention group received a combination of interventions, the authors should provide a thorough description of each intervention, an explanation of the order in which the combination of interventions were planned to be introduced or withdrawn, and the triggers for their introduction if applicable. Some complex interventions will require the development of specific documentation (eg, training materials, intervention manuals). Authors should make these available and indicate where they can be accessed.</p>
                            <p>If the control group is to receive usual care, it is important to describe what that constitutes so that readers can assess whether the comparator differs substantially from usual care in their own setting. Various approaches could be used: standardising usual care to be in line with specific guidelines; or asking practitioners to treat control patients according to their own preference, which could result in heterogeneity of the care provided particularly between centres and over time. Usual care can vary substantially across sites and patients, as well as over the duration of the trial. Further, it is important to clarify if the experimental group also received usual care in addition to the experimental intervention, and what actually differed between the groups. Usual care is frequently incompletely reported. In a review of 214 paediatric trials, the descriptions of standard of care were more often incomplete than the description of the intervention arms within the same study as measured by the TIDieR checklist.</p>
                            <p>If the control group is to receive a placebo, specific considerations need to be accounted for. Some evidence showed that placebos are insufficiently described. Placebo could have several different aspects from pills to saline injections or more complex interventions such as sham interventions (eg, sham surgery) or attention control interventions. Authors should report the same level of details as required for the intervention—that is, content of the placebo or different component of the placebo, how and when it should be administered, material, procedure for tailoring the placebo to individual participants, and how fidelity and adherence were assessed or enhanced. Complete reporting of the placebo is needed to understand what intervention effect is measured in the trial. A network meta-analysis of osteoarthritis trials showed that different placebo interventions (oral, intra-articular, topical, oral and topical) had different effects and can impact the relative effect estimate of active treatments.</p>
                            <p>Further, the trial groups could receive different concomitant care in addition to the assigned trial interventions. Concomitant care could impact trial outcomes and bias effect estimates. To facilitate interpretation of study results and risk-of-bias assessments, authors should report relevant concomitant care that was allowed or prohibited where relevant.</p>
                            <p>Specific guidance has been developed to improve the reporting of interventions, particularly TIDieR, TIDieR-Placebo for placebo and sham controls, and the CONSORT extensions for non-pharmacological treatments. Authors could consult these for more detailed information.</p>
                        `,
                        nut_ext: `
                                <br />(i) Dietary comparators, including details if equal in bioactive compound, energy, nutrient, food/food group, dietary pattern or eating behaviour, as applicable
                                <br />(ii) Details of the diet-related intervention, including its cultural appropriateness, if relevant
                                <br />(iii) Description of dose, how it was prepared, stored, administered, and analysed for bioactive compound(s), storage stability, and biological exposure, if relevant. For behavioural interventions, a description of the protocol development process and how it was implemented
                                <br />(iv) Describe background dietary assessment carried out
                        `,
                        nut_explanation: `
                            <p>CONSORT recommends that interventions for each group be described in sufficient detail to allow replication. The example from Hodges et al. (2023) illustrates the rigor expected for a study of a bioactive supplement for developing the product, validating the bioactive compound(s) in the intervention and subsequent exposure to the participants consuming the product, and storage and stability testing of the intervention.</p>
                            <p>Describing the comparator in detail is too often given insufficient attention. For studies of dietary patterns or macronutrient substitution in particular, a description of the comparator may be as important as the intervention in order to understand causal relationships. Further, some interventions are designed without explicit substitutions, and it is important that dietary assessment methods are described in detail to evaluate what dietary changes were made in response to the intervention when important to the interpretations of the effects. Finally, the background nutrient status throughout the intervention is crucial to the research question (i.e., if the intent is to contrast an intervention against background intake, or evaluate an intervention in the general population that may differ in nutrient status compared to targeted populations) and interpretation of potential intervention effects (PMID: 40771508). For another example, in a subgroup of the COcoa Supplement and Multivitamin Outcomes Study, 20% of participants in the placebo and intervention arms had a flavanol background dietary intake as high as the intervention. This influenced the effect sizes of outcomes in intention to treat vs per protocol analyses (Ottaviani et al., 2025). The TiDieR checklist can be used to guide elements to include an intervention for better replication, but it is not specific to nutrition trials (Hoffmann et al., 2014).</p>
                        `,
                        nut_examples: `
                            <p>“... the intervention consisted of three dose levels (low: 17.5 g/d, medium: 35 g/d, and high: 70 g/d) of freeze-dried whole blueberry powder incorporated into three products: a drink, a spread, and granola bites (cubic bars) consumed as part of a self-selected diet. Considerable product development efforts were undertaken to formulate products that did not require heat for preparation (high temperatures may degrade certain bioactive constituents), were palatable at the provided doses of blueberry powder (equivalent to 0, 1.5, and 3 cups of whole blueberries), and practical for consumer use with minimal preparation and storage requirements. Importantly, we also verified stability of the polyphenol profile in the freeze-dried blueberry powder and the intervention products throughout the study. The concentration of total polyphenols in freeze dried powder was 35.2 ± 0.6 mg/g, which was consistent with data provided by the manufacturer. The concentration of total polyphenols in the intervention products ranged from 522 to 613 mg per each low-dose serving indicating that processing lowered the concentration by <20%. Participants taste tested all products prior to study initiation.” (Weaver & Hodges, 2021)</p>
                            <p>“The intervention products were provided in a double-blind manner between February and November 2018. Products were coded by research staff prior to dispensing them to the participants by the study coordinator. Unconsumed foods were collected weekly during each intervention to monitor adherence. Participants received a list of polyphenol-rich foods to avoid and/or limit. Participants were instructed to complete a 4-d dietary record at the end of baseline and each intervention and washout period to quantify habitual intakes of energy and bone-relevant nutrients. Polyphenolics and their metabolites, including total phenolics, flavanols, phenolic acids, and anthocyanin metabolites, were assessed, as previously described, in 24-h urine collected at the end of baseline and each intervention period and normalized to creatinine to assess participant adherence to study protocol.” (Hodges et al., 2023)</p>
                            <p>“The first 24 weeks of the study comprised an intensive intervention period, during which participants in the MD and MD+PA arms were encouraged to change their behaviour via a combination of personalised goals, a web-based intervention, group sessions with facilitators trained in behaviour change techniques and supermarket vouchers or food delivery to support behaviour change….The intervention targets were to improve MEDAS scores by at least three points and increase levels of activity to 150 min of moderate, or 75 min of vigorous, activity per week. Participants were encouraged to select their own goals to meet these targets, which were introduced in a gradual process… . The web-based intervention was administered via an interactive, modular platform called LEAP2, as described elsewhere”. (Jennings et al., 2024)</p>
                        `
                    },
                    {
                        id: '14',
                        title: 'Outcomes',
                        text: 'Prespecified primary and secondary outcomes, including the specific measurement variable (eg, systolic blood pressure), analysis metric (eg, change from baseline, final value, time to event), method of aggregation (eg, median, proportion), and time point for each outcome',
                        consort_explanation: `
                            <p>All randomised trials assess outcomes, for which the groups are compared. Most trials have several outcomes, some of which are of more importance than others. The primary outcome is the prespecified outcome considered to be of greatest importance to relevant stakeholders (such as patients, policy makers, clinicians, and funders) and should be the one used in the sample size calculation (item 16). The primary outcome should be explicitly indicated as such in the report of a randomised trial. Other outcomes of interest are secondary outcomes.</p>
                            <p>It is important to explain the rationale and clinical relevance for chosen efficacy and harm outcomes, including whether they are part of a core outcome set. A core outcome set is an agreed standardised set of outcomes that should be measured and reported, as a minimum, in all clinical trials in specific areas of health or health care. The COMET (Core Outcome Measures in Effectiveness Trials) initiative and COMET database facilitate access to core outcome sets.</p>
                            <p>Most trials have a single primary outcome. Having several primary outcomes can incur potential problems of interpretation associated with multiplicity of analyses (items 28 and 30). There are typically multiple secondary outcomes (ie, the outcomes prespecified in the trial protocol to assess any additional effects of the intervention). Secondary outcomes can include harms that may include unintended effects of the intervention (item 27).</p>
                            <p>The primary and secondary outcomes reported should be consistent with the outcomes prespecified in the trial protocol and the registry. Evidence shows important discrepancies between the outcome reported in the registry or protocol and outcomes reported in final publications, frequently in favour of statistically significant results. Any change in outcome(s) specified in the protocol should be reported, with reasons (item 10).</p>
                            <p>All outcomes, whether primary or secondary, should be described and completely defined. This information is typically also detailed in the trial’s protocol and the trial registry. The principle here is that the information provided should be sufficient to allow others to use the same outcomes. For each outcome, it is important to detail: (1) the specific measurement variable, which corresponds to the data collected directly from trial participants (eg, Beck Depression Scale; all cause mortality) with definition where relevant (eg, major bleeding was defined as fatal bleeding or symptomatic bleeding in a critical area or organ; all cause mortality per hospital database); (2) the specific participant level analysis metric, which corresponds to the format of the outcome data that was used from each trial participant for analysis (eg, change from baseline; final value or value at a time point; time to event); (3) the method of aggregation, which refers to the summary measure format for each trial group (eg, mean; proportion of participants with score >2); and (4) the measurement time point of interest for analysis. For composite outcomes, all individual components of the composite outcome should be described as secondary outcomes. Only half of randomised trials published in PubMed indexed journals in 2000 and 2006 specified the primary outcome. In recent samples of trials published in specific fields, reporting has improved but still two thirds did not provide a complete definition.</p>
                            <p>The use of previously developed and validated scales can help to enhance quality of measurement. For example, assessment of health related quality of life using a validated instrument is critical to the integrity and applicability of the trial. Authors should report measurement properties of outcome measurement instruments to assist in interpretation and comparison with similar studies.</p>
                            <p>In most trials, information on outcomes is set to be collected as part of the trial conduct. However, some trials may use existing data collecting structures (eg, national, healthcare or administrative registries). This should be clarified in the methods. There is empirical evidence that treatment effect estimates may be different in trials where outcomes are obtained from routinely collected data.</p>
                        `,
                        nut_ext: 'Describe how adherence, acceptability and tolerance of intervention were assessed, where relevant',
                        nut_explanation: `
                            <p>As with all RCTs, nutrition trials should explicitly state all recommended elements of the prespecified primary (which forms the basis of the sample size calculation) and secondary outcome definitions, which should be clearly aligned with the objectives and hypotheses. CONSORT 2025 requests for each outcome: “the specific measurement variable (eg, systolic blood pressure), analysis metric (eg, change from baseline, final value, time to event), method of aggregation (eg, median, proportion), and time point”. If outcomes are assessed at multiple time points which are not aggregated in the analysis, the pre-specific time point of primary interest should be stated and justified. An intervention period that is too short runs the risk of a false negative finding and/or underestimating the effect size. Too long an intervention is unethical and an unnecessary use of participant, research and financial resources. For example, when looking at the impact of supplementation with EPA+DHA on plasma triglyceride levels, an intervention period of 4–8 weeks is sufficient to achieve the maximal effect. However, if focused on a longer-term functional endpoint, e.g., the impact of DHA on cognitive function, when the proposed mechanisms are dependent on the enrichment of neuronal cells with DHA, an intervention period of one year or more is needed, given the half-life of DHA in the brain is more than 2 years. Also details of the methodologies/tools for capturing the primary and secondary outcomes and whether they are validated for the population of interest should be clearly stated. Justification of the selection of one methodology/tool over the other should be clearly articulated. For example, for assessing Mediterranean Diet adherence over 50 questionnaires have been used with hundreds of assessment tools to capture global cognition and different cognitive domains such as memory, executive function and processing. The choice of tool has a large impact on the likelihood of detecting significance and on the comparability and interpretation of the data. Its relevance to the population and the validity in the population studied should also be clearly articulated.</p>
                            <p>Given that nutrition interventions can target multiple molecular targets and physiological processes, often numerous secondary outcomes are selected. Specific attention is hence required to indicate which outcomes are defined a priori, well-powered, and based on a robust hypothesis, and any other outcomes that are secondary and for which the assessment is rather exploratory.</p>
                            <p>In nutrition trials the acceptability of the intervention should be reported. Acceptability refers to the degree to which an evidence-based intervention is perceived as agreeable, palatable, or satisfactory and is generally assessed by post intervention questionnaire or qualitative interviews with those participating and/or delivering the intervention.</p>
                        `,
                        nut_examples: `
                            <p>“Acceptability of the intervention was assessed at 24 and 48 weeks by a custom questionnaire using 5-point Likert-type scales, informed by the Theoretical Framework of Acceptability.” (Jennings et al., 2024)</p>
                            <p>“The frequency and severity of selected side effects were evaluated using separate Likert scales ranging from 0 (none, 1 = 1–2 occurrences per week) to 5 (very severe, 5 = ≥9 per week).....No significant differences were noted between groups regarding the frequency or severity of gastrointestinal distress, constipation, diarrhea, fatigue, abdominal discomfort, headache, heartburn, itching, facial swelling, skin rash, nasal congestion, or shortness of breath. These findings indicate that the dietary and exercise interventions were well tolerated.”  (Ko et al., 2024)</p>
                            <p>“Programme acceptability was assessed in several ways. Full process evaluation and analysis of qualitative information from transcribed interviews of participants and health-care staff, during each phase of the intervention, will be presented separately. Figure 3 shows retention and attrition rates at each phase of the intervention, and adherence reflected by weight changes.” (Lean et al., 2018)</p>
                            <p>“.... but no previous trial based on dietary change has assessed sustained (ie, ≥1 year) disease remission as a primary outcome. We did the Diabetes Remission Clinical Trial (DiRECT) to assess whether effective weight management, delivered in the primary care setting, could produce sustained remission of type 2 diabetes.” (Lean et al., 2018)</p>
                        `
                    },
                    {
                        id: '15',
                        title: 'Harms',
                        text: 'How harms were defined and assessed (eg, systematically, non-systematically)',
                        consort_examples: `
                            <p>“Adverse events (AE) were assessed clinically and analytically at each monthly follow-up visit. The severity of AE were classified according to the National Cancer Institute Common Toxicity Criteria version 4.0. Following the onset of the first cases, the criteria for considering the presence of tenosynovitis were established as spontaneous pain that increased with movement in any tendon insertion with tenderness at that level and observation of localized inflammatory signs of at least 72 hours in duration . . . Patients were considered to have hepatotoxicity when they presented alanine transaminase, aspartate aminotransferase, or bilirubin elevations more than 2 times the upper limit of the normal range. Toxicity was considered severe, and therefore the drug was discontinued when symptomatic elevations were more than 3 times or asymptomatic elevations were more than 5 times the normal levels. All AE were recorded and additional information was required in case of serious adverse events.”</p>
                            <p>“Immediate adverse events were assessed by monitoring participants 30 min after injection in the trial centre. All participants were required to report all local and systemic adverse reactions and adverse events after the injection using the trial’s mobile application. Solicited adverse reactions were defined as any events that occurred from day zero to day seven after each injection. Unsolicited adverse reactions were defined as any adverse reactions which occurred from day eight to day 28 after each injection. The severity of adverse reactions was defined using the Food and Drug Administration guidance for industry and toxicity grading scale for healthy adult and adolescent volunteers enrolled in preventive vaccine clinical trial.”</p>
                        `,
                        consort_explanation: `
                            <p>Evaluation and reporting of harms in randomised trials can be useful to inform decision makers on the benefit-risk balance of an intervention. Randomised trials usually lack power and sufficient follow-up to adequately estimate harms; nevertheless, they can provide data about harms that can be synthesised in meta-analyses if adequately reported. For example, the Women’s Health Initiative trials on hormone therapy provided important data on the cardiovascular risk of hormone replacement therapy.</p>
                            <p>Harm relates to the unwanted effects of an intervention. According to the specific context, a given event could be considered for assessing harm (eg, myocardial infarction in a trial assessing non-steroidal anti-inflammatory drugs in patients with osteoarthritis) or benefit (eg, myocardial infarction in a trial assessing aspirin in patients with cardiovascular risk factors) of an intervention. The use of the term “harms” is preferred over “safety” to better reflect the negative effect of interventions.</p>
                            <p>Despite the importance of having access to data on harms, reporting of this information is poor. A review of 184 drug trials published between 2015 and 2016 in four medical journals with high impact factors showed that 28% did not provide any details on how harm data were collected and 89% did not report who decided whether the harm was attributable to the study drug. An overview of 13 reviews assessing the reporting of harms in randomised trials using the 2004 CONSORT extension for harms showed that only 40% of the included trials addressed harms outcomes with definitions for each and 44% clarified how harms-related information was collected.</p>
                            <p>How harms are defined and assessed will affect the results and effect estimates. Harm can be prespecified or not. They can be systematically assessed or rely on spontaneous declaration (ie, non-systematically assessed). To increase the study’s power, harm can be aggregated in a composite outcome (eg, cardiovascular diseases). Some trials implement a procedure to determine whether harms could be attributed to the intervention (ie, causality).</p>
                            <p>For each systematically assessed harm, authors should report the definition, the measurement variable (eg, name of a validated questionnaire), and where appropriate, the analysis metric for each participant (eg, time to event), the summary measure for each trial group (eg, proportion), and the time point of interest for analysis. They should describe the procedures for harm assessment including who did the assessment, whether they were blinded to the treatment allocated, the assessment time points, and the overall time period for recording harms. For non-systematically assessed harms, authors should report the mode of data collection with the time point and overall time period for recording harms. Nevertheless, non-systematically assessed harms can be difficult to analyse and interpretation of the results should be viewed with caution. To overcome this issue, trialists can code and group events into specific categories. Nevertheless, the lack of standardisation in data collection could result in selective and incomplete reporting. Access to individual participant data may be needed to adequately synthesise this information.</p>
                            <p>Where appropriate, the process for coding each harm and grading its severity should be described including who did the coding and severity grading, and whether they were blinded to the allocated trial group.</p>
                            <p>If harms outcomes are aggregated (eg, cardiovascular events, serious events, severe events, withdrawals due to harms, harms imputed to treatment), authors should describe the process for classifying harms, including the grouping system used (eg, grading system to define severity), who did the grouping, and whether they were blinded to the treatment allocated.</p>
                            <p>Box 3 summarises the essential information to be reported related to harms. More detailed information can be found in the CONSORT extension for harms, which was updated in 2022.</p>
                        `,
                        nut_ext: 'No formal extension for item 15 pertaining to nutrition trials. However, authors are advised to keep the specific advice below in mind.',
                        nut_explanation: `
                            <p>There is no extension for item 15 pertaining to nutrition trials. However, authors are advised to keep intervention tolerance methods and outcomes (CONSORT 2025 item 27) in mind while reporting trial findings.</p>
                        `
                    },
                    {
                        id: '16a',
                        title: 'Sample size',
                        text: 'How sample size was determined, including all assumptions supporting the sample size calculation',
                        consort_examples: `
                            <p>“We expected an improvement in PFS [progression free survival], in favor of avelumab, with a hazard ratio (HR) of 0.58. Considering a fixed design with a 2-sided α risk of 5% and a power of 80%, 106 events (progression or death) are needed to demonstrate this difference based on the Schoenfeld method. With an estimated recruitment rate of 3 patients per month, a follow-up period for each patient of 24 months, and a percentage of patients lost to follow-up or not evaluable of 15%, 132 patients had to be randomized, and we planned to enroll a total of 66 patients per group.”</p>
                            <p>“The target sample size was 300 (150 per arm) over a 3-and-a-half-year recruitment period. This was based on an assumed proportion of individuals with clinically meaningful improvement in VA [visual acuity] (>10 letters) of 55% in the standard care arm and a 19% increase in the adjunct group to 75%, with approximately 7% loss to follow-up, at least 90% power and two-sided 5% type 1 error.”</p>
                            <p>“In order to detect a minimum clinically important difference (MCID) in mean volume of daily PA [physical activity] of 2.1 m g [milligravity] at 12 months, and assuming a standard deviation (SD) of 5.3 m g, power of 80%, and a statistical significance level of 5%, a total of 202 participants were required. Allowing for 20% loss to follow-up and 20% non-compliance of accelerometer/intervention attendance meant that at least 338 participants were required (169 per group). The value of 2.1 m g was chosen as it represents an increase in PA that is equivalent to walking at the threshold between light intensity and moderate intensity (for example, 4 km per hour) for 30 min per day or 10–15 min of brisk walking per day.”</p>
                            <p>“Sample size was based on the primary outcome measure, HOS ADL [hip outcome score activities of daily living subscale] at eight months post-randomisation, and was calculated using a minimum clinically important difference between groups of 9 points. We estimated the standard deviation to be 14 points; however, summaries presented at a planned interim data monitoring meeting found that the standard deviation was 18 points. A revised calculation (significance level 5%, power 90%, loss to follow-up 20%) gave a sample size of 214 (107 participants in each group). The data monitoring committee approved the sample size increase from 120 to 214 participants.”</p>
                        `,
                        consort_explanation: `
                            <p>Sample size calculations are a key design component for a trial and need careful planning. Sample size calculations need to balance ethical and logistical considerations alongside medical and statistical considerations so that the scientific question can be reliably and precisely answered in a timely manner without unnecessarily exposing individuals to ineffective or harmful interventions. They are generally based on one primary outcome. A trial should therefore be sufficiently large to have a high probability (power) of identifying a clinically important difference of a prespecified size that meets a criterion of statistical significance, if such a difference exists. The magnitude of the effect has an inverse relationship with the sample size required for its detection; that is, larger sample sizes are needed to detect smaller differences. Moreover, the inverse relationship is not linear: very small differences require enormous sample sizes to have good power to detect.</p>
                            <p>All details on how the sample size was determined should be reported to allow replication (in principle). Elements of the sample size calculation that need to be specified are the primary outcome (and time point) on which the calculation was based (item 14); the anticipated values for the outcome in each trial group (which implies the clinically important target difference between the intervention groups) at a specific time point with rationale or provenance of all quantities, including any relevant citations; or continuous outcomes, the standard deviation of the measurements; the statistical test; the α (type I error) value and whether it is two sided; the statistical power (or the β (type II error) value); and the resulting target sample size per trial group. Details should be given of any inflation of the sample size made for attrition or non-adherence during the study. Reference to any formulas or software packages used for the sample size calculation should all be reported. The reporting will have additional considerations for crossover trials, factorial trials, cluster trials, multi-arm trials, within-person trials, and non-inferiority and equivalence trials.</p>
                            <p>Transparency in the sample size reveals the power of the trial to readers and gives them a measure by which to assess whether the trial attained its planned size. Any differences in the planned sample size described in the trial registration (item 2), study protocol (item 3), or statistical analysis plan should be explained.</p>
                            <p>Interim analyses are used in some trials to help decide whether to stop early or to continue recruiting sometimes beyond the planned trial end (item 16b). If the actual sample size differed from the originally intended sample size for some other reason (eg, because of poor recruitment or revision of the target sample size), an explanation should be given alongside details of the revised sample size. Many reviews have found that few authors report how they determined the sample size.</p>
                            <p>There is no value in conducting and reporting a post hoc calculation of statistical power using the results of a trial, for example, as a pretext to explain non-significant findings; this may even mislead and confuse readers.</p>
                        `                    
                      },
                      {
                        id: '16b',
                        title: 'Interim analyses',
                        text: 'Explanation of any interim analyses and stopping guidelines',
                        consort_examples: `
                            <p>“Interim analyses of effectiveness and safety endpoints were performed on behalf of the data monitoring committee on an approximately annual basis during the period of recruitment. These analyses were done with the use of the Haybittle–Peto principle and hence no adjustment was made in the final p values to determine significance.”</p>
                            <p>“One interim analysis of the primary endpoint and safety data was planned for when approximately 50% of the participants had completed D28 [day 28]. Statistical significance and futility boundaries were estimated for the interim and final analysis based on 50,000 simulations from the PASS® software (NCSS, Kaysville, Utah) by simulating a group sequential test for two means assuming normality testing. At the interim analysis, the two-sided significance boundary for clinical efficacy was 0.00312 and for futility of detecting μAUT00063 > μplacebo, the one-sided O’Brien-Fleming boundary was 0.39,141. Hence, at the final analysis, the two-sided significance boundary for clinical efficacy would be 0.04761. The Independent Data Monitoring Committee (IDMC) was advised to consider making recommendations for early termination only where there was a clear demonstration of futility.”</p>
                            <p>“Three planned analyses (two interim analyses and one final analysis) were performed when the observed number of events were 25, 47, and 84, respectively. Data were released by DSMC [data and safety monitoring committee] after final analysis. Efficacy stopping boundaries were based on the O’Brien-Fleming spending function. Futility boundaries were based on testing the alternative hypothesis at the 0.039 level.”</p>
                            <p>“Two interim analyses to be performed using the Haybittle-Peto approach were scheduled, after enrolment of 1000 and 2000 patients, respectively. The significance level associated with both interim analyses was 0.001 and the significance level associated with the final analysis was 0.049. With this method, the overall risk of type 1 error was 5%.”</p>
                        `,
                        consort_explanation: `
                            <p>Numerous randomised trials enrol participants over extended periods of time. If an intervention demonstrates exceptional efficacy, the study might require early termination on ethical grounds. To mitigate this concern, assessing results as data accumulates is advisable, ideally through an independent data monitoring committee (DMC), sometimes referred to as a data and safety monitoring board (DSMB). However, conducting multiple statistical evaluations on accruing data without proper adjustment may result in misleading conclusions. For instance, examining data from a trial at five interim analyses using a P value of 0.05 would elevate the overall false-positive rate closer to 19% rather than the expected 5%. Further to stopping early for efficacy, interim analyses can be used to evaluate (1) futility, to assess whether a trial is likely to meet its objectives; or (2) safety, to assess whether there is evidence for increased risk of harms (in the intervention group relative to the comparator group). Interim analyses can also be used to reassess the sample size, using updated information from interim trial data (eg, through an internal pilot), to ensure adequate power of the trial.</p>
                            <p>Various group sequential statistical approaches exist to adjust for multiple looks (ie, analyses) at the data, and these should be predetermined in the trial protocol (see item 27a of the SPIRIT 2025 statement). Using these methods, data are compared at each interim analysis, where a P value below the specified critical value by the chosen group sequential method signifies statistical significance. Some researchers view group sequential methods as a tool for decision making, while others regard them as a definitive stopping point, intending to halt the trial if the observed P value falls below the critical threshold.</p>
                            <p>Authors should disclose whether they or the DMC/DSMB performed multiple looks at the data (interim analyses). If such multiple looks occurred, it is important to specify the frequency; the triggers prompting them; the statistical methods applied (including any formal stopping rules); and whether these procedures were planned and documented in the trial protocol before the trial commenced, before the DMC examined any interim data, or at a later stage. Authors should also report the time point at which any interim analyses where conducted (and by whom); and state who decided to continue, stop or modify the trial, and whether they were blinded to the treatment allocation. Unfortunately, the reporting of interim analyses and stopping rules is frequently inadequate in published trial reports, even in cases where trials indeed halted earlier than originally planned.</p>
                        `
                    },
                    {
                        id: '17a',
                        title: 'Sequence generation',
                        text: 'Who generated the random allocation sequence and the method used',
                        subheader: 'Randomisation',
                        consort_examples: `
                            <p>“Randomization was done using computer-generated random numbers (Stat Trek software) by trained staff at the Soltan Mirahmad Clinic (Kashan, Iran).”</p>
                            <p>“The randomization was conducted by two independent researchers who were not involved in the study using a computer random sequence generator.”</p>
                        `,
                        consort_explanation: `
                            <p>Randomisation eliminates selection bias at trial entry and is the crucial component of high quality randomised trials. Successful randomisation hinges on two steps: generation of an unpredictable allocation sequence and concealment of this sequence from the investigators enrolling participants (item 18).</p>
                            <p>Who generated the random allocation sequence is important mainly for two reasons. Firstly, someone, or some group, should take responsibility for this critical trial function. Secondly, providing information on the generator might help readers to evaluate whether anyone had access to the allocation sequence during implementation. Investigators should strive for complete separation, independence, between the trial staff involved with generation of the allocation sequence and those staff who implement assignments.</p>
                            <p>Participants should be assigned to comparison groups in the trial on the basis of a chance (random) process characterised by unpredictability. Successful randomisation in practice depends on two inter-related aspects: adequate generation of an unpredictable allocation sequence and concealment of that sequence until assignment occurs. A key issue is whether the sequence is known or predictable by the people involved in allocating participants to the comparison groups. The treatment allocation system should thus be set up so that the person enrolling participants does not know in advance which treatment the next person will receive, a process termed allocation concealment (item 18). Proper allocation concealment shields knowledge of forthcoming assignments, whereas proper random sequences (item 17) prevent correct anticipation of future assignments based on knowledge of past assignments.</p>
                            <p>Authors should provide sufficient information such that the reader can assess the methods used to generate the random allocation sequence and the likelihood of bias in group assignment. Any software used for random sequence generation should also be reported. It is important that information on the process of randomisation is included in the body of the main article and not as a separate supplementary file, where it can be missed by the reader.</p>
                            <p>The term “random” has a precise technical meaning. With random allocation, each participant has a known probability of receiving each intervention before one is assigned, and the assigned intervention is determined by a chance process and cannot be predicted. However, “random” is sometimes used inappropriately in the literature to describe trials in which non-random, “deterministic” allocation methods were used, such as alternation, hospital numbers, or date of birth. When investigators use such non-random methods, they should describe them precisely and should not use the term “random” or any variation of it. Even the term “quasi-random” is unacceptable for describing such trials. Trials based on non-random methods generally yield biased results; bias presumably arises from the inability to adequately conceal these more predictable, non-random sequence generation systems.</p>
                            <p>Many methods of sequence generation are adequate. However, readers cannot judge adequacy from such terms as “random allocation,” “randomisation,” or “random” without further elaboration. Authors should specify the method of sequence generation, such as a random-number table or a computerised random number generator. The sequence may be generated by the process of minimisation, a non-random but generally acceptable method.</p>
                            <p>In some trials, participants are intentionally allocated in unequal numbers to each intervention: for example, to gain more experience with a new procedure or to limit costs of the trial. In such cases, authors should report the randomisation ratio (eg, 2:1, or two treatment participants per control participant).</p>
                            <p>In a representative sample of PubMed indexed trials in 2000, only 21% reported an adequate approach to random sequence generation; this increased to 34% for a similar cohort of PubMed indexed trials in 2006. Two more recent studies showed further small increases to about 40%, but another reported a stubbornly similar level of 32%. When authors report an adequate approach to random sequence generation, in over 90% of cases they report using a random number generator on a computer or a random number table.</p>
                        `
                    },
                    {
                        id: '17b',
                        title: 'Sequence generation',
                        text: 'Type of randomisation and details of any restriction (eg, stratification, blocking, and block size)',
                        consort_examples: `
                            <p>“Treatment assignment was generated using a simple randomization scheme . . . given the open-label nature of the intervention to limit the potential bias due to predictable treatment assignment.”</p>
                            <p>“Randomization (1:1) was performed by an independent researcher using computer generated random table numbers, with a block size of 20 and stratified for the indication of the IUI [intrauterine insemination] (mild male factor or unexplained subfertility).”</p>
                            <p>“Participants were randomized at an individual-level (1:1 ratio) and were stratified by recruitment location (VU [Vrije University] and UvA [University of Amsterdam]). Block randomization was applied with randomly varied block sizes (6–12 allocations per block).”</p>
                            <p>“Randomization was stratified by treatment centre, clinical severity (<4 vs >4 on a Western Ontario and McMaster Universities Osteoarthritis Index (WOMAC) pain subscale standardized to range from 0 to 10), and by whether patients had previously received TENS [transcutaneous electrical nerve stimulation] with randomly varied block sizes of 2, 4, and 6.”</p>
                            <p>“Randomization sequence was created using Stata 9.0 (StataCorp., College Station, TX) statistical software and was stratified by center with a 1:1 allocation using random block sizes of 2,4, and 6.”</p>
                        `,
                        consort_explanation: `
                            <p>In trials of several hundred participants or more, simple randomisation can usually be trusted to generate similar numbers in the two trial groups and to generate groups that are roughly comparable in terms of known and unknown prognostic variables. For smaller trials of fewer than around 200 participants, which are common, some form of restricted randomisation procedure to help achieve balance between groups in size or characteristics may be useful. However, larger trials of greater than approximately 200 participants may also benefit from registration. For example, they may stop before reaching their target size, they may need more power at interim analyses, or they may benefit from stratification with restriction.</p>
                            <p>It is important to indicate whether no restriction was used by stating such or by stating that simple randomisation was done. Otherwise, the methods used to restrict the randomisation, along with the method used for random selection, should be specified. For blocked randomisation, authors should provide details on how the blocks were generated (eg, by using a permuted block design with a computer random number generator), the block size or sizes, and whether the block size was fixed or randomly varied. If the trialists became aware of the block size(s), that information should also be reported as such knowledge could lead to them correctly deciphering future treatment assignments. Authors should specify whether stratification was used and, if so, which factors (eg, recruitment site, sex, disease stage) were involved; the categorisation cut-off thresholds within stratums; and the method used for restriction. Although stratification is a useful technique, especially for smaller trials, it can be complicated to implement and may not perform as well as expected if many stratifying factors are used. If minimisation was used, it should be explicitly identified, as should the variables incorporated into the scheme; whether a random element was used should also be stated.</p>
                            <p>With blocking, although the order of interventions varies randomly within each block, individuals running the trial could deduce some of the future treatment allocations if they discovered the block size. Discovering block sizes is much more likely in unblinded trials, where treatment allocations become known after assignment. Certain techniques, such as large block sizes and randomly varying block sizes, can help prevent the deciphering of future treatment allocations. Unfortunately, particularly with unblinded trials, a review “found that very few trials used techniques that would eliminate the risk of selection bias,” and that “These findings indicate that a substantial proportion of unblinded trials are at risk of selection bias.” Indeed, in a recent study of 179 open, unblinded randomised trials, small block sizes were associated with subversion.</p>
                            <p>Only 9% of 206 reports of trials in specialty journals and 39% of 80 trials in general medical journals reported use of stratification. In each case, only about half of the reports mentioned the use of restricted randomisation. Those studies and that of Adetugbo and Williams found that the sizes of the treatment groups in many trials were very often the same or quite similar, yet blocking or stratification had not been mentioned. One of a few possible causes of this close balance in numbers is under-reporting of the use of restricted randomisation, although non-random manipulation of treatment assignments is also suspected. A more recent study of 298 reports of trials in general medical journals found 69% reported the use of a stratified block method.</p>
                        `
                    },
                    {
                        id: '18',
                        title: 'Allocation concealment mechanism',
                        text: 'Mechanism used to implement the random allocation sequence (eg, central computer/telephone; sequentially numbered, opaque, sealed containers), describing any steps to conceal the sequence until interventions were assigned',
                        consort_examples: `
                            <p>“Participants were centrally assigned to randomised study treatment using an interactive web response system (IWRS) . . . Block randomisation schedules were computer generated by a vendor with a block size of 6 in a randomisation ratio of 2:1 and distributed to the IWRS vendor (endpointClinical) for participant randomisation.”</p>
                            <p>“For allocation concealment, numbered containers were used. The interventions were sealed in sequentially numbered identical opaque containers according to the allocation sequence.”</p>
                            <p>“Furthermore, we employed syringes sequentially numbered and packaged in opaque and sealed containers. Specifically, syringes containing esmolol or placebo were centrally prepared, pre-coded based on the randomization list, and sent sequentially to the operating room immediately before administration.”</p>
                            <p>“Allocation was concealed using sequentially numbered, opaque, sealed envelopes (SNOSE) prior to making the incision.”</p>
                            <p>“Allocation concealment was done using sequentially numbered, sealed, opaque packages.”</p>
                            <p>“The allocation sequence was concealed from the researcher (JR) enrolling and assessing participants in sequentially numbered, opaque, sealed and stapled envelopes. Aluminium foil inside the envelope was used to render the envelope impermeable to intense light. To prevent subversion of the allocation sequence, the name and date of birth of the participant was written on the envelope and a video tape made of the sealed envelope with participant details visible. Carbon paper inside the envelope transferred the information onto the allocation card inside the envelope and a second researcher (CC) later viewed video tapes to ensure envelopes were still sealed when participants' names were written on them. Corresponding envelopes were opened only after the enrolled participants completed all baseline assessments and it was time to allocate the intervention.”</p>
                        `,
                        consort_explanation: `
                            <p>Item 17 discussed generation of an unpredictable sequence of assignments. Of considerable importance is how this sequence is applied when participants are enrolled into the trial (box 5). A generated allocation sequence should be implemented by using allocation concealment, a critical mechanism that prevents foreknowledge of treatment assignment and thus shields those who enrol participants from being influenced by this knowledge. The decision to accept or reject a participant should be made, and informed consent should be obtained from the participant, in ignorance of the next assignment in the sequence. In summary, adequate allocation concealment safeguards knowledge of forthcoming assignments, whereas proper random sequences (item 17) prevent correct anticipation of future assignments based on knowledge of past assignments.</p>
                            <p>Allocation concealment should not be confused with blinding (item 20). Allocation concealment seeks to prevent selection bias (box 5), protects the assignment sequence before and until allocation, and can always be successfully implemented. In contrast, blinding seeks to prevent ascertainment bias, protects the sequence after allocation, and cannot always be implemented. Without adequate allocation concealment, however, even random, unpredictable assignment sequences can be subverted.</p>
                            <p>Centralised or third party assignment is especially desirable. Many good allocation concealment mechanisms incorporate external involvement. Use of a pharmacy or central computer or telephone randomisation system are common techniques. Automated assignment systems are likely to become more common. When external involvement is not feasible, an excellent method of allocation concealment is the use of numbered containers. The interventions (often medicines) are sealed in sequentially numbered identical containers according to the allocation sequence. Enclosing assignments in sequentially numbered, opaque, sealed envelopes can be a good allocation concealment mechanism if it is developed and monitored diligently. This method can be corrupted, however, particularly if it is poorly executed. Investigators should ensure that the envelopes are opaque when held to the light, and are opened sequentially and only after the participant’s name and other details are written on the appropriate sequentially numbered sealed envelope.</p>
                            <p>A number of methodological studies provide empirical evidence to support these precautions. Trials in which the allocation sequence had been inadequately or unclearly concealed yielded larger estimates of treatment effects than did trials in which authors reported adequate allocation concealment. These findings provide strong empirical evidence that inadequate allocation concealment contributes to bias in estimating treatment effects.</p>
                            <p>Despite the importance of the mechanism of allocation concealment, published reports frequently omit such details. Among older studies, the mechanism used to allocate interventions was omitted in reports of 89% of trials on rheumatoid arthritis, 48% of trials in obstetrics and gynaecology journals, and 44% of trials in general medical journals. In a more broadly representative sample of all PubMed indexed randomised trials, only 18% reported any allocation concealment mechanism and some of those reported mechanisms were inadequate. At the same time, some trials where there is no reporting of allocation concealment may have been properly concealed, as demonstrated by inspection of their protocols.</p>
                            <p>Newer studies further illuminate poor reporting of allocation concealment. Unclear reporting (ie, the authors did not provide sufficient information in the paper to allow judgment to be made on the adequacy of method of allocation concealment) was found in 78% and 85% of trials. Moreover, those two studies determined that only 27% and 14% used an adequate allocation concealment mechanism, while another found a similar level of 12%. A review of trials in journals of traditional Chinese medicine found that only 7% used adequate allocation concealment.</p>
                            <p>Fortunately, reporting and conduct may be improving in recent years, for example, after the CONSORT 2010 guidelines were published. Another study found that reporting on allocation concealment and sequence generation was much better in journals that endorsed the CONSORT 2010 guidelines than in non-endorsing journals. Moreover, that study found that 57% of trials in the sample had used an adequate allocation concealment mechanism. However, other empirical studies show only modest improvements, for example, an evaluation of over 176 000 trials found that allocation concealment reporting increased from 5.1% in 1966-90 to 19.3% in 2010-18. While any improvement is encouraging, more efforts to improve conduct and reporting remain necessary.</p>
                        `
                    },
                    {
                        id: '19',
                        title: 'Implementation',
                        text: 'Whether the personnel who enrolled and those who assigned participants to the interventions had access to the random allocation sequence',
                        consort_examples: `
                            <p>“Sequential randomisation codes were computer generated using permuted blocks . . . An independent study statistician generated the randomisation codes . . . Good Clinical Practice (GCP) trained research nurses or First Nations health practitioners allocate the study medicine to each mother–infant pair by selecting the next sequentially labelled (prerandomised) study medication from the appropriate stratification group. The allocation sequence number is recorded by the research team on the data collection form (DCF), the database and in the participant’s medical record.”</p>
                            <p>“LabCorp Drug Development (a subcontractor to the IWRS [interactive web response system] vendor) generated the live randomisation schedules. Site personnel enrolled participants in the IWRS. The IWRS assigned participants to the trial groups per live randomisation schedules. LabCorp Drug Development didn’t have any involvement in the rest of the trial . . . Site personnel were involved in participant care and performing trial procedures throughout the trial; however, they were masked to treatment assignment.”</p>
                            <p>“All participants were screened by a masked trial doctor who also obtained informed consent . . . The masked trial doctor then provided all participants with guideline-recommended care and a prescription for the trial medicine kit . . . The randomisation sequence was created using randomly permuted blocks by an independent statistician (who had no involvement in the rest of the trial).”</p>
                            <p>“The details of sequence generation and group allocation were unavailable to research team members bar one unblinded research assistant. The unblinded research team member that created the randomisation sequence had no contact with participants and was not involved with data collection or analysis.”</p>
                            <p>“Block randomisation was by a computer generated random number list prepared by an investigator with no clinical involvement in the trial . . . After the research nurse had obtained the patient’s consent, she telephoned a contact who was independent of the recruitment process for allocation consignment.”</p>
                        `,
                        consort_explanation: `
                            <p>As noted in item 18, concealment of the allocated intervention at the time of enrolment is especially important. Thus, in addition to knowing the methods used, it is also important to understand how the random sequence was implemented; specifically, whether the personnel who enrolled and those who assigned participants to the interventions had access to the random allocation sequence.</p>
                            <p>In practice, the process of randomising participants into a trial has three different steps: sequence generation, allocation concealment mechanism, and implementation. Although the same individuals may carry out more than one process under each heading, investigators should strive for complete separation of the people involved with generation and allocation concealment from the people who implement assignments. Thus, if someone is involved in the sequence generation or allocation concealment steps, ideally, they should not be involved in the implementation step. When this separation is not possible, importantly the investigators should ensure that the assignment schedule is unpredictable and locked away from even the person who generated it.</p>
                            <p>Even with flawless sequence generation and allocation concealment, failure to separate creation and concealment of the allocation sequence from assignment to trial group may introduce bias. For example, the person who was enrolling and assigning participants and who also generated an allocation sequence would likely have access to the sequence list and could consult it when interviewing potential participants for a trial. Thus, that person could bias the enrolment or assignment process, regardless of the unpredictability of the assignment sequence and the impenetrability of the allocation concealment mechanism. Investigators must therefore ensure that the assignment schedule is unpredictable and locked away (eg, in a safe deposit box in a building inaccessible to the enrolment location) from even the person who generated it. In that instance, the report of the trial should specify where the investigators stored the allocation list.</p>
                            <p>Thus, for full assessment of randomisation in a trial report, authors should confirm that personnel who enrolled and those who assigned participants to the interventions did not have access to the random allocation sequence. At minimum, authors should confirm complete separation of the people involved with generation and allocation concealment from the people involved in the implementation of assignments. If complete separation did not occur, then authors should describe how the people involved in the implementation were prevented from accessing the sequence (eg, specifying that the allocation sequence was locked in a secure location).</p>
                            <p>Sometimes those who enrol and those who assign are different people, but frequently the same individuals do both. These individuals may be termed differently by authors (eg, recruiters), but the functions remain the same.</p>
                            <p>Full assessment of implementation is not always possible from trial reports. In a sample of 199 medical journals, 63% of trial reports did not provide sufficient information to assess whether the person who generated the allocation sequence was not also the person who allocated participants to treatment groups. Only 31% of trial reports provided sufficient details on who recruited participants and who generated the allocation sequence.</p>
                        `
                    },
                    {
                        id: '20a',
                        title: 'Blinding',
                        text: 'Who was blinded after assignment to interventions (eg, participants, care providers, outcome assessors, data analysts)',
                        subheader: 'Blinding',
                        consort_examples: `
                            <p>“Whereas patients and physicians allocated to the intervention group were aware of the allocated arm, outcome assessors and data analysts were kept blinded to the allocation.”</p>
                            <p>“Blinding and equipoise were strictly maintained by emphasizing to intervention staff and participants that each diet adheres to healthy principles, and each is advocated by certain experts to be superior for long-term weight-loss. Except for the interventionists (dieticians and behavioural psychologists), investigators and staff were kept blind to diet assignment of the participants. The trial adhered to established procedures to maintain separation between staff that take outcome measurements and staff that deliver the intervention. Staff members who obtained outcome measurements were not informed of the diet group assignment. Intervention staff, dieticians and behavioural psychologists who delivered the intervention did not take outcome measurements. All investigators, staff, and participants were kept masked to outcome measurements and trial results.”</p>
                            <p>“This was a double-blind study with limited access to the randomisation code . . . The treatment each patient received was not disclosed to the investigator, study site staff, patient, sponsor personnel involved with the conduct of the study (with the exception of the clinical supply staff and designated safety staff), or study vendors.”</p>
                            <p>“Physicians, patients, nurses responsible for referring the patients, the statistician, also the investigators who rated the patients and administered the drugs, were all blinded to the allocation.”</p>
                        `,
                        consort_explanation: `
                            <p>The term “blinding” (masking) refers to withholding information about the assigned interventions from people involved in the trial who may potentially be influenced by this knowledge. Blinding is an important safeguard against bias, particularly when assessing subjective outcomes.</p>
                            <p>Benjamin Franklin has been credited as being the first to use blinding in a scientific experiment. He blindfolded participants so they would not know when he was applying mesmerism (a popular healing technique of the 18th century) and in so doing demonstrated that mesmerism was a sham. Since then, the scientific community has widely recognised the power of blinding to reduce bias, and it has remained a commonly used strategy in scientific experiments.</p>
                            <p>Box 7 on blinding terminology defines the groups of individuals (ie, participants, healthcare providers, data collectors, outcome assessors, and data analysts) that can potentially introduce bias into a trial through knowledge of the treatment assignments. Participants may respond differently if they are aware of their treatment assignment (eg, respond more favourably when they receive the new treatment). Lack of blinding may also influence adherence with the intervention, use of co-interventions, and risk of dropping out of the trial.</p>
                        `,
                        nut_ext: 'No formal extension for item 20a pertaining to nutrition trials. However, authors are advised to keep the specific advice below in mind while drafting their trial report.',
                        nut_explanation: `
                            <p>CONSORT asks for a description of who was blinded to the intervention, i.e., participants, care providers, those assessing outcomes. Accomplishing blinding is often more challenging when food or diet patterns are altered because of differences in appearance, taste, smell, texture, and color between the intervention and comparator. More efforts to assure blinding will improve rigor but may require experience with food processing and special packaging and coding. Even with supplement studies, placebos can be difficult to match to the intervention. Unfortunately, even highly cited trials may not explain blinding protocols. Behavioural interventions may be more difficult to blind, but blinding can occur after baseline measurements are taken. When blinding to participants is not possible, those performing the outcome measures and statistical analysis can often be blinded, and this should be distinguished in the trial report per CONSORT.</p>
                        `,
                        nut_examples: `
                            <p>In a comparison of dietary calcium from dairy and calcium carbonate and at two doses, a frozen product was made with matched macronutrients and packaged labelled with a code to blind participants (Weaver et al., 2011).</p>
                        `
                    },
                    {
                        id: '20b',
                        title: 'Blinding',
                        text: 'If blinded, how blinding was achieved and description of the similarity of interventions',
                        consort_examples: `
                            <p>“Jamieson Laboratories Inc. provided 500-mg immediate release niacin in a white, oblong, bisect caplet. We independently confirmed caplet content using high performance liquid chromatography . . . The placebo was matched to the study drug for taste, color, and size, and contained microcrystalline cellulose, silicon dioxide, dicalcium phosphate, magnesium stearate, and stearic acid.”</p>
                            <p>“Placebo tablets were identical to NAC [N‐acetylcysteine] tablets in color, shape, size, and odor. They were all kept in identical containers and were administered by an investigational drug pharmacist.”</p>
                            <p>“The study treatment and placebo tablets and bottles were identical in physical appearance . . . The IWRS [interactive web response system] housed treatment codes and bottle numbers for study treatment. In case of an emergency, the investigator had the sole responsibility for determining if unmasking of a participant’s treatment assignment was warranted to provide appropriate medical care. Participant safety was always the first consideration in making such a determination. The IWRS was programmed with blind-breaking instructions to guide the investigator on how to obtain treatment assignment in the event of an emergency unmasking. The investigator was requested to contact the medical monitor promptly in case of any treatment unmasking. If a participant’s treatment assignment was unmasked, the sponsor was to be notified within 24 h after unmasking. The date and reason for the unmasking were recorded in the source documentation and electronic case report form, as applicable. Investigators broke the masking for four participants: one in ELEVATE UC 12 (on etrasimod) and three in ELEVATE UC 52 (on etrasimod).”</p>
                        `,
                        consort_explanation: `
                            <p>Blinding of participants, healthcare providers, data collectors, and outcome assessors in a trial requires adequate procedures to both achieve and maintain blinding. Just as we seek evidence of adequate allocation concealment to assure us that assignment was truly random, we seek evidence on the method of blinding.</p>
                            <p>If researchers contend that the trial investigators, participants, and assessors were blinded, then they should provide information about the mechanism used to establish blinding (eg, placebo identical to the experimental intervention, sham intervention, sham surgery). They should describe the similarity of treatment characteristics (eg, route of administration, appearance, smell, taste) and where relevant methods used to mask some characteristics of the treatments (eg, use of special flavours to mask a distinctive taste, opaque coverage to conceal intravenous treatments with different appearances, double-dummy procedures).</p>
                            <p>Blinding can be difficult to maintain over time because of dosage adaptation over time or the occurrence of specific side effects. Specific procedures to maintain blinding can be implemented (eg, centralised assessment of side effects, centralised adapted dosage, or provision of sham results of complementary investigations).</p>
                            <p>Even if blinding of participants and healthcare providers is not possible, blinding data collectors and outcome assessors could still be implemented to limit ascertainment bias. This could be achieved, for example, through centralised assessment of complementary investigation (eg, anonymised radiography), physician mediated data (eg, video, photography, audiotape), and clinical events (eg, adjudication of clinical events from extract of the case report form).</p>
                            <p>Details of how blinding was achieved are important because slight, but discernible, differences between interventions can lead to large problems in bias. Notably, inadequate matching related to discernible differences in colour and taste seem particularly problematic. It is important that authors report any known compromises in blinding. For example, authors should report if it was necessary to unblind any participants at any point during the conduct of the trial. Moreover, authors should report the risk of unblinding but, unfortunately, such reporting is rare. In a random sample of 300 publications describing blinded randomised clinical trials indexed in PubMed, only 8% reported on risk of unblinding. It is also important to report any procedures, pretrial or concurrent, that are intended to reduce or evaluate risk of compromised blinding. Indeed, some pretrial assessments of unblinding may be helpful in reducing the risk of unblinding in the eventual randomised trial. Thus, authors of randomised trial articles should report procedures to avoid, document, and address cases of overt unblinding.</p>
                            <p>Where appropriate, authors should also describe any procedures used for emergency unblinding (ie, disclosing the assigned intervention of a trial participant for specific reasons such as harms). They should indicate whether they used fixed code to indicate group assignment (eg, A=group 1; B=group 2) or a unique code for each participant. Use of a fixed code will increase the risk of unblinding because unblinding a participant could result in unblinding several or all trial participants.</p>
                            <p>Some people have advocated testing for blinding by asking participants or healthcare providers at the end of a trial whether they think the participant received the experimental or control intervention. Because participants and healthcare providers will frequently know whether the participant has experienced the primary outcome, this makes it difficult to determine whether their responses reflect failure of blinding or accurate assumptions about the efficacy of the intervention. Thus, given the uncertainty this type of information provides, the usefulness of tests of blinding has been questioned. Testing for blinding was not an included item in CONSORT 2010, and still is not in CONSORT 2025. Nevertheless, if investigators decide to conduct tests of blinding, we encourage them to completely report their findings with appropriate limitations.</p>
                        `
                    },
                    {
                        id: '21a',
                        title: 'Statistical methods',
                        text: 'Statistical methods used to compare groups for primary and secondary outcomes, including harms',
                        consort_examples: `
                            <p>“The primary outcome was analysed using a mixed effects log-binomial model to generate an adjusted risk ratio (RR) and an adjusted risk difference (using an identity link function), including centre as a random effect. Statistical significance of the treatment group parameter was determined (p value generated) through examination of the associated χ2 statistic (obtained from the log-binomial model which produced the RR). Binary secondary outcomes were analysed as per the primary outcome. Time to hCG [human chorionic gonadotrophin] resolution was considered in a competing risk framework to account for participants who had surgical intervention for their ectopic pregnancy. A cumulative incidence function was used to estimate the probability of occurrence (hCG resolution) over time. A Fine and Gray model was then used to estimate a subdistribution adjusted hazard ratio (HR) directly from the cumulative incidence function. In addition, a further Cox proportional hazard model was fitted and applied to the cause-specific (non-surgical resolution) hazard function and used to generate an adjusted HR. Return to menses was analysed using a Cox regression model. Number of hospital visits associated with treatment was analysed using a Poisson regression model, including centre as a random effect to generate an adjusted incidence ratio.”</p>
                            <p>“For the primary continuous outcome and secondary outcomes, linear mixed-effect models were used, with outcome measurement (at the two follow-up timepoints) as the dependent variable. The models included fixed effects for timepoint, treatment, timepoint by treatment interactions, the baseline measure of the outcome, and therapist, assuming a linear relationship between baseline and outcome. The dichotomous outcome of recovery in the delusion was analysed using a logistic mixed-effect model. Persecutory delusion conviction was analysed as a continuous and also as a dichotomous (recovery) variable. The models included a random intercept for participant, an unstructured correlation matrix for the residuals, and were fitted using restricted maximum likelihood estimation . . . For each outcome and timepoint, we report the treatment effect estimate as the adjusted mean difference between groups, its SE [standard error], 95% CIs [confidence intervals], and p value. In addition, we report estimates for Cohen’s d effect sizes as the adjusted mean difference of the outcome (between the groups) divided by the sample SD [standard deviation] of the outcome at baseline.”</p>
                            <p>“Analyses followed a prespecified statistical analysis plan. The primary outcome (ODQ [Oswestry Disability Questionnaire] score at 18 weeks after randomisation) was compared between groups with a linear regression model, adjusted for baseline ODQ, with centre as a random effect. ODQ score, visual analogue scores (VAS) for back pain, VAS for leg pain, MRM [modified Roland-Morris] outcome score, and COMI [Core Outcome Measures Index] score at all follow-up visits were analysed with a repeated measures mixed-effects model adjusting for baseline outcome measure, treatment group, time (as a continuous variable), and a time-treatment arm interaction (if significant). Centre and participant were random effects in the repeated measures models. A second model adjusted for other prespecified variables, age, sex, duration of symptoms, body-mass index, and size of disc prolapse (as a percentage of the diameter of the spinal canal, categorised as <25%, 25–50%, or >50%).”</p>
                            <p>“We analysed the primary outcome (between-group difference in the SPPB [short physical performance battery] at 12 months) using linear mixed models, adjusted for baseline measurements, minimisation variables (age, sex and CKD [chronic kidney disease] category) and a random effect variable for recruitment site. We analysed secondary outcomes using repeated measures mixed models, including all participants and including data from all available timepoints. Models were adjusted for baseline values and the minimisation variables. We conducted time-to-event analyses (time to death, time to commencing renal replacement therapy) using Cox proportional hazards models adjusted for minimisation variables. All participants were included in these analyses, with participants censored at the point of dropout or truncation of follow-up for those not reaching the analysis endpoint before 24 months. For all analyses, we took a two-sided p value of < 0.05 as significant with no adjustment for multiple testing.”</p>
                        `,
                        consort_explanation: `
                            <p>Various methods can be used to analyse data, and it is crucial to ensure that the chosen approach is suitable for the specific context. Specifying the statistical procedures and software used for each analysis is essential, and additional clarification may be required in the results section of the report. Authors should describe the statistical methods insufficient detail to allow a knowledgeable reader with access to the original data to verify the reported results, as emphasised by the ICMJE (https://www.icmje.org/). It is also important to elaborate on specific aspects of the statistical analysis, such as the intention-to-treat approach.</p>
                            <p>Details of all statistical analyses are frequently prespecified in a statistical analysis plan, a document that accompanies the trial protocol. In the report of the trial results, authors should detail and justify any deviation from the statistical analysis plan or from the protocol if no statistical analysis plan was developed. They should clarify which analyses were prespecified and which were post hoc.</p>
                            <p>Most analysis approaches provide an estimate of the treatment effect, representing the difference in outcomes between comparison groups, and authors should also indicate the effect measure (eg, absolute risk) considered. Authors should accompany this with a CI for the estimated effect, delineating a central range of uncertainty regarding the actual treatment effect. The CI may be interpreted as the range of values for the treatment effect that is compatible with the observed data. Typically, a 95% CI is presented, signifying the range anticipated to encompass the true value in 95 of 100 similar studies.</p>
                            <p>Study findings can also be assessed in terms of their statistical significance. The P value represents the probability that the observed data (or a more extreme result) could have arisen by chance when the interventions did not truly differ. The statistical significance level that will be used should be reported. In the results section, actual P values (for example, P=0.001) are strongly preferable to imprecise threshold reports such as P<0.05.</p>
                            <p>Some trials may use bayesian methods. In this case, the choices of priors, computational decisions, and any modelling methods used should be described. Most bayesian trials so far have been for early phases of drug development, but this approach can be applicable to any phase. Typically, results are presented as treatment effects along with credible intervals.</p>
                            <p>Where an analysis lacks statistical power (eg, harms outcomes), authors may prefer descriptive approaches over formal statistical analysis.</p>
                            <p>While the necessity for covariate adjustments is generally reduced in randomised trials compared with epidemiological studies, considering an adjusted analysis can have value in terms of increased power and precision, particularly if there is an indication that one or more variables may have prognostic value. It is preferable for adjusted analyses to be explicitly outlined in the study protocol (item 3). For instance, it is often advisable to make adjustments for stratification variables, in keeping with the principle that the analysis strategy should align with the study design. In the context of randomised trials, the decision to make adjustments should not be based on whether there are baseline covariates that are statistically significantly different between randomised groups. The testing of baseline imbalance in covariates should be avoided, as if randomisation is properly conducted, then by definition, any differences in baseline covariates between treatment arms are random. The rationale for any adjusted analyses and the statistical methods used should be specified, along with clarifying the choice of covariates that were adjusted for, indicating how continuous variables were handled (eg, linear, modelled with splines), and specifying whether the analysis was planned or post hoc. Reviews of published studies show that reporting of adjusted analyses is inadequate with regard to all of these aspects.</p>
                            <p>Multiplicity issues are prevalent in trials and merit special consideration, especially in cases involving multiple primary outcomes, multiple time points stemming from repeated assessments of an outcome, multiple planned analyses for an outcome (such as interim or subgroup analyses (item 21d)), or analyses of numerous secondary outcomes (see CONSORT outcomes extension for more details). Any methods used to mitigate or account for multiplicity should be described. If no methods have been used to account for multiplicity (eg, not applicable, or not considered), then this should also be reported, particularly when a large number of analyses has been carried out.</p>
                        `,
                        nut_ext: 'No formal extension for item 21a pertaining to nutrition trials. However, authors are advised to keep the specific advice below in mind while drafting their trial report.',
                        nut_explanation: `
                            <p>A common error in nutrition RCTs is incorrectly basing conclusions on within-group differences rather than basing conclusions on between-group differences. For example, reporting a statistically significant change from baseline within the intervention group, and separately no statistically significant change from baseline within the control group, and concluding a treatment effect, has an increased risk of false-positive conclusions compared to a direct between-group comparison (for nutrition-specific examples, see: PMID: 26354536).</p>
                            <p>Another common error is the failure to account for non-independence of observations and any hierarchical structure of a design. Standard statistical tests assume that all observations are independent, but data in nutrition trials can be clustered (e.g., participants allocated together from the same family to treatment or control, classrooms or schools allocated to treatment or control, or participants allocated individually and treated in a group setting). Analyzing data with methods that ignore clustering and nesting can lead to artificially small p-values and confidence intervals and an inflated risk of false-positive conclusions (PMID: 26016864).</p>
                        `
                    },
                    {
                        id: '21b',
                        title: 'Statistical methods',
                        text: 'Definition of who is included in each analysis (eg, all randomised participants), and in which group',
                        consort_examples: `
                            <p>“The primary statistical analyses were performed according to the treatment to which the participants were randomly assigned. The analyses of the efficacy and safety outcomes (other than adverse events) included all available data from all randomized participants who contributed at least 1 value after baseline for the outcome of interest. The data that were obtained after a participant enrolled in another trial of an investigational treatment were excluded from the analyses. However, the participant was included in the analyses if that participant contributed at least 1 value after baseline for the outcome of interest prior to enrolling in another trial.”</p>
                            <p>“Efficacy outcomes were assessed using intention-to-treat analysis (ie, the full set of all randomly assigned patients). Safety outcomes were assessed using the safety analysis set of all randomly allocated patients exposed to at least one dose of randomised intervention.”</p>
                            <p>“Efficacy analyses and other exploratory analyses were performed in the full analysis set (defined as all patients randomly assigned to the study, including those who did not receive a dose of study treatment). Safety analyses were performed in the safety analysis set (defined as patients who received at least one dose of study treatment). The per protocol set was defined as all patients in the full analysis set who complied with the protocol in terms of exposure to study treatment, availability of tumour assessments, and absence of major protocol deviations likely to affect efficacy outcomes. Sensitivity analyses of the primary endpoint were performed on the per protocol analysis set.”</p>
                            <p>“The primary analysis population was defined as all participants who completed baseline and 36-week assessments. The primary analysis of the primary outcome, AMCA [amended motor club assessment] score at 36 weeks, followed a modified intention-to-treat approach, regardless of compliance to the intervention, but did exclude patients who were deemed ineligible after randomisation, those who withdrew from the trial and were unwilling for their previously collected data to be used, or those who did not provide baseline and week 36 measurements.”</p>
                        `,
                        consort_explanation: `
                            <p>A key strength of a randomised trial design is the avoidance of bias when randomly allocating trial participants to interventions. To preserve the benefits of randomisation, all randomised participants are included in the analysis and retained in the group to which they were allocated. Meeting these two conditions defines an intention-to-treat analysis—which is widely recommended as the preferred analysis strategy. However, strict adherence to an intention-to-treat analysis is often difficult to achieve owing to missing outcomes for some trial participants (item 21c) or non-adherence to the trial intervention protocol. While imputation of missing outcomes would allow an intention-to-treat analysis, it does not guarantee an avoidance of bias except under strong assumptions about the missing data which may be unknown.</p>
                            <p>Various strategies for performing intention-to-treat analyses in the presence of missing outcome data are available. When the number of missing outcomes is not large, the analysis population could be all randomised participants with outcome observed (known as an “available case” population) under a plausible missing data mechanism, and sensitivity analyses could be performed exploring departures from this assumption (thereby using all randomised participants at least in sensitivity analyses). Concerns may arise when the frequency or the causes of dropping out differ between the intervention groups. Striving for intention-to-treat analysis by imputing values for participants with missing outcomes may lead to use of inadequate methods such as last observation carried forward.</p>
                            <p>Regardless of whether all randomised participants (completely observed outcomes or imputed outcomes) or a subset of randomised participants with observed outcomes are included in the primary analysis, the analysis population should be described. Authors often describe performing analyses on a “modified intention-to-treat” population to cover departures from a strict intention-to-treat that excludes participants who did not adequately adhere to the protocol such that they did not receive some minimum amount of the intervention—in such cases, what defines the minimum amount of the intervention should be explained (eg, those participants receiving at least one dose of the medication). It is also common to include analyses based on a per protocol population, which includes participants completing the study with no major protocol deviations. Excluding participants may compromise the randomisation and lead to biased estimates of treatment effects if appropriate methods are not used. Other analysis populations are possible (eg, a safety population), and their rationale and definition should be explained. Thus, authors should clearly define which participants are included in each analysis and in which intervention group and avoid terms such as “modified intention-to-treat” or “per protocol” analysis.</p>
                        `,
                        nut_ext: 'No formal extension for item 21b pertaining to nutrition trials. However, authors are advised to keep the specific advice below in mind while drafting their trial report.',
                        nut_explanation: `
                            <p>Different analytical approaches answer distinct causal questions. An intention-to-treat (ITT) analysis provides an unbiased causal estimate of the effect of assigning an intervention, and therefore as CONSORT 2025 notes “is widely recommended as the preferred analysis strategy” because it preserves the benefits of randomization. However, ITT analysis is often difficult to achieve in nutrition trials for two main reasons. First, non-adherence, which is common in dietary interventions, means an ITT analysis will likely underestimate the treatment effect. Second, missing outcome data from participants lost to follow-up requires thoughtful approaches based on missing data assumptions that may be unverifiable. Deviations from the ITT principle, such as per-protocol (including only adherent participants) or as-treated analyses (grouping participants by intervention received), attempt to estimate the effect a researcher may be most interested in - namely, the effect of an intervention when it is fully adhered to. However, these approaches are susceptible to bias, as excluding or re-grouping individuals breaks the randomization and its protection against confounding. Thus, while the ITT analysis provides an unbiased estimate of an intervention’s effect, a per-protocol analysis is often also reported to explore the potential effect under full adherence. Each provides insights into the translatability of the intervention depending on the target population (e.g., a population-level impact of an intervention versus a clinician advising a highly motivated patient on the potential benefit of full adherence). The degree to which the intention-to-treat and per-protocol analyses diverge in their findings, and thus the overall interpretation of the trial, will largely depend on the severity of non-adherence and missing outcome data.</p>
                            <p>Regardless of which analysis approach is used, a clear and explicit description of who was included in each analysis is essential given that terminology such as “intention-to-treat” and “per-protocol” are often used ambiguously. Finally, authors should be explicit about which causal question their analysis addresses - for example, the effect of assignment (from an ITT analysis) versus the effect of adherence (from a per-protocol analysis). The use of causal language must be justified by the assumptions of the chosen method; strong causal claims are often inappropriate for non-ITT analyses due to their risk of bias.</p>
                        `
                    },
                    {
                        id: '21c',
                        title: 'Statistical methods',
                        text: 'How missing data were handled in the analysis',
                        consort_examples: `
                            <p>“Regarding the multiple imputation procedure, briefly, for each outcome, the analysis model used was a linear regression with treatment arm, baseline outcome, and ethnicity (randomization stratifier) as explanatory variables. The imputation models contained all the variables of the analysis model(s) as well as factors associated with missingness: age (identified empirically to predict missingness, P = .03) and adherence (number of doses taken of either vitamin D or placebo, P < .001).”</p>
                            <p>“To consider the potential impact of missing data on trial conclusions, we used multiple imputation (data missing at random) and sensitivity analysis (data not missing at random). Multiple imputation by chained equations was performed using the “mi impute chained” command in Stata. We used a linear regression model to impute missing outcomes for the HOS ADL [activities of daily living subscale of the hip outcome score] at eight months post-randomisation. Variables in the imputation model included all covariates in the analysis model (baseline HOS ADL (continuous), age (continuous), and sex). In addition, we included other variables that were thought to be predictive of the outcome (lateral centre-edge angle, maximum α angle, Kellgren-Lawrence grade, and baseline HADS score). Imputations were run separately by treatment arm and based on a predictive mean matching approach, choosing at random one of the five HOS ADL values with the closest predicted scores. Missing data in the covariates that were included in the multiple imputation model were imputed simultaneously (multiple imputation by chained equation approach). Sensitivity analysis was performed using the “rctmiss” command in Stata, and we considered scenarios where participants with missing data in each arm were assumed to have outcomes that were up to 9 points worse than when data were missing at random.”</p>
                            <p>“Analyses for the 2 primary outcomes compared each treatment with usual care using multiple imputation to handle missing data and a Bonferroni-corrected 2-tailed type I error of .025. We performed 20 imputations with a fully conditional specification using Proc MI in SAS. Imputation was performed with the following prespecified variables: age, study group, study site, clinic, sex, race and ethnicity, body mass index, exercise frequency at baseline, education, employment status, smoking status, other medical conditions at baseline, number of medications used for spine pain at baseline, duration of pain at baseline, number of previous pain episodes, STarT Back score, baseline ODI, baseline self-efficacy, baseline EQ-5D-5L, and scores for patient-reported outcomes at every follow-up point (ODI [Oswestry Disability Index], cost, Lorig et al self-efficacy scale, and EQ-5D-5L [EuroQol 5-dimensional 5-level questionnaire]). Each imputed data set was analyzed separately using Proc GENMOD in SAS (with an identity link and normally distributed errors for ODI and a log link and Poisson-distributed errors for spine-related spending).”</p>
                            <p>“Missing peak V̇o2 [oxygen consumption] data at week 20, regardless of the type of intercurrent event, was imputed using multiple imputation methodology under the missing at random assumption for the primary analysis. Sensitivity analyses were performed by exploring a missing not at random assumption in the imputation of peak V̇o2. The imputation model used a regression multiple imputation, which includes treatment group, baseline respiratory exchange ratio, persistent atrial fibrillation (yes or no), age, sex, baseline peak V̇o2, baseline hemoglobin level, baseline estimated glomerular filtration rate, baseline body weight, baseline KCCQ [Kansas City cardiomyopathy questionnaire] total symptom score, baseline NYHA [New York Heart Association] class, and baseline average daily activity units (refers to 10 hours of wearing during the awake time for ≥7 days unless otherwise specified). Treatment group, persistent atrial fibrillation (yes or no), baseline NYHA class, and sex were treated as categorical variables. Fifty imputed data sets were generated. Each of the imputed data sets was analyzed using the analysis of covariance model of the primary analysis. Least square mean (LSM) treatment difference and the standard error were combined using Rubin’s rules to produce an LSM estimate of the treatment difference, its 95% CI [confidence interval], and P value for the test of null hypothesis of no treatment effect.”</p>
                            <p>“Multiple imputation was preplanned for the primary outcome measure in the case of missing data; however, because there were no missing data relating to ventilator-free days, imputation was not required.”</p>
                        `,
                        consort_explanation: `
                            <p>Missing data are common when conducting medical research. Collecting data on all study participants can be challenging even in a trial that has mechanisms to maximise data capture. Missing values can occur in either the outcome or in one or more covariates, or usually both. There are many reasons why missing values occur in the outcome. Patients may stop participating in the trial, withdraw consent for further data collection, or fail to attend follow-up visits; all of which could be related to the treatment allocation, specific (prognostic) factors, or experiencing a specific health outcome. Missing values could also occur in baseline variables, such that all the necessary data needed to conduct the trial have been only partially recorded. Despite the ubiquity of missing data in medical research, the reporting of missing data and how they are handled in the analyses is poor.</p>
                            <p>Many trialists exclude patients without an observed outcome. Once any randomised participants are excluded, the analysis is not strictly an intention-to-treat analysis. Most randomised trials have some missing observations. Trialists effectively must choose between omitting the participants without final outcome data, imputing their missing outcome data, or using model based approaches such as fitting a linear mixed model to repeated measures data. A complete case (or available case) analysis includes only those participants whose outcome is known. While a few missing outcomes will not cause a problem, many trials have more than 10% of randomised patients with missing outcomes. This common situation will result in loss of power by reducing the sample size, and bias may well be introduced if being lost to follow-up is related to a participant’s response to treatment. There should be concern when the frequency or the causes of dropping out differ between the intervention groups.</p>
                            <p>Participants with missing outcomes can be included in the analysis if their outcomes are imputed (ie, their outcomes are estimated from other information that was collected) or if using a model based approach. Imputing the values of missing data allows the analysis to potentially conform to intention-to-treat analysis but requires strong assumptions, which may be hard to justify. Simple imputation methods are appealing, but their use may be inadvisable as they fail to account for uncertainty introduced by missing data and may lead to invalid inferences (eg, estimated standard errors for the treatment effect will be too small). For randomised trials with missing data within repeated measures data, model based approaches such as fitting a linear mixed model can be used to estimate the treatment effect at the final time point which is valid under a missing-at-random assumption. A model is fit at a (limited) number of time points following randomisation, by including fixed effects for time and randomised group and their interaction.</p>
                            <p>Another approach that is sometimes used is known as “last observation carried forward,” in which missing final values of the outcome variable are replaced by the last known value before the participant was lost to follow-up. Although this method might appear appealing through its simplicity, the underlying assumption will rarely be valid, so the method may introduce bias, and makes no allowance for the uncertainty of imputation. The approach of last observation carried forward has been severely criticised. Sensitivity analyses should be reported to understand the extent to which the results of the trial depend on the missing data assumptions and subsequent analysis (item 21d). When the findings from the sensitivity analyses are consistent with the results from the primary analysis (eg, complete case for the primary analysis and multiple imputation for a sensitivity analysis), trialists can be reassured that the missing data assumptions and associated methods had little impact on the trial results.</p>
                            <p>Regardless of what data are missing, how such data are to be analysed and reported needs to be carefully planned. Authors should provide a description on how missing data were handled in sufficient detail to allow for the analysis to be reproduced (in principle; box 8).</p>
                        `
                    },
                    {
                        id: '21d',
                        title: 'Additional analyses',
                        text: 'Methods for any additional analyses (eg, subgroup and sensitivity analyses), distinguishing prespecified from post hoc',
                        consort_examples: `
                            <p>“We conducted prespecified sensitivity analyses to examine the effect of our assumption that participants who withdrew or were lost to follow-up returned to smoking: (1) a complete case analysis and (2) multiple imputation to impute missing smoking abstinence and reduction data. Multiple imputation was performed using the fully conditional specification approach with 5 imputed data sets and results combined using the Rubin rules (eMethods in Supplement 2). Other prespecified sensitivity analyses examined the effect of imbalances in baseline participant characteristics using multiple logistic regression models to estimate odds ratios and 95% CIs [confidence intervals] for point prevalence abstinence at 12 and 24 weeks, adjusting for characteristics for which the absolute value of the standardized difference was 0.1 or greater. We conducted additional post hoc analyses: (1) to examine potential clustering by site using generalized linear mixed models with a random effect for site to estimate odds ratios and 95% CIs for point prevalence abstinence at 12 and 24 weeks, and (2) to compare the baseline characteristics of participants with self-reported smoking data at 12 weeks (primary end point) with those of participants without self-reported smoking data. Statistical analyses were performed using SAS statistical software (version 9.4; SAS Institute).”</p>
                            <p>“Several prespecified sensitivity analyses were done. First, assessment of the effect of missing data on the primary outcome was done using multiple imputation by chained equations method (MICE). This imputation model included all the variables in the primary ITT [intention to treat] analysis, secondary outcomes (from each timepoint), and baseline variables associated with the missingness of the primary outcome. 20 imputed datasets were generated and combined using Rubin’s rules, and the primary analysis model was then repeated using the imputed data. We specified a priori the following potential exploratory analyses to assess effect modification on the primary outcome: baseline hypertension, baseline MMSE [Mini-Mental State Examination], baseline age, time since Alzheimer’s disease diagnosis, baseline brain volume, and change in systolic blood pressure. A post-hoc analysis was also done to investigate for differences between aggregated and disaggregated MRI [magnetic resonance imaging] data (according to MRI scanner modality) for the primary outcomes.”</p>
                            <p>“Four sensitivity analyses were done examining the primary outcome: restricted to women who had not received antibiotics in the 7 days before delivery, to examine whether any masking of a prophylactic effect was occurring by inclusion of pretreated women; excluding women prescribed antibiotics (other than the trial intervention) within the first 24 h after delivery, and who might therefore already have had an infection at the time of administration of the intervention; restricted to women whose primary outcome was obtained between weeks 6 and 10 after delivery to exclude any biases by over-reporting of outcomes from data returned at a later timepoint or under-reporting of outcomes in data returned at an earlier timepoint; and including centre as a random effect. No subgroup analyses were planned; however, we did a post-hoc subgroup analysis of the primary outcome according to mode of birth (forceps or vacuum extraction). More stringent 99% CIs [confidence intervals] are presented for the estimate of RR [risk ratio] for this post-hoc subgroup analysis.”</p>
                            <p>“A prespecified subgroup analysis for the primary outcomes, testing for an interaction for baseline anxiety, depression, and opioid use, defined using their median values was completed. Prespecified sensitivity analyses for the primary outcome, excluding participants included in process evaluation interviews, adjusting for the imbalance of death, and split by baseline pain disorders were also completed. Because of the potential for type I error due to multiple comparisons, findings for analyses of secondary end points should be interpreted as exploratory. Statistical analyses were conducted using Stata version 16.1 (StataCorp).”</p>
                        `,
                        consort_explanation: `
                            <p>Sensitivity analyses can be important additional analyses to examine the robustness of the primary trial results under a range of assumptions about the data, methods, and models that differ from those of the primary analysis. When the findings from a sensitivity analysis are consistent with the primary trial findings, trialists can be confident that any assumptions in the primary analysis had little impact—strengthening the trial results. Morris and colleagues provide a principled approach to guide any sensitivity analyses by posing three questions to trialists: does the proposed sensitivity analysis address the same question as the primary analysis; is it possible for the proposed sensitivity analysis to return a different result to the primary analysis; and if the results do differ, is there any uncertainty as to which will be believed.</p>
                            <p>Subgroup analyses are another set of additional analyses that are widely carried out and reported. Here, the focus is on those analyses that look for evidence of a difference in treatment effect in complementary subgroups (eg, older and younger participants), a comparison known as a test of interaction. Empirical analyses of subgroup difference claims for factors such as age, sex, race, ethnicity, and other factors show selective reporting, frequent lack of proper statistical support, and poor independent corroboration.</p>
                            <p>A common but misleading approach is to compare P values for separate analyses of the treatment effect in each group. Categorising continuous variables to create subgroups is often done for simplicity and because it is perceived as easier to understand and communicate. Major limitations of the approach include the splitting of a continuous variable into discrete subgroups by arbitrarily chosen cut-off points that lack clinical or biological plausibility, which loses information, and thus reduces statistical power. Choosing cut-off points based on achieving statistical significance should be avoided. It is incorrect to infer a subgroup effect (interaction) from one significant (in one subgroup) and one non-significant P value (in another subgroup). The rationale for any subgroups should be outlined (including how they are defined), along with whether the subgroups were specified a priori in the protocol or statistical analysis plan or were done post hoc. Because of the high risk for spurious findings, subgroup analyses are often discouraged. Post hoc subgroup comparisons (analyses done after looking at the data) are especially likely not to be confirmed by further studies. Most of these analyses do not have substantial credibility.</p>
                            <p>An alternative and stronger approach, which avoids the need to specify cut-off points to assess the interaction between a continuous variable (eg, age) and treatment effect would be to fit a regression model, which can be presented graphically to examine how the estimated treatment effects varies with the level of the variable. These analyses are more complex, requiring model assumptions to capture the relationship (linear or non-linear) between the variable and the treatment effect. Authors should clearly describe the statistical methods used to explore the treatment-covariate interaction.</p>
                        `,
                        nut_ext: `
                                <br />(i) Methods for nutritional data analysis, e.g., method(s) used to combine dietary or nutritional data, energy or other adjustments, intake modelling, use of weighting factors
                                <br />(ii) For any non-randomized comparisons (e.g., per-protocol or as-treated), describe the strategy used to select and adjust for potential confounders.
                                <br />(iii) Describe the selection and statistical handling of potential effect moderators [e.g., habitual diet, baseline nutritional status, socioeconomic status, nutritional knowledge of participants and interventionists (especially for education interventions)].
                        `,
                        nut_explanation: `
                            <p>Additional analyses are often necessary to fully interpret the results of nutrition trials. It is critical to distinguish between analyses that were planned before a trial was executed from those conducted after seeing the data, as the latter have a higher tendency to produce chance findings. One type of additional analysis that is often important in nutrition research is exploring effect modification, where an intervention’s effect may differ based on participants’ baseline characteristics, such as background level of nutrients, foods, or dietary patterns. When participants are already sufficient in a nutrient, little effect of providing additional amounts of the nutrient may be expected. For example, a large RCT of vitamin D and omega-3, the VITAL study, reported no effect of supplementation on fracture incidence. The trial included all otherwise eligible participants regardless of vitamin D status for greater generalizability. The strength of the evidence for vitamin D on bone outcomes from this trial design is being debated, even though no benefit was found at various thresholds of one indicator of vitamin D status, i.e. serum 25-hydroxyvitamin D. In one prespecified subgroup analysis of VITAL, participants with baseline vitamin D status below the median who received vitamin D had less loss of spine and hip bone mineral density. As was done in the VITAL trial, such analyses should be reported transparently (i.e., report all additional analyses that were performed regardless of the results) and interpreted cautiously regarding causal claims, and viewed as hypothesis-generating for future randomized trials.</p>
                            <p>Beyond moderation, other specific analyses require clear reporting. As discussed in item 21b, when conducting analyses that break the original randomization (e.g., per-protocol or as-treated analyses), the groups may no longer be comparable, creating a risk of confounding. In these situations, authors should report their strategy for selecting and adjusting for potential confoundings - and whether this strategy was prespecified - to provide a less biased estimate of the intervention’s effect.</p>
                        `,
                        nut_examples: `
                            <p>“Subgroup analyses showed a possible lower incidence of the primary cardiovascular end point with n−3 supplementation than with placebo among participants with low fish consumption (Fig. 2). Additional subgroup analyses are presented in Tables S3 and S4 and Figure S3 in the Supplementary Appendix, with a focus on exploring differences according to racial or ethnic group, diabetes status, number of traditional cardiovascular risk factors, dietary fish intake, and other variables for the primary end point of major cardiovascular events and the secondary end point of total myocardial infarction. For myocardial infarction, these analyses are presented as explanatory analyses to assess whether the effect of the intervention was similar across subgroups. The suggestion of greater differences in the risk of myocardial infarction among blacks and among those with low fish intake, comparing the n−3 group with the placebo group, … .” (Manson et al., 2019)</p>
                        `
                    },
                ]
            },
            // --- RESULTS ---
            {
                group: 'Results',
                items: [
                {
                        id: '22a',
                        title: 'Participant flow',
                        text: 'For each group, the numbers of participants who were randomly assigned, received intended intervention, and were analysed for the primary outcome',
                        consort_examples: `
                            <p>See figure 1, figure 2, and figure 3.</p>
                        `,
                        consort_explanation: `
                            <p>The design and conduct of some randomised trials are straightforward, and the flow of participants, particularly where there are no losses to follow-up or exclusions, through each phase of the study can be described relatively easily. For other trials, it can be difficult for readers to discern whether and why some participants did not receive the treatment as allocated, were lost to follow-up, or were excluded from the analysis. This information is crucial for several reasons. Participants who were excluded after allocation are unlikely to be representative of all participants in the study. For example, participants may not be available for follow-up evaluation because they experienced an acute exacerbation of their illness or harms of treatment.</p>
                            <p>Attrition as a result of loss to follow-up, which is often unavoidable, needs to be distinguished from investigator-determined exclusion for such reasons as ineligibility, withdrawal from treatment, and poor adherence to the trial protocol. Erroneous conclusions can be reached if participants are excluded from analysis, and imbalances in such omissions between groups may be especially indicative of bias. Information about whether the investigators included in the analysis all participants who underwent randomisation, in the groups to which they were originally allocated (item 21b), is therefore of particular importance. Knowing the number of participants who did not receive the intervention as allocated or did not complete treatment permits the reader to assess to what extent the estimated efficacy of therapy might be underestimated in comparison with ideal circumstances.</p>
                            <p>If available, the number of people assessed for eligibility, and reason for exclusion, should also be reported. Although this number is relevant to external validity only and is arguably less important than the other counts, it is a useful indicator of whether trial participants were likely to be representative of all eligible participants.</p>
                            <p>A suggested template for reporting the number of participants who were randomly assigned, received intended treatment, were lost to follow-up, and were analysed for the primary outcome is shown in figure 1, and the counts required are described in detail in table 7. A review of randomised trials published in general medical journals found that reporting of what happened to participants and their data was considerably more thorough in articles that included a diagram of the flow of participants through a trial than in those that did not.</p>
                            <p>Some information, such as the number of individuals assessed for eligibility, may not always be known, and depending on the nature of a trial, some counts may be more relevant than others. It will sometimes be useful or necessary to adapt the structure of the flow diagram to a particular trial. In some situations, other information may usefully be added. For example, for trials of non-pharmacological interventions it may be important to report the number of care providers or centres performing the intervention in each group and the number of participants treated by each care provider or in each centre.</p>
                            <p>The exact form and content of the flow diagram may be varied according to specific features of a trial. For example, many trials of surgery or vaccination do not include the possibility of discontinuation. Although CONSORT strongly recommends using a flow diagram to communicate participant flow throughout the study, there is no specific, prescribed format.</p>
                        `,
                        nut_ext: 'No formal extension, but specific advice provided: Include a flow diagram; understand reasons for loss to follow-up (e.g., food aversion).',
                        nut_explanation: `
                            <p>Participant flow information is important to interpret the representativeness, external and internal validity and the final power achieved to detect the effect size of interest. These data gain particular importance in nutrition trials, given that behavioural interventions for dietary modification in free-living populations have a high loss to follow-up after 6 months. Though there is no specific additional recommendation in CONSORT-Nut 2025 for reporting in nutrition trials, CONSORT-Nut 2025 recognizes the importance of including a participant flow diagram in every nutrition trial report.</p>
                            <p>Understanding the reasons for the loss to follow-up is important to gauge the sustainability of the dietary intervention. Excessive loss to follow-up in a study group may indicate food aversion or that the intervention is not practical in the population. The lack of practicality could be due to low affordability or availability of recommended foods within the existing food environment, poor taste or lack of cultural acceptability of the recommended food or dietary modification for the participants.</p>
                        `,
                        nut_examples: `
                            <p>Lean et al (2018) contains an example flow diagram from a multi-centre, open-label, cluster randomised trial, the DiRECT trial, and Bauer et al (2011) contains an example flow diagram from a double-blind crossover study (Figure 2, a and b).</p>
                        `
                    },
                    {
                        id: '22b',
                        title: 'Participant flow',
                        text: 'For each group, losses and exclusions after randomisation, together with reasons',
                        consort_examples: `
                            <p>See figure 2.</p>
                        `,
                        consort_explanation: `
                            <p>Some protocol deviations may be reported in the flow diagram (item 22a), for example, participants who did not receive the intended intervention. If participants were excluded after randomisation (contrary to the intention-to-treat principle) because they were found not to meet eligibility criteria, they should be included in the flow diagram. Use of the term “protocol deviation” in published articles is not sufficient to justify exclusion of participants after randomisation. The nature of the protocol deviation and the exact reason for excluding participants after randomisation should always be reported. Similarly, if participants did not complete the treatment intervention as allocated (ie, discontinued treatment), this should be reported by trial group, with reasons.</p>
                            <p>While attrition as a result of loss to follow-up is often unavoidable, it is important to report the number of participants who do not complete follow-up as planned; this should be reported by trial group along with reasons. For the primary outcome, loss to follow-up can be reported in the flow diagram.</p>
                        `,
                        nut_ext: 'No formal extension, but specific advice provided: Understand reasons for loss to follow-up (e.g., food aversion).',
                        nut_explanation: `
                            <p>Participant flow information is important to interpret the representativeness, external and internal validity and the final power achieved to detect the effect size of interest. These data gain particular importance in nutrition trials, given that behavioural interventions for dietary modification in free-living populations have a high loss to follow-up after 6 months. Though there is no specific additional recommendation in CONSORT-Nut 2025 for reporting in nutrition trials, CONSORT-Nut 2025 recognizes the importance of including a participant flow diagram in every nutrition trial report.</p>
                            <p>Understanding the reasons for the loss to follow-up is important to gauge the sustainability of the dietary intervention. Excessive loss to follow-up in a study group may indicate food aversion or that the intervention is not practical in the population. The lack of practicality could be due to low affordability or availability of recommended foods within the existing food environment, poor taste or lack of cultural acceptability of the recommended food or dietary modification for the participants.</p>
                        `,
                        nut_examples: `
                            <p>Lean et al (2018) contains an example flow diagram from a multi-centre, open-label, cluster randomised trial, the DiRECT trial, and Bauer et al (2011) contains an example flow diagram from a double-blind crossover study (Figure 2, a and b).</p>
                        `
                    },
                    {
                        id: '23a',
                        title: 'Recruitment',
                        text: 'Dates defining the periods of recruitment and follow-up for outcomes of benefits and harms',
                        consort_examples: `
                            <p>“Age-eligible participants were recruited . . . from February 1993 to September 1994 . . . Participants attended clinic visits at the time of randomization (baseline) and at 6-month intervals for 3 years.”</p>
                            <p>“The trial involved five visits: Visit 1 on day 1 (screening, randomization and initial dosing), Visit 2 on day 2 (assessment of the primary endpoint), Visit 3 on day 4 (assessment of efficacy and safety parameters), Visit 4 on day 6 (end-of-treatment visit) and Visit 5 on day 8 to day 10 (follow up by telephone interview). Patients were asked to return all unused trial medication and their diaries at each visit.” (Note: In this example, the term “safety” is used as a reference to harm outcomes; we recommend against the use of “safety”; preferable terms are “harms” or “adverse events.”)</p>
                        `,
                        consort_explanation: `
                            <p>Knowing when a study took place and over what period participants were recruited places the study in historical context. Medical and surgical treatments, including concurrent treatments, evolve continuously and may affect the routine care given to participants during a trial. Thus, it is important to report the periods of recruitment into the trial. Knowing the rate at which participants were recruited may also be useful, especially to other investigators.</p>
                            <p>The length of follow-up is not always a fixed period after randomisation. In many randomised trials in which the outcome is time to an event, follow-up of all participants is ended on a specific date. This date should be given, and it is also useful to report the minimum, maximum, and median duration of follow-up. A review of reports in oncology journals that used survival analysis, most of which were not randomised trials, found that nearly 80% included the starting and ending dates for accrual of patients, but only 24% also reported the date on which follow-up ended.</p>
                            <p>Information on the periods of recruitment and follow-up may be different for outcomes of benefits and harm. For example, the assessment of harms might be planned to take place during the entire study through non-systematic assessment, might occur during only part of the study duration, might occur at specific time points using systematic or non-systematic assessment, or might continue after the completion of follow-up for the main efficacy outcome. Reporting the periods of recruitment and follow-up for benefits and harms is important to allow comprehensive and accurate interpretation of the trial’s results.</p>
                        `,
                        nut_ext: 'No formal extension for item 23a pertaining to nutrition trials. However, authors are advised to keep the specific advice below in mind while reporting trial findings.',
                        nut_explanation: `
                            <p>In general, this chronological information is useful for understanding the recruitment rate and helps estimate recruitment timeframe for future trials. Additionally, nutritional exposures and/or outcomes may be time-sensitive and affected by the season of data collection. For example, seasonal variations in dietary intake, and nutrition status have been reported in literature. Also, food policy can affect consumer behaviour with consequences for dietary intake. The recent coronavirus pandemic and the public health measures to tackle its spread had negative impacts on the food environments by affecting the food supply chain, changed consumer purchase behaviours and also necessitated adjustments to data collection strategies for nutrition trials ongoing during the lockdown period. Thus the timing of data collection may affect dietary intake, adherence to dietary intervention and the nutrition or health outcome measured. Therefore, for nutrition trials, chronological data help interpret the results within a contextual understanding of food availability, affordability, overall acceptability and seasonality of the intervention and facilitates evaluating the limits to the transferability of the evidence.</p>
                        `,
                        nut_examples: `
                            <p>“From October 30, 2019 to December 12, 2020, 2,016 women were assessed for eligibility, of whom 1,897 were randomized (960 control and 937 intervention).” (de Kok et al., 2022)</p>
                            <p>“Between March 31, 2009, and June 2, 2014, we assessed 8820 women for eligibility and recruited 1555... .“ (Poston et al., 2015)</p>
                            <p>“From June 25, 2003, through June 30, 2009, a total of 8713 candidates were screened for eligibility, and 7447 were assigned to one of the three intervention groups…  Participants were followed for a median of 4.8 years (interquartile range, 2.8 to 5.8).” (Estruch et al., 2018)</p>
                        `
                    },
                    {
                        id: '23b',
                        title: 'Reason for trial termination',
                        text: 'If relevant, why the trial ended or was stopped',
                        consort_examples: `
                            <p>“At the time of the interim analysis, the total follow-up included an estimated 63% of the total number of patient-years that would have been collected at the end of the study, leading to a threshold value of 0.0095, as determined by the Lan-DeMets alpha-spending function method . . . At the interim analysis, the RR [risk ratio] was 0.37 in the intervention group, as compared with the control group, with a p value of 0.00073, below the threshold value. The Data and Safety Monitoring Board advised the investigators to interrupt the trial and offer circumcision to the control group, who were then asked to come to the investigation centre, where MC (medical circumcision) was advised and proposed . . . Because the study was interrupted, some participants did not have a full follow-up on that date, and their visits that were not yet completed are described as ‘planned’ in this article.”</p>
                            <p>“In January 2000, problems with vaccine supply necessitated the temporary nationwide replacement of the whole cell component of the combined DPT/Hib vaccine with acellular pertussis vaccine. As this vaccine has a different local reactogenicity profile, we decided to stop the trial early.”</p>
                        `,
                        consort_explanation: `
                            <p>Arguably, trialists who arbitrarily conduct unplanned interim analyses after very few events accrue using no statistical guidelines run a high risk of catching the data at a random extreme, which likely represents a large overestimate of treatment benefit.</p>
                            <p>Readers will likely draw weaker inferences from a trial that was truncated in a data driven manner versus one that reports its findings after reaching a results-independent goal. Where relevant, authors should report the reason for stopping the trial before completion as planned (eg, result of an interim analysis, lack of funding, poor recruitment of participants, intervention no longer available, or the question becoming no longer relevant after publication of another study). Authors should also disclose factors extrinsic to the trial that affected the decision to stop the trial, and who made the decision to stop the trial, including reporting the role the funding agency had in the deliberations and in the decision to stop the trial.</p>
                            <p>A systematic review of 143 randomised trials that were stopped earlier than planned for benefit found that these trials reported stopping after accruing a median of 66 events. The review estimated a median relative risk of 0.47 and a strong association between the number of events accrued and the magnitude of the effect, with smaller trials with fewer events yielding the largest treatment effects. While an increasing number of trials published in high impact medical journals report stopping early, many still do not report how the decision to stop the trial was made. In a systematic review of 110 paediatric trials that reported on the presence of a data monitoring committee, interim analysis, or early stopping, 32 were terminated early. Of these 32 trials, 22 (69%) did not report predefined stopping guidelines and 15 (47%) did not provide information on statistical monitoring methods.</p>
                        `,
                        nut_ext: 'No formal extension, but specific advice provided: Make absence of interim results explicit and justify early stopping (may indicate poor sustainability).',
                        nut_explanation: `
                            <p>When nutrition trials are stopped prematurely for reasons other than having crossed the prespecified stopping boundaries for interim analysis, it is important to make the absence of interim results explicit and provide reasons as to why the trial was ceased. Without justification, the decision to stop the nutrition trial early may indicate other drivers for trial failure such as poor sustainability of the dietary intervention in the targeted population.</p>
                        `,
                        nut_examples: `
                            <p>“Yearly interim analyses began on March 2008 after a median of 2 years of follow-up. With the use of O’Brien–Fleming stopping boundaries, the P values for stopping the study at each yearly interim analysis were 5×10−6, 0.001, 0.009, and 0.02 for benefit and 9×10−5, 0.005, 0.02, and 0.05 for adverse effects. The stopping boundary for the benefit of the Mediterranean diets with respect to the primary end point was crossed at the fourth interim evaluation; on July 22, 2011, the data and safety monitoring board recommended stopping the study on the basis of end points documented through December 1, 2010… .” (Estruch et al., 2018)</p>
                        `
                    },
                    {
                        id: '24a',
                        title: 'Intervention and comparator delivery',
                        text: 'Intervention and comparator as they were actually administered (eg, where appropriate, who delivered the intervention/comparator, whether participants adhered, whether they were delivered as intended (fidelity))',
                        consort_examples: `
                            <p>“Patients were randomly assigned to the P2Y12 inhibitor monotherapy group . . . Overall adherence to the study protocol was 79.3% in the P2Y12 inhibitor monotherapy group and 95.2% in the DAPT group . . . The rates of P2Y12 inhibitor use were similar in both groups: 96.4% at 6 months and 95.0% at 12 months in the P2Y12 inhibitor monotherapy group and 98.1% at 6 months and 96.6% at 12 months in the DAPT group. The median duration of aspirin was 96 days (interquartile range, 88-118 days) in the P2Y12 inhibitor monotherapy group and 365 days (interquartile range, 363-365) in the DAPT group. The proportion of patients receiving aspirin beyond 3 months in the P2Y12 inhibitor monotherapy group was 14.4% at 6 months and 8.9% at 12 months.”</p>
                            <p>“Most participants received treatment as allocated. Across intervention groups, high protocol adherence was achieved in terms of the delivery, type, and content for the injection, progressive exercise, and best practice advice interventions. 53 physiotherapists delivered corticosteroid injections to 329 (97%) participants and three doctors to ten (3%) participants. Progressive exercise was delivered by 104 physiotherapists to 339 participants and best practice advice was delivered by 83 physiotherapists to 324 participants. Two physiotherapists swapped groups during the trial because of staffing issues and delivered both interventions. We found no difference in attendance rates between those receiving progressive exercise or best practice advice and those who received the intervention in conjunction with corticosteroid injection.”</p>
                        `,
                        consort_explanation: `
                            <p>This new item has been added to the CONSORT 2025 checklist to address the poor reporting of the intervention and comparator in randomised trials. For example, in a review of 102 randomised trials evaluating bariatric surgery, only 14% reported the intervention as implemented. A review of 192 randomised trials assessing pharmacological treatments in six major chronic diseases published in journals with high impact factors showed that adherence to medication was reported in only one third of the publications.</p>
                            <p>There is frequently a gap between the intervention/comparator as planned and described in the trial protocol and how the intervention/comparator were actually administered. This gap could be related to poor fidelity, which can be driven by the extent to which the intervention/comparator are implemented as planned in the protocol by practitioners, and/or poor adherence to treatment, defined as the extent to which participants comply with the care providers’ recommendations (eg, taking a drug, placebo, behavioural change, doing exercises). This gap could also be related to the expected diversity in the implementation of the intervention/comparator in clinical practice particularly for complex interventions.</p>
                            <p>The gap between the intervention/comparator as planned and as delivered also depends on how the trial was planned. In explanatory trials, the aim is to estimate treatment effect under ideal circumstances. The intervention/comparator are usually highly standardised with close monitoring of fidelity and adherence to interventions and strategies to increase them. Intensive efforts to maximise fidelity and adherence in early phase trials or explanatory trials may lead to unrealistic, inflated estimates of treatment benefit that cannot be reproduced under real life circumstances. Reporting the results of this monitoring is essential to allow readers to interpret the study results.</p>
                            <p>In contrast, pragmatic trials aim to determine treatment effect in clinical conditions. The intervention and comparator are usually highly flexible, and measurement of fidelity and adherence is unobstructive with no strategies to maintain or improve them. Reporting how the intervention/comparator were actually administered is nevertheless crucial to allow readers to accurately interpret the trial results. For example, in a large international randomised trial comparing endarterectomy to medical management for patients with symptomatic carotid artery stenosis, there were important differences in the delay in receiving the surgical procedure which impacted the outcomes.</p>
                            <p>Authors should provide details on who actually delivered the intervention/comparator (number and expertise), how the intervention/comparator were delivered, what was actually administered, participants’ adherence to treatment, and the caregiver’s fidelity to the intervention/comparator protocol where appropriate. Reporting fidelity and adherence can be complex and vary according to the type of intervention or comparator (eg, one-off, short term repeated, long term repeated). Various deviations to the protocol can occur. Participants might initiate the intervention/comparator but then discontinue the intervention/comparator permanently and completely after a specific period of time, discontinue temporarily, reduce the dose, or modify the schedule.</p>
                            <p>More detailed information is available in TIDieR and the CONSORT extension for non-pharmacological treatments (item 13).</p>
                        `,
                        nut_ext: 'No formal extension for item 24a pertaining to nutrition trials. However, authors are advised to keep the specific advice below in mind while reporting trial findings.',
                        nut_explanation: `
                            <p>The following examples from dietary supplement and behavioural intervention trials are provided to help clarify the CONSORT-2025 statement as it applies to nutrition trials:</p>
                        `,
                        nut_examples: `
                            <p>“This was a dietitian-led intervention where all participants consulted the study dietitian fortnightly, received resources including recipes and meal plans, and those in the intervention arm collected study foods representing the MedDiet, including canned fish, legumes, walnut, peanut, and almond mix, Greek yoghurt, and extra virgin olive oil.” (Murphy et al., 2022)</p>
                            <p>“ Among women in the intervention group, 92% (n = 200) consumed the complete portion of the fortified BEP supplement (72 g) the day prior to the assessment. Twelve women indicated that they consumed a part of it (0.5 or 0.75 portion) and 5 women did not consume the BEP supplement at all. Reasons for not consuming the BEP supplement included not feeling well, not feeling hungry, or not receiving the visit from the trial community support staff who provide the daily supplement. Two women from the control group indicated having consumed the BEP supplement. One woman in the control group and 5 women in the intervention group did not take the IFA tablet. No women reported the consumption of any other type of nutritional supplement .” (de Kok et al., 2021)</p>
                            <p>“The feasibility of the intervention was assessed using recruitment and retention rates. Intervention fidelity and participant engagement were evaluated via group session attendance (intervention phase) and self-reported usage of LEAP2 (intervention and behaviour maintenance phases) in the MD and MD + PA groups. Acceptability of the intervention was assessed at 24 and 48 weeks by a custom questionnaire using 5-point Likert-type scales, informed by the Theoretical Framework of Acceptability .” (Jennings et al., 2024)</p>
                        `
                    },
                    {
                        id: '24b',
                        title: 'Concomitant care',
                        text: 'Concomitant care received during the trial for each group',
                        consort_examples: `
                            <p>“The principal investigators invited hospitals with the capability to provide the current standard of care for covid-19 to participate in the study. Minimum requirements for the standard of care included the provision of intravenous fluids, supplemental oxygen, regular laboratory testing, SARS-CoV-2 testing, haemodynamic monitoring, and intensive care, as well as the ability to deliver concomitant medications . . .”</p>
                            <p>“90 (60%) patients received concomitant drug treatment before randomisation. Among these, 52 (35%) patients received antiviral treatment [table 9] . . . Concomitant treatments, including antiviral agents, antibiotics, and systemic glucocorticoid therapy, were similar in the two groups [table 9].”</p>
                        `,
                        consort_explanation: `
                            <p>Concomitant care refers to any additional treatments, interventions, or medications that participants may have received during the trial period, in addition to the study interventions. Relevant concomitant care refers to interventions that could have affected the outcome. Transparently reporting this information is essential for readers to understand the context in which the trial was conducted and be able to assess the potential influence of concomitant care on the trial’s results. Particularly, readers should be aware of any unequal use of concomitant care that might affect the outcome between the intervention and comparator groups. This is particularly important when the trials are not fully blinded. This information could be particularly important for evaluating the risk of bias due to deviations from the intended interventions, an important domain of the risk-of-bias tool developed by Cochrane.</p>
                            <p>Nevertheless, this information is poorly reported. A review of 164 cardiovascular clinical trials published in five influential medical journals from 2011 to 2021 showed that cointerventions were inadequately reported in 71% of the trials and that trials with deficient reporting had larger treatment effect estimates on average. In rheumatology, an assessment of 109 trials in leading journals from 2018 to 2020 found that only 57% of randomised trials provided the number of patients on concomitant medications at baseline, and only 5% reported the cumulative or mean exposure data for concomitant medications.</p>
                            <p>Authors should report the number and percentage of participants receiving the different relevant concomitant care in each arm and, where relevant, the cumulative or average for each concomitant intervention taken over the trial period for each group.</p>
                        `,
                        nut_ext: 'No formal extension for item 24b pertaining to nutrition trials. However, authors are advised to keep the specific advice below in mind while reporting trial findings.',
                        nut_explanation: `
                            <p>Fidelity, a multi-domain concept that describes the extent to which an intervention was delivered as intended and differentiated from the comparator relies on two major aspects: (i) the competence with which the intervention was delivered by the provider and (ii) the level of adherence to intervention by the participants. While capturing and reporting the data may be less challenging in trials using dietary supplements, behavioural interventions pose challenges. In interventions that use behavioural change strategies, nutrition education or counselling techniques to modify diets, without sufficient information to assess fidelity of intervention delivery, intervention acceptability and the level of adherence in participants and the type and extent of differentiation from the comparator achieved, it is impossible to unequivocally ascribe the treatment effect to the dietary intervention. Additionally, since nutrition is often offered as an adjunct/support to medical treatment, physical training or other modalities, description of the concomitant care received by the participants during the trial for each group is important to allow for evaluation of dietary treatment effects.</p>
                        `,
                        nut_examples: `
                            <p>“ Mean drug prescriptions (including antidiabetic, antihypertensive, lipid-lowering, and all other medications) at baseline were 5·6 (SD 3·5) in the intervention group and 5·7 (3·8) in the control group; at 12 months, these figures were 4·8 (4·3) and 6·5 (4·1), respectively (p<0·0001). Antidepressant drugs were being taken by 40 (27%) participants in the intervention group and 28 (19%) participants in the control group at baseline; no significant change was observed at 12 months (n=40 [27%] vs n=31 [21]; p=0·2506; appendix). In the intervention group, the proportion of participants taking no prescription drugs increased from 2% (n=3) at baseline to 11·5% (n=17) at 12 months, with no change in the control group (n=3 [2%] at both timepoints; Fisher's exact p=0·0018) .” (Lean et al., 2018)</p>
                        `
                    },
                    {
                        id: '25',
                        title: 'Baseline data',
                        text: 'A table showing baseline demographic and clinical characteristics for each group',
                        consort_examples: `
                            <p>See table 10.</p>
                        `,
                        consort_explanation: `
                            <p>Although the eligibility criteria (item 12a) indicate who was eligible for the trial, it is also important to know the characteristics of the participants who were actually included. This information allows readers, especially clinicians, to judge how relevant the results of a trial might be to an individual patient. Participant baseline demographics may include characteristics such as age, sex and/or gender, place of residence, race and/or ethnicity, culture and/or religion, language, occupation, education, or socioeconomic status. Baseline clinical characteristics include those which are identical, or closely related, to the trial outcomes.</p>
                            <p>Randomised trials aim to compare groups of participants that differ only with respect to the intervention (treatment). Although proper random assignment prevents selection bias, it does not guarantee similarity of the groups at baseline. Any differences in baseline characteristics are, however, the result of chance rather than bias. Important demographic and clinical characteristics should be presented so that readers can assess how similar the groups were at baseline. Baseline data are especially valuable for outcomes that can also be measured at the start of the trial (eg, blood pressure).</p>
                            <p>Baseline information is most efficiently presented in a table. For continuous variables, such as weight or blood pressure, the variability of the data should be reported, along with average values. Continuous variables can be summarised for each group by the mean and standard deviation. When continuous data have an asymmetrical distribution, a preferable approach may be to quote the median and percentile values (eg, the 25th and 75th percentiles). Standard errors and CIs are not appropriate for describing variability—they are inferential rather than descriptive statistics. Variables with a small number of ordered categories (such as stages of disease I to IV) should not be treated as continuous variables; instead, numbers and proportions should be reported for each category.</p>
                            <p>Significance testing of baseline differences is not recommended and should not be reported. Such significance tests assess the probability that observed baseline differences could have occurred by chance; however, providing the randomisation has not been subverted or comprised, any differences are caused by chance. Unfortunately, such significance tests are still relatively common. Such hypothesis testing is superfluous and can mislead investigators and their readers. Rather, comparisons at baseline should be based on consideration of the prognostic strength of the variables measured and the magnitude of any chance imbalances that have occurred.</p>
                        `,
                        nut_ext: 'No formal extension for item 25 pertaining to nutrition trials. However, authors are advised to keep the specific advice below in mind while reporting trial findings.',
                        nut_explanation: `
                            <p>Nutrition trials vary from other clinical trials given that everyone has a dietary exposure prior to enrolment. Baseline food intake, dietary pattern, or nutritional status could modify the intervention effect. Hence, an appropriate marker of these characteristics should be included for each group in the table describing baseline data. An objective biomarker of baseline nutritional status (e.g. of dietary pattern/food/nutrient/bioactive intake or other biological assessment of status related to the intervention studied) is preferred. However, if measurement of such biomarkers or signature metabolites were not feasible or unavailable, related and proxy measurements of food and nutrient intakes or functional biomarkers (e.g. anthropometrics, clinical measures, or dietary/nutrient/bioactive intake assessment) should be considered for reporting. It is also important to include data on usage of medications relating to the studied outcomes. These data help practitioners gauge the applicability of the evidence in their practice and determine the suitability of the treatment for specific individuals or groups.</p>
                        `,
                        nut_examples: `
                            <p>“Table S1. Characteristics of the 25,871 Participants at Baseline, According to Randomized Assignment to Marine n−3 Fatty Acids or Placebo.” (Manson et al., 2019)</p>
                        `
                    },
                    {
                        id: '26',
                        title: 'Outcomes and estimation',
                        text: 'For each primary and secondary outcome, by group: the number of participants included in the analysis; the number of participants with available data at the outcome time point; result for each group, and the estimated effect size and its precision (such as 95% CI); for binary outcomes, presentation of both absolute and relative effect size',
                        consort_examples: `
                            <p>“All principal analyses were based on the intention-to treat (ITT) principle, analysing participants in the groups to which they were randomly assigned irrespective of compliance with treatment allocation.”</p>
                            <p>See table 11, table 12, and table 13.</p>
                        `,
                        consort_explanation: `
                            <p>For each primary and secondary outcome, the number of participants included in each group is an essential element of the analyses. Although the flow diagram (item 22a) should indicate the numbers of participants included in the analysis of the primary outcome, the number of participants with available data will often vary for different outcomes and at different time points.</p>
                            <p>Missing data can introduce potential bias through different types of participants being included in each treatment group. It can also reduce, through loss of information, the power to detect a difference between treatment groups if one exists (item 21c) and reduce the generalisability of the trial findings. It is therefore important to report the number of participants with available data for each primary and secondary outcome and at each timepoint. Where possible, it is also important to report the reason data were not available, for example, if the participant did not attend follow-up appointments, or if data were truncated because the participant died. The extent and causes of missing data can vary. For example, a systematic review of palliative care trials estimated that 23% of primary outcome data were not available; this compares to a recent review of trials published in four top general medical journals where the median percentage of participants with a missing outcome was around 9%.</p>
                            <p>Trial results are often more clearly displayed in a table rather than in the text, as shown in table 11 and table 12. For each outcome, results should be reported as a summary of the outcome in each group (eg, the number of participants included in the analysis with or without the event and the denominators, or the mean and standard deviation of measurements), together with the contrast between the groups, known as the effect size. For binary outcomes, the effect size could be the risk ratio (relative risk), odds ratio, or risk difference; for survival time data, it could be the hazard ratio or difference in median survival time; and for continuous data, it is usually the difference in means.</p>
                            <p>For all outcomes, authors should provide a CI to indicate the precision (uncertainty) of the estimated effect size. A 95% CI is conventional, but occasionally other levels are used. Most journals require or strongly encourage the use of CIs. They are especially valuable in relation to differences that do not meet conventional statistical significance, for which they often indicate that the result does not rule out an important clinical difference. The use of CIs has increased markedly in recent years, although not in all medical specialties. A common error is the presentation of separate CIs for the outcome in each group rather than for the treatment effect. Although P values may be provided in addition to CIs, results should not be reported solely as P values. Results should be reported for all planned primary and secondary outcomes and at each time point, not just for analyses that were statistically significant or thought to be interesting. Selective reporting within studies is a widespread and serious problem.</p>
                            <p>When the primary outcome is binary, both the relative effect (risk ratio (relative risk) or odds ratio), and the absolute effect (risk difference) should be reported (with CIs) (table 13), as neither the relative measure nor the absolute measure alone gives a complete picture of the effect and its implications. Different audiences may prefer either relative or absolute risk, but both clinicians and lay people tend to overestimate the effect when it is presented solely in terms of relative risk. The magnitude of the risk difference is less generalisable to other populations than the relative risk since it depends on the baseline risk in the unexposed group, which tends to vary across populations. For diseases where the outcome is common, a relative risk near unity might nonetheless indicate clinically important differences in public health terms. In contrast, a large relative risk when the outcome is rare may not be so important for public health (although it may be important to an individual in a high risk category). For both binary and survival time data, expressing the results also as the number needed to treat for benefit or harm can be helpful.</p>
                        `
                    },
                    {
                        id: '27',
                        title: 'Harms',
                        text: 'All harms or unintended events in each group',
                        consort_examples: `
                            <p>“Few women vomited after drug administration. 12 (0.2%) of 6685 sulfadoxine–pyrimethamine, 19 (0.3%) of 7014 dihydroartemisinin–piperaquine, and 23 (0.3%) of 6849 dihydroartemisinin–piperaquine plus azithromycin treatment courses were vomited within 30 min . . . All three regimens were well tolerated . . . but vomiting, nausea, and dizziness were more common in the first 3 days after dihydroartemisinin–piperaquine . . . than sulfadoxine–pyrimethamine . . . The addition of azithromycin to dihydroartemisinin–piperaquine was associated with significantly more vomiting than with dihydroartemisinin–piperaquine alone (p=0.0033).”</p>
                        `,
                        consort_explanation: `
                            <p>Readers need information about the harms as well as the benefits of interventions to make rational and balanced decisions. Randomised trials offer an excellent opportunity for providing harms data, although they cannot detect differences in uncommon or rare harms between treatment groups. The existence and nature of adverse effects can have a major impact on whether a particular intervention will be deemed acceptable and useful. Not all reported adverse events observed during a trial are necessarily a consequence of the intervention; some may be a consequence of the condition being treated. Nevertheless, they all need to be reported.</p>
                            <p>Many reports of randomised trials provide inadequate information on harms. A comparison between harm data submitted to the trials database of the National Cancer Institute, which sponsored the trials, and the information reported in journal articles found that low grade adverse events were under-reported in journal articles. High grade events were reported inconsistently in the articles and the information regarding attribution to investigational drugs was incomplete. Moreover, a review of trials published in six general medical journals found that while most reports mentioned adverse events, no information on severe adverse events and withdrawal of patients owing to an adverse event was given in many articles.</p>
                            <p>For non-systematically assessed harms, reporting can be more complex as the information is not standardised. A common approach is to code the event declared by participants. Authors should report the coding system used, whether coding was prespecified in the protocol, in the statistical analysis plan, or post hoc, and whether coding was performed by researchers blinded to the treatment allocated. In addition, there is a risk of under-reporting and selective non-reporting of harms particularly for non-systematically assessed harms. Sharing of de-identified individual participant data may be needed to be able to adequately synthesise this information, for example for inclusion in a systematic review.</p>
                            <p>Authors should report for each group, the number of participants at risk, the number of deaths, the number of participants withdrawn due to harms, the number of participants with at least one harm event, and the number of events, if appropriate. Where appropriate, the estimated effect size with its precision (such as 95% CIs) should be reported including both absolute and relative effects for binary outcomes. It is important to separate the reporting of systematically and non-systematically assessed harms. Systematically assessed harms should be reported even if zero events were identified. It should also be clear whether the authors are reporting the number of participants with at least one harm event or the number of events per unit of time at risk and whether recurrent events were included. The number of participants withdrawn because of harms should also be reported for each group. Finally, results should be reported for all harms. We strongly discourage the use of thresholds or criteria to select which harms should be reported. All harms could be detailed in supplementary materials. We recommend reporting the results in a table with the results for each trial arm.</p>
                        `,
                        nut_ext: 'No formal extension for item 27 pertaining to nutrition trials. However, authors are advised to keep the specific advice below in mind regarding intervention tolerance.',
                        nut_explanation: `
                            <p>Harms and adverse events indicate suitability of the dietary intervention in a particular population. Moreover, issues relating to acceptability and tolerance, even if not considered serious, may affect the sustainability of an intervention in the long term. In nutrition trials, tolerance usually refers to the physiological phenomenon of the response to the intervention. Typical tolerance measures including gastrointestinal discomfort and allergic reactions, assessed by the ongoing reporting of adverse events to the trial team, primary or secondary care records, or post-trial questionnaires. Tolerance is monitored to ensure the safety and effectiveness of the intervention and the integrity of the trial results.</p>
                        `,
                        nut_examples: `
                            <p>“Adverse effects during the 24 week trial period are summarized in Table 2. The most common side effects were gastrointestinal problems, including soft stool or diarrhea, nausea, constipation or other gastrointestinal discomfort. Most of these were tolerated and self-limiting. However, one participant in the omega-3 group and one in the placebo group dropped out due to complaints of intolerable diarrhea.“ (Chiu et al., 2008)</p>
                        `
                    },
                    {
                        id: '28',
                        title: 'Ancillary analyses',
                        text: 'Any other analyses performed, including subgroup and sensitivity analyses, distinguishing prespecified from post hoc',
                        consort_examples: `
                            <p>“In a [prespecified] sensitivity analysis to support the primary binary endpoint, the NRS [numerical rating score] pain score at 1 month was also analyzed using the constrained longitudinal data analysis model . . . Primary Outcome: At 1 month after the intervention, the percentage of responders (Low Back Pain intensity <40) was higher in the glucocorticoid intradiscal injection (GCIDI) group (36 of 65 [55.4%]) than the control group (21of 63 [33.3%]) (absolute risk difference, 22.1 percent-age points [CI, 5.5 to 38.7 percentage points]; P=0.009 [after multiple imputation]) . . . In the sensitivity analysis, the mean reduction in LBP [low back pain] intensity from baseline to 1 month was greater in the GCIDI group (−32.5 [CI,-38.2 to −26.8]) than the control group (−17.5 [CI, −23.3 to −11.7]) (absolute difference, -15.0 [CI,-22.9 to −7.1]; P< 0.001).”</p>
                            <p>“Owing to the later inclusion of parent cosmetic appearance assessments (to assist with trial conduct), it was decided to perform a post hoc subgroup analysis to determine whether the scores given by the assessors and parents differed between treatment groups [table 15] . . . The assessor scores did not indicate a difference between the nail-replaced and nail-discarded groups. However, the scores given by the parents suggested that there was a statistically significant difference in favour of the nail-discarded group. The treatment by subgroup interaction term was statistically significant (OR [odds ratio] 0.24, 95% CI [confidence interval] 0.06 to 0.96. P= 0.044).”</p>
                        `,
                        consort_explanation: `
                            <p>Multiple analyses of the same data create a risk for false-positive findings. Authors should especially resist the temptation to perform many subgroup analyses. Analyses that were prespecified in the trial protocol (item 3) are much more reliable than those suggested by the data, and therefore authors should report which analyses were prespecified. If subgroup analyses were undertaken, authors should report which subgroups were examined, why, whether they were prespecified, and how many were prespecified. Selective reporting of subgroup analyses could lead to bias. When evaluating a subgroup, the question is not whether the subgroup demonstrates a statistically significant result but whether the subgroup treatment effects are significantly different from each other. To determine this, a test of interaction is helpful, although the power for such tests is typically low. If formal evaluations of interaction are undertaken (item 21d) they should be reported as the estimated difference in the intervention effect in each subgroup (with a CI), not just as P values.</p>
                            <p>In one survey, 35 of 50 trial reports included subgroup analyses, of which only 42% used tests of interaction. It was often difficult to determine whether subgroup analyses had been specified in the protocol. In another survey of surgical trials published in high impact journals, 27 of 72 trials reported 54 subgroup analyses of which 91% were post hoc and only 6% of subgroup analyses used a test of interaction to assess whether a subgroup effect existed.</p>
                        `,
                        nut_ext: 'No formal extension for item 28 pertaining to nutrition trials. However, authors are advised to keep the specific advice below in mind while reporting trial findings.',
                        nut_explanation: `
                            <p>There are no additional recommendations for item 28 pertaining to nutrition trials. However, the examples provided help clarify the CONSORT statement as it applies to nutrition trials. In these examples, the authors clarify the exploratory nature of their analyses. Delaney et al. states the exploratory nature of the analysis explicitly in the title, abstract, and the main text of their article. The PRUNE study declares the ancillary study in their title, abstract, and as illustrated in the aims of their methods. The Look AHEAD Trial example describes pre-specified sub-group analyses.</p>
                        `,
                        nut_examples: `
                            <p>Delaney et al. (2023) aimed “to assess the efficacy of a multi-strategy intervention implemented in an online school canteen ordering system in reducing the energy, saturated fat, sugar, and sodium content of students’ online recess orders” in a primary trial that evaluated the efficacy of an intervention on lunch order in schools. “This was an exploratory analysis of recess purchases for a cluster randomized controlled trial that initially sought to examine the efficacy of the intervention on lunch orders.” (Delaney et al., 2023)</p>
                            <p>“The Prune Study was a 12-mo parallel-design RCT that aimed to investigate the effects of prunes at 2 doses, 50 g/d and 100 g/d, compared with a no-prune control group on bone mineral density (BMD), bone geometry, and bone strength in postmenopausal women. … In our report of primary BMD endpoints, we observed a protective effect of 50 g/d prunes on total hip BMD in postmenopausal women. However, our understanding of the long-term effects of daily prune intake over the course of 12 mo on measures of fasting plasma glucose, insulin resistance, blood lipids, and central adiposity in this study population of postmenopausal women is limited. Therefore, the purpose of the current investigation is to perform an ancillary analysis of the parent RCT evaluating the dose–response effects of daily prune intake for 12 mo on select cardiometabolic health markers and regional fat distribution in postmenopausal women who completed the entire trial.“ (Damani et al., 2024)</p>
                            <p>The Look AHEAD Trial presents prespecified subgroup analysis and reports as follows: “The consistency of intervention effects on the primary outcome among three pre-specified subgroups (sex, race or ethnicity and history of cardiovascular disease) was evaluated using interaction tests.”  (Look et al., 2013)</p>
                        `
                    }
                ]
            },
            // --- DISCUSSION ---
            {
                group: 'Discussion',
                items: [
                {
                        id: '29',
                        title: 'Interpretation',
                        text: 'Interpretation consistent with results, balancing benefits and harms, and considering other relevant evidence',
                        consort_examples: `
                            <p>“In this trial, which compared standard of care with monthly IPTp [intermittent preventive treatment in pregnancy] with sulfadoxine–pyrimethamine with monthly IPTp with dihydroartemisinin–piperaquine and monthly IPTp with dihydroartemisinin–piperaquine plus azithromycin, the use of dihydroartemisinin– piperaquine was associated with reductions in clinical malaria, malaria infection detected by microscopy during pregnancy, and placental malaria at the time of birth. However, despite these reductions in malaria, the risk of adverse pregnancy outcomes (composite primary endpoint) was significantly lower in the sulfadoxine– pyrimethamine group than in both dihydroartemisinin–piperaquine groups . . .”</p>
                            <p>“In a previous meta-analysis a modest, but nonsignificant, reduction of 17% in the number of adverse pregnancy outcomes favouring dihydroartemisinin– piperaquine versus sulfadoxine–pyrimethamine was reported . . . These findings led WHO [World Health Organization] to recommend larger definitive studies to determine whether IPTp with dihydroartemisinin–piperaquine improves adverse pregnancy outcomes compared with sulfadoxine– pyrimethamine in areas with high sulfadoxine–pyrimethamine resistance. Our results are consistent with those from a third trial in eastern Uganda, which showed that monthly IPTp with dihydroartemisinin– piperaquine did not decrease the number of adverse pregnancy outcomes among livebirths or reduce fetal loss compared with monthly IPTp with sulfadoxine–pyrimethamine . . . All of these trials, including ours, show that dihydroartemisinin– piperaquine is the superior antimalarial, resulting in 40–90% fewer malaria infections during pregnancy.”</p>
                        `,
                        consort_explanation: `
                            <p>A good discussion section of a completed randomised trial should start with a brief summary of the trial results, balancing both benefits and harms of the intervention. The discussion sections of scientific reports are often filled with rhetoric supporting the authors’ findings and provide little measured argument of the pros and cons of the study and its results. Indeed, some discussion sections can be overly optimistic when discussing the trial findings (interpretation bias; spin). Authors need to guard against such behaviours, as they diminish the rigour of the scientific effort and may result in a loss of trust by readers.</p>
                            <p>Readers will also want to know how the trial results relate to those of other randomised trials. This can best be achieved by including a published systematic review in the results or discussion section of the report. This might be an easy ask for some authors as a systematic review might have been part of the rationale for conducting the trial. However, for others, such synthesis may be impractical, and quoting and discussing any existing systematic reviews of similar trials may be more appropriate. One recent estimate suggests that nearly 80 systematic reviews are published daily. Discussing trial findings in the context of results from any systematic reviews will help readers assess whether the results of the randomised trial are similar to those of other trials in the same topic area and whether participants are similar across studies. Reports of randomised trials have often not dealt adequately with these points. Several methods to address the issue of setting new trial findings within the context of previous research have been proposed. Where conducting a new updated systematic review is not practical, adding the new trial result to the previous systematic review is a much simpler alternative.</p>
                            <p>We recommend that at a minimum, the discussion should be as systematic and objective as possible and be based on a comprehensive search, rather than being limited to studies that support the results of the current trial.</p>
                        `,
                        nut_ext: `
                                <br />(i) Biological plausibility of the intervention or mechanism(s) underpinning the effect on the primary outcome. Role of background diet or other confounders or moderators on the results
                                <br />(ii) Consider dietary practices, socio-cultural appropriateness, environmental impact, and policy context
                                <br />(iii) Distinction between statistical and clinically relevant findings and how they contribute to clinical practice, dietary guidance, or public health recommendations and policy, as relevant
                        `,
                        nut_explanation: `
                            <p>Not all studies have the capability to measure mechanism(s) of benefit. Nutrition trials, where able, should state the causal relationship between a nutritional, physiological or health outcome and an exposure. This is important for exploring the strength of evidence, for complementing associations observed in epidemiological studies and to contribute to the reporting of evidence-based strategies. To this end, authors should refer back to any additional analyses performed for potential effect moderators or confounders (item 21d). This interpretation may consider how moderators, such as background dietary intake, might explain the overall findings and help identify populations most likely to benefit or be harmed by the intervention. Investigators should keep in mind that subgroup and other exploratory analyses should be interpreted with caution and described in terms of hypothesis-generation that may be used to prompt future trials designed specifically to address the hypothesis.</p>
                            <p>There may be cultural barriers against changing current food preferences thus supporting the need to make dietary advice culturally appropriate and these should be reported. The Mediterranean diet may share similarities with non-Mediterranean patterns such as a foundation of plant foods like rice, grains, legumes, fruit and vegetables as seen in the Japanese diet. In relation to culture, tradition and culinary practice, these factors may be less easy to change; however substitutions of cultural dishes and similarities between culinary practice have begun to appear in nutrition research, which need to be reported.  There is an emerging importance on acknowledging the impact of dietary interventions on the environment. The EAT-Lancet Commission is advancing efforts toward healthier and more sustainable diets that balance nutritional needs with environmental goals. Increasingly, studies are examining how different foods and dietary patterns affect both human and planetary ‘health’. Where appropriate, the environmental impact should be considered and clearly stated.</p>
                            <p>Statistical significance does not necessarily entail a clinically relevant observed effect. As reported in drug trials, the clinical relevance of outcomes from a nutrition intervention should be considered. This is important to ensure that research findings can be used in a meaningful and impactful way by individuals and healthcare providers and policy-makers.</p>
                        `,
                        nut_examples: `
                            <p><strong>Examples for (i) Biological Plausibility</strong></p>
                            <p>“Significant controversy has emerged over the last decade concerning the effects of vitamin D on skeletal and non-skeletal tissues. The demonstration that the vitamin D receptor is expressed in virtually all cells of the body and the growing body of observational data supporting a relationship of serum 25-hydroxyvitamin D to chronic metabolic, cardiovascular, and neoplastic diseases have led to widespread utilization of vitamin D supplementation for the prevention and treatment of numerous disorders.” (Rosen et al., 2012)</p>
                            <p>“Mechanisms responsible for benefits of black tea on BP were not addressed in the current study.  There is mounting evidence that black tea flavonoids can improve vascular health (13) via effects on nitric oxide status (32), endothelial function (33), and arterial stiffness (14).” (Hodgson, Croft et al. 2013)</p>
                            <p>“The mechanisms by which omega-3 PUFAs lower triglycerides reflects, in part, increased uptake into cellular phospholipids, rather than into triacylglycerol, due to inhibition of phosphatidic acid phosphatase.” (Weinberg et al., 2021)</p>
                            <br />
                            <p><strong>Examples for (ii) Socio-cultural appropriate and environmental impact</strong></p>
                            <p>“Incorporating foods that are culturally acceptable, locally produced and accessible, but with a similar nutritional profile to those prominent in a Mediterranean Diet, may further encourage Mediterranean Diet adherence in non-Mediterranean countries.” (Woodside et al., 2022)</p>
                            <p>“...., compared the [GreenHouse Gas] GHG emissions in different diet styles, concluding that a high-meat diet emitted 7.19 carbon dioxide equivalents per day (kgCO2e/day), while vegetarian diet emitted 3.81 kgCO2e/day. It means almost a half of reduction in GHG emissions. The decrease is even greater when following a vegan diet: 2.89 kgCO2e/day”. (Gonzalez et al., 2020)</p>
                            <br />
                            <p><strong>Examples for (iii) statistical and clinical relevance</strong></p>
                            <p>“A difference between the minimal detectable change (MDC) and minimal clinically important difference (MCID) values indicates that there is a range of score changes that are statistically significant but not clinically meaningful, or vice versa. The differences between the MDC and MCID values of the Montreal Cognitive Assessment (MoCA) have important clinical and scientific implications. From a clinical perspective, a change of ≥ 1 to 2 points in a patient's MoCA score may be considered important by the patient or clinician, although larger changes may be required to definitively demonstrate significant differences. Our results suggest that the MoCA may not be an ideal outcome measure for studies evaluating the effectiveness of interventions for cognitive impairment, as subtle improvements or deteriorations in cognitive function that are important to stroke survivors may be ‘lost’ in test-retest variability”. (Lindvall et al., 2024)</p>
                            <p>“In our study, the average depression score of the MedDiet group [significantly] fell below the extremely severe depression cut-off, whereas in the social group it remained in the extremely severe range.”  (Parletta, Zarnowiecki et al. 2019)</p>
                        `
                    },
                    {
                        id: '30',
                        title: 'Limitations',
                        text: 'Trial limitations, addressing sources of potential bias, imprecision, generalisability, and, if relevant, multiplicity of analyses',
                        consort_examples: `
                            <p>“The preponderance of male patients (85%) is a limitation of our study . . . We used bare-metal stents, since drug-eluting stents were not available until late during accrual. Although the latter factor may be perceived as a limitation, published data indicate no benefit (either short-term or long-term) with respect to death and myocardial infarction in patients with stable coronary artery disease who receive drug-eluting stents, as compared with those who receive bare-metal stents.”</p>
                            <p>“Our study had several limitations. The early changes to the protocol to accommodate patients with a shorter injury history (but still not acute) to improve recruitment altered the characteristics of the study population. Overall, patients had less long-standing injury than was originally planned. Moreover, the study addressed a deliberately specific population of patients who continued to have ACL injury-related symptoms of instability and had not undergone any previous formal treatment. Another potential limitation is the proportion of patients who did not undergo surgical reconstruction, despite allocation to that group. The true benefit of surgical reconstruction could be somewhat greater than the ITT analysis suggests. The 18-month follow-up period ideally could have been longer but was constrained by various factors including funding. Notwithstanding, most patients had established their level of instability at this timepoint since being included in the trial. The trial design and analysis accounted for delayed surgery in both groups.”</p>
                        `,
                        consort_explanation: `
                            <p>An essential part of a good discussion section is summarising the limitations of the trial. Limitations are frequently omitted from research reports; identification and discussion of the weaknesses of a study have particular importance.</p>
                            <p>Some journals have attempted to remedy this problem by encouraging more structure to authors’ discussion of their results. For example, The BMJ recommends that authors structure the discussion section by presenting (1) a statement of the principal findings; (2) the strengths and weaknesses of the study; (3) the strengths and weaknesses in relation to other studies, discussing important differences in results; (4) the meaning of the study, its possible explanations and implications for clinicians and policymakers; and (5) any unanswered questions and future research. We recommend that authors follow these sensible suggestions, perhaps also using suitable subheadings in the discussion section.</p>
                            <p>Authors should also discuss any imprecision of the results. Imprecision may arise in connection with several aspects of a study, including measurement of a primary outcome (item 14) or diagnosis (item 12a). Perhaps the scale used was validated on an adult population but used in a paediatric one, or the assessor was not trained in how to administer the instrument.</p>
                            <p>The difference between statistical significance and clinical importance should always be borne in mind. Authors should particularly avoid the common error of interpreting a non-significant result as indicating equivalence of interventions. The CI (item 26) provides valuable insight into whether the trial result is compatible with a clinically important effect, regardless of the P value.</p>
                            <p>Authors should exercise special care when evaluating the results of trials with multiple comparisons. Such multiplicity arises from several interventions, outcome measures, time points, subgroup analyses, and other factors. In such circumstances, some statistically significant findings are likely to result from chance alone.</p>
                            <p>Authors should also consider the extent to which the results of a study can be generalised to other circumstances; also known as external validity. For example, can the results be generalised to an individual participant or groups that differ from those enrolled in the trial with regard to age, sex, severity of disease, and comorbid conditions? Are the results applicable to other drugs within a class of similar drugs, to a different dose, timing, and route of administration? Can similar results be expected in different healthcare settings? What about the effect on related outcomes that were not assessed in the trial, and the importance of length of follow-up and duration of treatment, especially with respect to harms? Internal validity, the extent to which the design and conduct of the trial eliminates the possibility of bias, is a prerequisite for external validity: the results of a flawed trial are invalid and the question of its external validity becomes irrelevant. External validity is a matter of judgement and depends on the characteristics of the participants included in the trial, the trial setting, the treatment regimens tested, and the outcomes assessed.</p>
                        `
                    }
                ]
            }
        ];

        // --- RENDERING LOGIC ---
        const form = document.getElementById('checklist-form');
        
        checklistData.forEach(group => {
            const groupDiv = document.createElement('div');
            groupDiv.innerHTML = `<h3 class="text-2xl font-bold text-gray-900 border-b-2 border-gray-200 pb-2 mb-6 mt-10">${group.group}</h3>`;
            
            group.items.forEach(item => {
                const hasConsort = item.consort_explanation || item.consort_examples;
                const hasNut = item.nut_explanation || item.nut_examples || item.nut_ext;
                const itemDiv = document.createElement('div');
                itemDiv.className = "checklist-item bg-gray-50 p-4 rounded-lg border border-gray-200 shadow-sm transition hover:shadow-md";
                
                let nutBadge = item.nut_ext && !item.nut_ext.includes('No formal extension') 
                    ? `<span class="inline-block bg-purple-100 text-purple-800 text-xs px-2 py-1 rounded-full font-semibold border border-purple-200 mb-2">CONSORT-Nut Extension</span>` 
                    : '';

                // If it's just advice, we can use a different badge or just the text
                if (item.nut_ext && item.nut_ext.includes('No formal extension')) {
                    nutBadge = `<span class="inline-block bg-blue-100 text-blue-800 text-xs px-2 py-1 rounded-full font-semibold border border-blue-200 mb-2">Nutrition-Specific Advice</span>`;
                }

                itemDiv.innerHTML = `
                    <div class="flex flex-col md:flex-row md:items-start gap-4">
                        <div class="flex-grow">
                            ${nutBadge}
                            <div class="flex items-baseline gap-2">
                                <span class="font-mono font-bold text-lg text-gray-500">#${item.id}</span>
                                <h4 class="font-bold text-lg text-gray-900">${item.title}</h4>
                            </div>
                            <p class="text-gray-700 mt-1 pl-8"><strong>Item:</strong> ${item.text}</p>
                            ${item.nut_ext && !item.nut_ext.includes('No formal extension') ? `<p class="text-purple-800 mt-2 pl-8 border-l-4 border-purple-300 bg-purple-50 p-2 text-sm"><strong>Extension:</strong> ${item.nut_ext}</p>` : ''}
                        </div>
                        <div class="flex-shrink-0 w-full md:w-32">
                            <label class="block text-xs font-semibold text-gray-500 uppercase tracking-wide">Page No.</label>
                            <input type="text" id="page_${item.id}" class="w-full mt-1 p-2 border border-gray-300 rounded focus:ring-2 focus:ring-indigo-500 focus:border-indigo-500" placeholder="e.g. 4-5">
                        </div>
                    </div>
                    
                    <div class="mt-4 pl-8">
                        <label class="block text-xs font-semibold text-gray-500 uppercase tracking-wide">Notes</label>
                        <textarea id="notes_${item.id}" rows="2" class="w-full mt-1 p-2 border border-gray-300 rounded text-sm focus:ring-2 focus:ring-indigo-500 focus:border-indigo-500" placeholder="Your notes here..."></textarea>
                    </div>

                    <div class="mt-4 pl-0 md:pl-8">
                        <button type="button" class="toggle-btn text-indigo-600 hover:text-indigo-800 text-sm font-medium flex items-center focus:outline-none">
                            <span class="mr-1">▶</span> Show Explanation & Examples
                        </button>
                        
                        <div class="explanation-panel hidden mt-4 grid grid-cols-1 lg:grid-cols-2 gap-4">
                            ${hasConsort ? `
                            <div class="bg-white p-4 rounded border border-teal-200 border-t-4 border-t-teal-500">
                                <h5 class="font-bold text-teal-800 text-sm uppercase mb-2">CONSORT (General)</h5>
                                <div class="text-sm text-gray-700 space-y-2 explanation-text">${item.consort_explanation || ''}</div>
                                ${item.consort_examples ? `<div class="mt-3 pt-3 border-t border-teal-100 text-sm bg-teal-50 p-2 rounded"><strong class="text-teal-800">Example:</strong> ${item.consort_examples}</div>` : ''}
                            </div>` : ''}
                            
                            ${hasNut ? `
                            <div class="bg-white p-4 rounded border border-purple-200 border-t-4 border-t-purple-500">
                                <h5 class="font-bold text-purple-800 text-sm uppercase mb-2">CONSORT-Nut (Nutrition)</h5>
                                ${item.nut_ext && item.nut_ext.includes('No formal extension') ? `<div class="text-sm font-semibold text-blue-700 mb-2">${item.nut_ext}</div>` : ''}
                                <div class="text-sm text-gray-700 space-y-2 explanation-text">${item.nut_explanation || ''}</div>
                                ${item.nut_examples ? `<div class="mt-3 pt-3 border-t border-purple-100 text-sm bg-purple-50 p-2 rounded"><strong class="text-purple-800">Nutrition Example:</strong> ${item.nut_examples}</div>` : ''}
                            </div>` : ''}
                        </div>
                    </div>
                `;
                groupDiv.appendChild(itemDiv);
            });
            form.appendChild(groupDiv);
        });

        // --- LOCAL STORAGE LOGIC (7-Day Expiry) ---
        const storageKey = 'consortNutData'; // Unique key for this form
        const expiryDuration = 7 * 24 * 60 * 60 * 1000; // 7 days in milliseconds

        function saveData() {
            const formData = {};
            // Capture all page number inputs and note textareas
            form.querySelectorAll('input[type="text"], textarea').forEach(field => {
                if (field.id) {
                    formData[field.id] = field.value;
                }
            });

            // Create object with timestamp and data
            const dataObject = {
                timestamp: Date.now(),
                data: formData
            };

            localStorage.setItem(storageKey, JSON.stringify(dataObject));
        }

        function loadData() {
            const storedString = localStorage.getItem(storageKey);
            if (!storedString) return;

            try {
                const storedObject = JSON.parse(storedString);
                const now = Date.now();

                // Check if data is older than 7 days
                if (now - storedObject.timestamp > expiryDuration) {
                    console.log("Saved data has expired. Clearing storage.");
                    localStorage.removeItem(storageKey);
                    return;
                }

                // If valid, populate fields
                if (storedObject.data) {
                    Object.entries(storedObject.data).forEach(([id, value]) => {
                        const element = document.getElementById(id);
                        if (element) {
                            element.value = value;
                        }
                    });
                }
            } catch (error) {
                console.error("Error parsing saved data:", error);
            }
        }

        // Initialize: Load data immediately
        loadData();

        // Event Listener: Save whenever the user types
        form.addEventListener('input', saveData);

        // --- INTERACTIVITY ---

      

        // Function to show a page and update navigation styling
        function showPage(hash) {
            if (!pages || !pages.length) return;

            // 1. Determine target page ID (default to 'checklist' if hash is empty)
            const currentHash = hash || '#checklist';
            const targetId = (currentHash.substring(1)) + '-page';
            const targetPage = document.getElementById(targetId);
            
            // 2. Hide all pages
            pages.forEach(page => page.classList.remove('active'));
            
            // 3. Show target page (fallback to checklist if target doesn't exist)
            if (targetPage) {
                targetPage.classList.add('active');
            } else {
                const defaultPage = document.getElementById('checklist-page');
                if(defaultPage) defaultPage.classList.add('active');
            }

            // 4. Update Navigation Link Styling (Subtle Background Highlight)
            if (navLinksWrap) {
                const links = navLinksWrap.querySelectorAll('.nav-link');
                links.forEach(link => {
                    // Reset to inactive style
                    // Remove the active background and white text
                    link.classList.remove('bg-gray-800', 'text-white', 'font-semibold');
                    // Add back the gray text and hover effect
                    link.classList.add('text-gray-300', 'hover:bg-gray-700');

                    // Apply active style if matches
                    if (link.getAttribute('href') === currentHash) {
                        link.classList.remove('text-gray-300', 'hover:bg-gray-700');
                        // Add subtle dark background and white text
                        link.classList.add('bg-gray-800', 'text-white', 'font-semibold');
                    }
                });
            }
        }

        // --- ROBUST NAVIGATION LOGIC ---
        const navLinksWrap = document.getElementById('nav-links');
        const pages = document.querySelectorAll('.page-content');

        function showPage(hash) {
            if (!pages || !pages.length) return;

            // 1. Identify the target page (Default to 'checklist' if hash is empty)
            const currentHash = hash || '#checklist';
            const targetId = (currentHash.substring(1)) + '-page';
            const targetPage = document.getElementById(targetId);
            
            // 2. Hide all pages, then show the target
            pages.forEach(page => page.classList.remove('active'));
            if (targetPage) {
                targetPage.classList.add('active');
            } else {
                // Fallback if ID not found
                const fallback = document.getElementById('checklist-page');
                if (fallback) fallback.classList.add('active');
            }

            // 3. Update the Navigation Bar Styles
            if (navLinksWrap) {
                const links = navLinksWrap.querySelectorAll('.nav-link');
                links.forEach(link => {
                    // Remove active styling from EVERY link first
                    link.classList.remove('bg-gray-900', 'text-white');
                    link.classList.add('text-gray-300');

                    // Add active styling ONLY to the current link
                    if (link.getAttribute('href') === currentHash) {
                        link.classList.remove('text-gray-300');
                        link.classList.add('bg-gray-900', 'text-white');
                    }
                });
            }
        }

        // Listener: Handle clicks on nav links
        if (navLinksWrap) {
            navLinksWrap.addEventListener('click', function (e) {
                if (e.target.classList.contains('nav-link')) {
                    e.preventDefault();
                    const targetHash = e.target.getAttribute('href');
                    history.pushState(null, '', targetHash); // Update URL
                    showPage(targetHash); // Update View
                }
            });
        }

        // Listener: Handle "How to use" banner inside the checklist
        const howToBanner = document.getElementById('how-to-use-banner');
        if (howToBanner) {
            howToBanner.addEventListener('click', () => {
                history.pushState(null, '', '#how-to-use');
                showPage('#how-to-use');
            });
        }

        // Listener: Handle Browser Back/Forward buttons
        window.addEventListener('popstate', function () {
            showPage(window.location.hash);
        });

        // Initialization: Run once on page load to set correct state
        showPage(window.location.hash);

        // Toggle Single Item
        document.body.addEventListener('click', (e) => {
            if(e.target.closest('.toggle-btn')) {
                const btn = e.target.closest('.toggle-btn');
                const panel = btn.nextElementSibling;
                
                panel.classList.toggle('hidden');
                if(panel.classList.contains('hidden')) {
                    btn.innerHTML = `<span class="mr-1">▶</span> Show Explanation & Examples`;
                } else {
                    btn.innerHTML = `<span class="mr-1">▼</span> Hide Explanation & Examples`;
                }
            }
        });

        // Toggle All
        const toggleAllBtn = document.getElementById('toggle-all-btn');
        let allExpanded = false;
        toggleAllBtn.addEventListener('click', () => {
            const panels = document.querySelectorAll('.explanation-panel');
            const btns = document.querySelectorAll('.toggle-btn');
            
            allExpanded = !allExpanded;
            
            panels.forEach(panel => {
                if(allExpanded) panel.classList.remove('hidden');
                else panel.classList.add('hidden');
            });

            btns.forEach(btn => {
                btn.innerHTML = allExpanded 
                    ? `<span class="mr-1">▼</span> Hide Explanation & Examples`
                    : `<span class="mr-1">▶</span> Show Explanation & Examples`;
            });

            toggleAllBtn.innerHTML = allExpanded 
                ? `<span class="mr-2">▼</span> Collapse All Details`
                : `<span class="mr-2">▶</span> Expand All Details`;
        });

        // Word Export Logic (Table Format - Landscape)
        document.getElementById('download-word-btn').addEventListener('click', (e) => {
            e.preventDefault();
            
            // Build HTML string for Word with TABLE structure
            let content = `
                <html xmlns:o='urn:schemas-microsoft-com:office:office' xmlns:w='urn:schemas-microsoft-com:office:word' xmlns='http://www.w3.org/TR/REC-html40'>
                <head><meta charset='utf-8'><title>CONSORT-Nut Checklist</title>
                <style>
                    body { font-family: 'Calibri', sans-serif; }
                    h1 { font-size: 24pt; color: #111827; margin-bottom: 10px; }
                    table { width: 100%; border-collapse: collapse; margin-top: 20px; }
                    th, td { border: 1px solid #000000; padding: 8px; vertical-align: top; }
                    th { background-color: #E5E7EB; font-weight: bold; text-align: left; }
                    .section-header { background-color: #F3F4F6; font-weight: bold; padding: 10px; font-size: 14pt; }
                    .nut-bold { font-weight: bold; }
                    .notes-cell { white-space: pre-wrap; }
                    /* Ensure table fits nicely in landscape */
                    @page {
                        size: landscape;
                        margin: 1cm;
                    }
                </style>
                </head><body>
                <h1>CONSORT-Nut 2025 Checklist Report</h1>
                <p>Generated on ${new Date().toLocaleDateString()}</p>
                
                <table style="width: 100%;">
                    <thead>
                        <tr>
                            <th style="width: 15%;">Section/Topic</th>
                            <th style="width: 5%;">Item</th>
                            <th style="width: 55%;">CONSORT 2025 with CONSORT-Nut 2025 (in bold)</th>
                            <th style="width: 25%;">Page(s) no. / notes</th>
                        </tr>
                    </thead>
                    <tbody>
            `;

            checklistData.forEach(group => {
                // Section Header Row
                content += `
                    <tr>
                        <td colspan="4" class="section-header">${group.group}</td>
                    </tr>
                `;
                
                group.items.forEach(item => {
                    const pageVal = document.getElementById(`page_${item.id}`).value;
                    const notesVal = document.getElementById(`notes_${item.id}`).value;
                    
                    // Construct the combined text for the description column
                    let description = `<p>${item.text}</p>`;
                    if (item.nut_ext) {
                        // Append the CONSORT-Nut text in bold
                        let nutText = item.nut_ext;
                        description += `<p class="nut-bold">CONSORT-Nut 2025: ${nutText}</p>`;
                    }

                    // Construct Notes/Page column content
                    let userNotes = "";
                    if (pageVal) userNotes += `Page: ${pageVal}\n`;
                    if (notesVal) userNotes += `Notes: ${notesVal}`;

                    content += `
                        <tr>
                            <td>${item.title}</td>
                            <td>${item.id}</td>
                            <td>${description}</td>
                            <td class="notes-cell">${userNotes}</td>
                        </tr>
                    `;
                });
            });

            content += `
                    </tbody>
                </table>
                </body></html>
            `;

            // Generate Blob with Landscape orientation
            const converted = htmlDocx.asBlob(content, { 
                orientation: 'landscape', 
                margins: { top: 720, right: 720, bottom: 720, left: 720 } // approx 0.5 inch margins
            });
            
            saveAs(converted, 'CONSORT-Nut_Checklist.docx');
        });
    
        // --- INITIALIZATION ---
        
        // 1. Clear the URL hash so it doesn't remember the last tab
        if (history.replaceState) {
            history.replaceState(null, document.title, window.location.pathname + window.location.search);
        }

        // 2. Force load the Checklist page
        showPage('#checklist');
    })();
    </script>
</body>
</html>
